{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d588b1ad",
   "metadata": {
    "id": "9ae8fe9a"
   },
   "source": [
    "## Building Artificial Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d01214",
   "metadata": {
    "id": "f5d01214"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "sb.set()\n",
    "\n",
    "import pickle\n",
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51228b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.read_csv('x_train.csv', index_col=0)\n",
    "x_test_df = pd.read_csv('x_test.csv', index_col=0)\n",
    "y_train_df = pd.read_csv('y_train.csv', index_col=0)\n",
    "y_test_df = pd.read_csv('y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcfe1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_x = StandardScaler()\n",
    "\n",
    "x_train_scaled = sc_x.fit_transform(x_train_df.values[:,:2])\n",
    "x_test_scaled = sc_x.transform(x_test_df.values[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b25c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((x_train_scaled, x_train_df.values[:,2:]), axis=1)\n",
    "x_test = np.concatenate((x_test_scaled, x_test_df.values[:,2:]), axis=1)\n",
    "y_test = y_test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5637b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(X_train, y_train_df.values, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "452f337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = x_train.shape[1]\n",
    "\n",
    "def make_regression_model(units=6, activation1='sigmoid', activation2='linear', initializer='he_normal', rate=00, lr=0.01):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units, activation=activation1, kernel_initializer=initializer, input_shape=(input_layer_size,)))\n",
    "    model.add(Dropout(rate))\n",
    "    model.add(Dense(output_size, activation=activation2))\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr), loss = 'mse', metrics = ['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b2f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 17ms/step - loss: 1.3599 - mae: 0.8936 - val_loss: 1.0696 - val_mae: 0.7693\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5951 - mae: 0.5585 - val_loss: 0.5925 - val_mae: 0.5800\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3592 - mae: 0.4410 - val_loss: 0.3911 - val_mae: 0.4841\n",
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2665 - mae: 0.3948 - val_loss: 0.3021 - val_mae: 0.4349\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2204 - mae: 0.3677 - val_loss: 0.2727 - val_mae: 0.4077\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1916 - mae: 0.3411 - val_loss: 0.2438 - val_mae: 0.3826\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1599 - mae: 0.3149 - val_loss: 0.1855 - val_mae: 0.3283\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1338 - mae: 0.2843 - val_loss: 0.1898 - val_mae: 0.3254\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1149 - mae: 0.2631 - val_loss: 0.1589 - val_mae: 0.2931\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0957 - mae: 0.2407 - val_loss: 0.1402 - val_mae: 0.2624\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0823 - mae: 0.2222 - val_loss: 0.1576 - val_mae: 0.2901\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0755 - mae: 0.2149 - val_loss: 0.1255 - val_mae: 0.2562\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - mae: 0.2052 - val_loss: 0.1301 - val_mae: 0.2675\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - mae: 0.2092 - val_loss: 0.1236 - val_mae: 0.2507\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0653 - mae: 0.2010 - val_loss: 0.1191 - val_mae: 0.2583\n",
      "Epoch 16/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0619 - mae: 0.1970 - val_loss: 0.1255 - val_mae: 0.2553\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0622 - mae: 0.1948 - val_loss: 0.1151 - val_mae: 0.2427\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0611 - mae: 0.1951 - val_loss: 0.1158 - val_mae: 0.2444\n",
      "Epoch 19/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0588 - mae: 0.1941 - val_loss: 0.1096 - val_mae: 0.2348\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0632 - mae: 0.1958 - val_loss: 0.1119 - val_mae: 0.2400\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - mae: 0.1900 - val_loss: 0.1195 - val_mae: 0.2460\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0595 - mae: 0.1914 - val_loss: 0.1113 - val_mae: 0.2370\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0607 - mae: 0.1944 - val_loss: 0.1097 - val_mae: 0.2367\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0598 - mae: 0.1963 - val_loss: 0.1093 - val_mae: 0.2363\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0574 - mae: 0.1887 - val_loss: 0.1074 - val_mae: 0.2272\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0596 - mae: 0.1908 - val_loss: 0.1144 - val_mae: 0.2471\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0579 - mae: 0.1919 - val_loss: 0.1096 - val_mae: 0.2377\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - mae: 0.1897 - val_loss: 0.1081 - val_mae: 0.2352\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0569 - mae: 0.1872 - val_loss: 0.1063 - val_mae: 0.2304\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0574 - mae: 0.1893 - val_loss: 0.1111 - val_mae: 0.2398\n",
      "Epoch 31/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - mae: 0.1885 - val_loss: 0.1150 - val_mae: 0.2451\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - mae: 0.1882 - val_loss: 0.1069 - val_mae: 0.2362\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - mae: 0.1817 - val_loss: 0.1078 - val_mae: 0.2355\n",
      "Epoch 34/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - mae: 0.1888 - val_loss: 0.1087 - val_mae: 0.2408\n",
      "Epoch 35/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0557 - mae: 0.1872 - val_loss: 0.1077 - val_mae: 0.2377\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0541 - mae: 0.1866 - val_loss: 0.1008 - val_mae: 0.2195\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - mae: 0.1851 - val_loss: 0.0993 - val_mae: 0.2178\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0531 - mae: 0.1809 - val_loss: 0.1066 - val_mae: 0.2377\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0537 - mae: 0.1846 - val_loss: 0.1032 - val_mae: 0.2306\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0529 - mae: 0.1801 - val_loss: 0.1148 - val_mae: 0.2453\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0531 - mae: 0.1819 - val_loss: 0.0985 - val_mae: 0.2164\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0525 - mae: 0.1780 - val_loss: 0.1004 - val_mae: 0.2244\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0535 - mae: 0.1818 - val_loss: 0.0975 - val_mae: 0.2219\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0527 - mae: 0.1818 - val_loss: 0.0986 - val_mae: 0.2255\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0521 - mae: 0.1802 - val_loss: 0.0981 - val_mae: 0.2242\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0517 - mae: 0.1802 - val_loss: 0.0956 - val_mae: 0.2204\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0511 - mae: 0.1813 - val_loss: 0.1007 - val_mae: 0.2298\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - mae: 0.1743 - val_loss: 0.1004 - val_mae: 0.2335\n",
      "Epoch 49/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0510 - mae: 0.1760 - val_loss: 0.0961 - val_mae: 0.2195\n",
      "Epoch 50/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1773 - val_loss: 0.0966 - val_mae: 0.2228\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.1751 - val_loss: 0.0944 - val_mae: 0.2217\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0516 - mae: 0.1779 - val_loss: 0.0956 - val_mae: 0.2224\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - mae: 0.1736 - val_loss: 0.0925 - val_mae: 0.2158\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - mae: 0.1752 - val_loss: 0.0919 - val_mae: 0.2190\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0479 - mae: 0.1719 - val_loss: 0.0976 - val_mae: 0.2220\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1710 - val_loss: 0.0947 - val_mae: 0.2219\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0486 - mae: 0.1721 - val_loss: 0.0929 - val_mae: 0.2152\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0461 - mae: 0.1692 - val_loss: 0.0907 - val_mae: 0.2136\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - mae: 0.1677 - val_loss: 0.0986 - val_mae: 0.2273\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - mae: 0.1649 - val_loss: 0.0953 - val_mae: 0.2249\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.1677 - val_loss: 0.1042 - val_mae: 0.2335\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - mae: 0.1725 - val_loss: 0.0936 - val_mae: 0.2157\n",
      "Epoch 63/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.1684 - val_loss: 0.0988 - val_mae: 0.2296\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0452 - mae: 0.1685 - val_loss: 0.0907 - val_mae: 0.2136\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.1658 - val_loss: 0.0909 - val_mae: 0.2124\n",
      "Epoch 66/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.1647 - val_loss: 0.0887 - val_mae: 0.2110\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 0.1683 - val_loss: 0.0901 - val_mae: 0.2157\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1607 - val_loss: 0.0958 - val_mae: 0.2253\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1636 - val_loss: 0.0905 - val_mae: 0.2129\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1640 - val_loss: 0.0898 - val_mae: 0.2122\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0408 - mae: 0.1598 - val_loss: 0.0925 - val_mae: 0.2174\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.1643 - val_loss: 0.0880 - val_mae: 0.2116\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0422 - mae: 0.1617 - val_loss: 0.0897 - val_mae: 0.2096\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0401 - mae: 0.1568 - val_loss: 0.0871 - val_mae: 0.2095\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1522 - val_loss: 0.0875 - val_mae: 0.2123\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0388 - mae: 0.1562 - val_loss: 0.0882 - val_mae: 0.2102\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1573 - val_loss: 0.0871 - val_mae: 0.2088\n",
      "Epoch 78/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.1550 - val_loss: 0.0846 - val_mae: 0.2068\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1500 - val_loss: 0.0859 - val_mae: 0.2075\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0386 - mae: 0.1572 - val_loss: 0.0841 - val_mae: 0.2072\n",
      "Epoch 81/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1507 - val_loss: 0.0833 - val_mae: 0.2068\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1522 - val_loss: 0.0825 - val_mae: 0.2057\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.1551 - val_loss: 0.0847 - val_mae: 0.2111\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1546 - val_loss: 0.0857 - val_mae: 0.2080\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1474 - val_loss: 0.0820 - val_mae: 0.2018\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1517 - val_loss: 0.0850 - val_mae: 0.2092\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0369 - mae: 0.1488 - val_loss: 0.0845 - val_mae: 0.2103\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0359 - mae: 0.1526 - val_loss: 0.0832 - val_mae: 0.2034\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0348 - mae: 0.1499 - val_loss: 0.0840 - val_mae: 0.2100\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - mae: 0.1486 - val_loss: 0.0802 - val_mae: 0.2035\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1478 - val_loss: 0.0836 - val_mae: 0.2085\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1494 - val_loss: 0.0811 - val_mae: 0.2013\n",
      "Epoch 93/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1451 - val_loss: 0.0803 - val_mae: 0.2012\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1482 - val_loss: 0.0800 - val_mae: 0.2034\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1487 - val_loss: 0.0808 - val_mae: 0.2033\n",
      "Epoch 96/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.1494 - val_loss: 0.0820 - val_mae: 0.2066\n",
      "Epoch 97/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0343 - mae: 0.1500 - val_loss: 0.0812 - val_mae: 0.2115\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.1457 - val_loss: 0.0830 - val_mae: 0.2087\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1451 - val_loss: 0.0816 - val_mae: 0.2069\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1432 - val_loss: 0.0795 - val_mae: 0.2081\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1474 - val_loss: 0.0813 - val_mae: 0.2062\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0343 - mae: 0.1506 - val_loss: 0.0803 - val_mae: 0.2066\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1490 - val_loss: 0.0823 - val_mae: 0.2076\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1484 - val_loss: 0.0818 - val_mae: 0.2068\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1449 - val_loss: 0.0800 - val_mae: 0.2130\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1499 - val_loss: 0.0796 - val_mae: 0.2073\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1467 - val_loss: 0.0835 - val_mae: 0.2106\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1485 - val_loss: 0.0809 - val_mae: 0.2108\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1452 - val_loss: 0.0786 - val_mae: 0.2065\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1499 - val_loss: 0.0811 - val_mae: 0.2071\n",
      "Epoch 111/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1497 - val_loss: 0.0814 - val_mae: 0.2076\n",
      "Epoch 112/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1466 - val_loss: 0.0806 - val_mae: 0.2048\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1480 - val_loss: 0.0806 - val_mae: 0.2070\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0333 - mae: 0.1506 - val_loss: 0.0809 - val_mae: 0.2060\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1458 - val_loss: 0.0796 - val_mae: 0.2063\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1481 - val_loss: 0.0792 - val_mae: 0.2048\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1493 - val_loss: 0.0806 - val_mae: 0.2048\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1456 - val_loss: 0.0790 - val_mae: 0.2069\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1480 - val_loss: 0.0795 - val_mae: 0.2139\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1478 - val_loss: 0.0794 - val_mae: 0.2122\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1460 - val_loss: 0.0797 - val_mae: 0.2058\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1466 - val_loss: 0.0787 - val_mae: 0.2092\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1452 - val_loss: 0.0807 - val_mae: 0.2068\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1492 - val_loss: 0.0803 - val_mae: 0.2072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1442 - val_loss: 0.0832 - val_mae: 0.2234\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1521 - val_loss: 0.0805 - val_mae: 0.2085\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1480 - val_loss: 0.0812 - val_mae: 0.2103\n",
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1442 - val_loss: 0.0801 - val_mae: 0.2147\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1489 - val_loss: 0.0779 - val_mae: 0.2063\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1439 - val_loss: 0.0820 - val_mae: 0.2203\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1438 - val_loss: 0.0788 - val_mae: 0.2080\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1427 - val_loss: 0.0798 - val_mae: 0.2103\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1475 - val_loss: 0.0806 - val_mae: 0.2099\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1471 - val_loss: 0.0801 - val_mae: 0.2055\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1457 - val_loss: 0.0817 - val_mae: 0.2122\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1490 - val_loss: 0.0795 - val_mae: 0.2049\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1433 - val_loss: 0.0809 - val_mae: 0.2062\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1462 - val_loss: 0.0798 - val_mae: 0.2181\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1491 - val_loss: 0.0785 - val_mae: 0.2096\n",
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1459 - val_loss: 0.0786 - val_mae: 0.2088\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1459 - val_loss: 0.0799 - val_mae: 0.2108\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1455 - val_loss: 0.0815 - val_mae: 0.2131\n",
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1507 - val_loss: 0.0810 - val_mae: 0.2087\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1457 - val_loss: 0.0828 - val_mae: 0.2148\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1472 - val_loss: 0.0797 - val_mae: 0.2066\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1413 - val_loss: 0.0813 - val_mae: 0.2119\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1473 - val_loss: 0.0811 - val_mae: 0.2202\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1487 - val_loss: 0.0802 - val_mae: 0.2104\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1477 - val_loss: 0.0783 - val_mae: 0.2094\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1470 - val_loss: 0.0834 - val_mae: 0.2112\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1448 - val_loss: 0.0787 - val_mae: 0.2089\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1465 - val_loss: 0.0835 - val_mae: 0.2106\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1497 - val_loss: 0.0792 - val_mae: 0.2066\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1462 - val_loss: 0.0793 - val_mae: 0.2054\n",
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1464 - val_loss: 0.0788 - val_mae: 0.2127\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0331 - mae: 0.1506 - val_loss: 0.0787 - val_mae: 0.2128\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0306 - mae: 0.1447 - val_loss: 0.0807 - val_mae: 0.2083\n",
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1465 - val_loss: 0.0807 - val_mae: 0.2162\n",
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1429 - val_loss: 0.0839 - val_mae: 0.2273\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1478 - val_loss: 0.0797 - val_mae: 0.2088\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1479 - val_loss: 0.0796 - val_mae: 0.2099\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1439 - val_loss: 0.0818 - val_mae: 0.2186\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1496 - val_loss: 0.0790 - val_mae: 0.2113\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1443 - val_loss: 0.0797 - val_mae: 0.2148\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1493 - val_loss: 0.0791 - val_mae: 0.2146\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1428 - val_loss: 0.0790 - val_mae: 0.2065\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1467 - val_loss: 0.0797 - val_mae: 0.2080\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1489 - val_loss: 0.0811 - val_mae: 0.2065\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1477 - val_loss: 0.0786 - val_mae: 0.2077\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1452 - val_loss: 0.0793 - val_mae: 0.2152\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1506 - val_loss: 0.0800 - val_mae: 0.2088\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0301 - mae: 0.1439 - val_loss: 0.0819 - val_mae: 0.2086\n",
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0319 - mae: 0.1454 - val_loss: 0.0787 - val_mae: 0.2115\n",
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0311 - mae: 0.1439 - val_loss: 0.0790 - val_mae: 0.2142\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1455 - val_loss: 0.0804 - val_mae: 0.2182\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1456 - val_loss: 0.0788 - val_mae: 0.2135\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1439 - val_loss: 0.0778 - val_mae: 0.2103\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1463 - val_loss: 0.0785 - val_mae: 0.2101\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1449 - val_loss: 0.0801 - val_mae: 0.2084\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1436 - val_loss: 0.0782 - val_mae: 0.2091\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1475 - val_loss: 0.0783 - val_mae: 0.2130\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1501 - val_loss: 0.0778 - val_mae: 0.2079\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1462 - val_loss: 0.0788 - val_mae: 0.2135\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1490 - val_loss: 0.0778 - val_mae: 0.2072\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1472 - val_loss: 0.0778 - val_mae: 0.2106\n",
      "Epoch 186/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1453 - val_loss: 0.0798 - val_mae: 0.2068\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1436 - val_loss: 0.0790 - val_mae: 0.2044\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1459 - val_loss: 0.0808 - val_mae: 0.2073\n",
      "Epoch 189/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1473 - val_loss: 0.0788 - val_mae: 0.2093\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1460 - val_loss: 0.0788 - val_mae: 0.2074\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1456 - val_loss: 0.0791 - val_mae: 0.2134\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1455 - val_loss: 0.0787 - val_mae: 0.2048\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1462 - val_loss: 0.0807 - val_mae: 0.2087\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1461 - val_loss: 0.0772 - val_mae: 0.2071\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1448 - val_loss: 0.0787 - val_mae: 0.2054\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1487 - val_loss: 0.0772 - val_mae: 0.2129\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1478 - val_loss: 0.0784 - val_mae: 0.2065\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1472 - val_loss: 0.0783 - val_mae: 0.2086\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1449 - val_loss: 0.0784 - val_mae: 0.2087\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1435 - val_loss: 0.0766 - val_mae: 0.2077\n",
      "Epoch 201/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1452 - val_loss: 0.0764 - val_mae: 0.2100\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1483 - val_loss: 0.0783 - val_mae: 0.2082\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1445 - val_loss: 0.0795 - val_mae: 0.2051\n",
      "Epoch 204/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1443 - val_loss: 0.0785 - val_mae: 0.2092\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1458 - val_loss: 0.0777 - val_mae: 0.2084\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1468 - val_loss: 0.0793 - val_mae: 0.2062\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1439 - val_loss: 0.0768 - val_mae: 0.2108\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1459 - val_loss: 0.0769 - val_mae: 0.2079\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1450 - val_loss: 0.0765 - val_mae: 0.2125\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1419 - val_loss: 0.0780 - val_mae: 0.2037\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1446 - val_loss: 0.0780 - val_mae: 0.2115\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1455 - val_loss: 0.0776 - val_mae: 0.2096\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1386 - val_loss: 0.0809 - val_mae: 0.2180\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1452 - val_loss: 0.0778 - val_mae: 0.2065\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1436 - val_loss: 0.0778 - val_mae: 0.2127\n",
      "Epoch 216/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1407 - val_loss: 0.0831 - val_mae: 0.2107\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1450 - val_loss: 0.0789 - val_mae: 0.2082\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1468 - val_loss: 0.0800 - val_mae: 0.2059\n",
      "Epoch 219/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1459 - val_loss: 0.0798 - val_mae: 0.2060\n",
      "Epoch 220/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1433 - val_loss: 0.0773 - val_mae: 0.2064\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1433 - val_loss: 0.0791 - val_mae: 0.2149\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1407 - val_loss: 0.0788 - val_mae: 0.2056\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1450 - val_loss: 0.0782 - val_mae: 0.2149\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1446 - val_loss: 0.0776 - val_mae: 0.2076\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0305 - mae: 0.1462 - val_loss: 0.0793 - val_mae: 0.2092\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1429 - val_loss: 0.0792 - val_mae: 0.2063\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0310 - mae: 0.1454 - val_loss: 0.0782 - val_mae: 0.2099\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1445 - val_loss: 0.0769 - val_mae: 0.2077\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1462 - val_loss: 0.0775 - val_mae: 0.2083\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1433 - val_loss: 0.0775 - val_mae: 0.2089\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1420 - val_loss: 0.0785 - val_mae: 0.2158\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1446 - val_loss: 0.0776 - val_mae: 0.2114\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1439 - val_loss: 0.0773 - val_mae: 0.2064\n",
      "Epoch 234/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1420 - val_loss: 0.0767 - val_mae: 0.2124\n",
      "Epoch 235/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1446 - val_loss: 0.0786 - val_mae: 0.2042\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1464 - val_loss: 0.0792 - val_mae: 0.2037\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1473 - val_loss: 0.0781 - val_mae: 0.2083\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1462 - val_loss: 0.0783 - val_mae: 0.2046\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1415 - val_loss: 0.0783 - val_mae: 0.2049\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1448 - val_loss: 0.0790 - val_mae: 0.2116\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1442 - val_loss: 0.0791 - val_mae: 0.2037\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1430 - val_loss: 0.0784 - val_mae: 0.2087\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1437 - val_loss: 0.0787 - val_mae: 0.2089\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1430 - val_loss: 0.0786 - val_mae: 0.2114\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1429 - val_loss: 0.0773 - val_mae: 0.2107\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1419 - val_loss: 0.0767 - val_mae: 0.2129\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1435 - val_loss: 0.0775 - val_mae: 0.2114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1427 - val_loss: 0.0773 - val_mae: 0.2065\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1451 - val_loss: 0.0778 - val_mae: 0.2137\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1445 - val_loss: 0.0788 - val_mae: 0.2101\n",
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1398 - val_loss: 0.0811 - val_mae: 0.2221\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1418 - val_loss: 0.0779 - val_mae: 0.2119\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1433 - val_loss: 0.0779 - val_mae: 0.2051\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1419 - val_loss: 0.0784 - val_mae: 0.2104\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1433 - val_loss: 0.0780 - val_mae: 0.2065\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1415 - val_loss: 0.0772 - val_mae: 0.2093\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1445 - val_loss: 0.0797 - val_mae: 0.2060\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1407 - val_loss: 0.0797 - val_mae: 0.2143\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1445 - val_loss: 0.0780 - val_mae: 0.2054\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1450 - val_loss: 0.0777 - val_mae: 0.2090\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1431 - val_loss: 0.0791 - val_mae: 0.2070\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1429 - val_loss: 0.0769 - val_mae: 0.2069\n",
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1412 - val_loss: 0.0792 - val_mae: 0.2159\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1428 - val_loss: 0.0803 - val_mae: 0.2078\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1419 - val_loss: 0.0773 - val_mae: 0.2109\n",
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1450 - val_loss: 0.0767 - val_mae: 0.2097\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1401 - val_loss: 0.0776 - val_mae: 0.2058\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1438 - val_loss: 0.0788 - val_mae: 0.2080\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1425 - val_loss: 0.0766 - val_mae: 0.2069\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1436 - val_loss: 0.0790 - val_mae: 0.2076\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1454 - val_loss: 0.0773 - val_mae: 0.2096\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1457 - val_loss: 0.0801 - val_mae: 0.2039\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1440 - val_loss: 0.0788 - val_mae: 0.2073\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1415 - val_loss: 0.0775 - val_mae: 0.2048\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1435 - val_loss: 0.0770 - val_mae: 0.2084\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1429 - val_loss: 0.0765 - val_mae: 0.2074\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1428 - val_loss: 0.0767 - val_mae: 0.2102\n",
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1419 - val_loss: 0.0767 - val_mae: 0.2098\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1427 - val_loss: 0.0754 - val_mae: 0.2023\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1412 - val_loss: 0.0760 - val_mae: 0.2056\n",
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1435 - val_loss: 0.0775 - val_mae: 0.2046\n",
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1393 - val_loss: 0.0765 - val_mae: 0.2064\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1432 - val_loss: 0.0767 - val_mae: 0.2107\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1451 - val_loss: 0.0759 - val_mae: 0.2073\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1399 - val_loss: 0.0785 - val_mae: 0.2116\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1445 - val_loss: 0.0762 - val_mae: 0.2084\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1396 - val_loss: 0.0780 - val_mae: 0.2074\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1456 - val_loss: 0.0774 - val_mae: 0.2080\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1431 - val_loss: 0.0775 - val_mae: 0.2133\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1430 - val_loss: 0.0775 - val_mae: 0.2038\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1369 - val_loss: 0.0797 - val_mae: 0.2208\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1411 - val_loss: 0.0780 - val_mae: 0.2081\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1402 - val_loss: 0.0789 - val_mae: 0.2046\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1447 - val_loss: 0.0774 - val_mae: 0.2067\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1371 - val_loss: 0.0774 - val_mae: 0.2108\n",
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1421 - val_loss: 0.0772 - val_mae: 0.2091\n",
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0303 - mae: 0.1436 - val_loss: 0.0764 - val_mae: 0.2077\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1431 - val_loss: 0.0773 - val_mae: 0.2103\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0284 - mae: 0.1372 - val_loss: 0.0809 - val_mae: 0.2041\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0299 - mae: 0.1417 - val_loss: 0.0778 - val_mae: 0.2097\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0307 - mae: 0.1409 - val_loss: 0.0772 - val_mae: 0.2046\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0297 - mae: 0.1428 - val_loss: 0.0766 - val_mae: 0.2052\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0301 - mae: 0.1428 - val_loss: 0.0757 - val_mae: 0.2087\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0300 - mae: 0.1432 - val_loss: 0.0764 - val_mae: 0.2068\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1410 - val_loss: 0.0757 - val_mae: 0.2030\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0303 - mae: 0.1424 - val_loss: 0.0763 - val_mae: 0.2040\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0300 - mae: 0.1433 - val_loss: 0.0785 - val_mae: 0.2029\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0302 - mae: 0.1405 - val_loss: 0.0768 - val_mae: 0.2059\n",
      "Epoch 309/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1428 - val_loss: 0.0784 - val_mae: 0.2065\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0295 - mae: 0.1411 - val_loss: 0.0802 - val_mae: 0.2031\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0284 - mae: 0.1361 - val_loss: 0.0779 - val_mae: 0.2168\n",
      "Epoch 312/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0311 - mae: 0.1430 - val_loss: 0.0776 - val_mae: 0.2047\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0305 - mae: 0.1397 - val_loss: 0.0768 - val_mae: 0.2037\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - mae: 0.1426 - val_loss: 0.0782 - val_mae: 0.2066\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1398 - val_loss: 0.0773 - val_mae: 0.2041\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1435 - val_loss: 0.0785 - val_mae: 0.2019\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0288 - mae: 0.1362 - val_loss: 0.0755 - val_mae: 0.2096\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0301 - mae: 0.1426 - val_loss: 0.0752 - val_mae: 0.2050\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0304 - mae: 0.1416 - val_loss: 0.0757 - val_mae: 0.2037\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1400 - val_loss: 0.0756 - val_mae: 0.2035\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1372 - val_loss: 0.0816 - val_mae: 0.2018\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1405 - val_loss: 0.0781 - val_mae: 0.2080\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0296 - mae: 0.1438 - val_loss: 0.0754 - val_mae: 0.2005\n",
      "Epoch 324/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1413 - val_loss: 0.0751 - val_mae: 0.2076\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1435 - val_loss: 0.0757 - val_mae: 0.2046\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1419 - val_loss: 0.0779 - val_mae: 0.1991\n",
      "Epoch 327/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1398 - val_loss: 0.0764 - val_mae: 0.2051\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - mae: 0.1409 - val_loss: 0.0755 - val_mae: 0.2036\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1391 - val_loss: 0.0759 - val_mae: 0.2091\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1399 - val_loss: 0.0778 - val_mae: 0.2025\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1393 - val_loss: 0.0749 - val_mae: 0.2065\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1434 - val_loss: 0.0759 - val_mae: 0.2036\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1382 - val_loss: 0.0751 - val_mae: 0.2096\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1420 - val_loss: 0.0774 - val_mae: 0.1993\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1390 - val_loss: 0.0768 - val_mae: 0.2044\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1431 - val_loss: 0.0749 - val_mae: 0.2047\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1364 - val_loss: 0.0803 - val_mae: 0.2111\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1386 - val_loss: 0.0765 - val_mae: 0.2119\n",
      "Epoch 339/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1388 - val_loss: 0.0770 - val_mae: 0.2103\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1431 - val_loss: 0.0757 - val_mae: 0.2069\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0310 - mae: 0.1446 - val_loss: 0.0756 - val_mae: 0.2020\n",
      "Epoch 342/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1410 - val_loss: 0.0750 - val_mae: 0.2034\n",
      "Epoch 343/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1398 - val_loss: 0.0749 - val_mae: 0.2043\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0297 - mae: 0.1404 - val_loss: 0.0793 - val_mae: 0.2112\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1369 - val_loss: 0.0777 - val_mae: 0.2051\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1403 - val_loss: 0.0743 - val_mae: 0.2036\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0305 - mae: 0.1418 - val_loss: 0.0765 - val_mae: 0.2020\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1371 - val_loss: 0.0746 - val_mae: 0.2034\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1385 - val_loss: 0.0739 - val_mae: 0.2058\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1427 - val_loss: 0.0741 - val_mae: 0.2083\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1388 - val_loss: 0.0738 - val_mae: 0.2061\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1399 - val_loss: 0.0756 - val_mae: 0.2078\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1381 - val_loss: 0.0748 - val_mae: 0.2039\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1397 - val_loss: 0.0764 - val_mae: 0.2058\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1407 - val_loss: 0.0751 - val_mae: 0.2073\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1398 - val_loss: 0.0755 - val_mae: 0.2048\n",
      "Epoch 357/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1428 - val_loss: 0.0754 - val_mae: 0.2021\n",
      "Epoch 358/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1369 - val_loss: 0.0746 - val_mae: 0.2027\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1411 - val_loss: 0.0752 - val_mae: 0.2082\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1389 - val_loss: 0.0802 - val_mae: 0.1997\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1369 - val_loss: 0.0769 - val_mae: 0.2005\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1398 - val_loss: 0.0774 - val_mae: 0.2000\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1395 - val_loss: 0.0752 - val_mae: 0.1976\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1392 - val_loss: 0.0746 - val_mae: 0.2016\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1375 - val_loss: 0.0773 - val_mae: 0.2119\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1391 - val_loss: 0.0743 - val_mae: 0.2002\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1399 - val_loss: 0.0766 - val_mae: 0.2012\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1376 - val_loss: 0.0777 - val_mae: 0.2046\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0289 - mae: 0.1372 - val_loss: 0.0743 - val_mae: 0.2019\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0293 - mae: 0.1395 - val_loss: 0.0763 - val_mae: 0.2080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0289 - mae: 0.1392 - val_loss: 0.0754 - val_mae: 0.2112\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0303 - mae: 0.1416 - val_loss: 0.0739 - val_mae: 0.2060\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1375 - val_loss: 0.0740 - val_mae: 0.1989\n",
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1376 - val_loss: 0.0747 - val_mae: 0.2084\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0284 - mae: 0.1363 - val_loss: 0.0765 - val_mae: 0.2029\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1400 - val_loss: 0.0749 - val_mae: 0.2022\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0297 - mae: 0.1398 - val_loss: 0.0738 - val_mae: 0.2045\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1363 - val_loss: 0.0746 - val_mae: 0.1988\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1353 - val_loss: 0.0749 - val_mae: 0.2004\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1388 - val_loss: 0.0741 - val_mae: 0.2010\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1424 - val_loss: 0.0745 - val_mae: 0.1985\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1368 - val_loss: 0.0740 - val_mae: 0.1989\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1359 - val_loss: 0.0747 - val_mae: 0.2027\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1383 - val_loss: 0.0746 - val_mae: 0.1999\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1347 - val_loss: 0.0736 - val_mae: 0.2037\n",
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1381 - val_loss: 0.0761 - val_mae: 0.1997\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0301 - mae: 0.1407 - val_loss: 0.0771 - val_mae: 0.2013\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1395 - val_loss: 0.0755 - val_mae: 0.2008\n",
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1331 - val_loss: 0.0748 - val_mae: 0.2096\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1360 - val_loss: 0.0739 - val_mae: 0.2020\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1363 - val_loss: 0.0751 - val_mae: 0.1981\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1383 - val_loss: 0.0741 - val_mae: 0.1972\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1351 - val_loss: 0.0728 - val_mae: 0.2028\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1349 - val_loss: 0.0746 - val_mae: 0.2002\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1375 - val_loss: 0.0741 - val_mae: 0.2048\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1340 - val_loss: 0.0746 - val_mae: 0.2046\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1381 - val_loss: 0.0757 - val_mae: 0.2005\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1408 - val_loss: 0.0762 - val_mae: 0.1973\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1370 - val_loss: 0.0776 - val_mae: 0.2072\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1396 - val_loss: 0.0756 - val_mae: 0.2088\n",
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1368 - val_loss: 0.0754 - val_mae: 0.1976\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1352 - val_loss: 0.0733 - val_mae: 0.1992\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1378 - val_loss: 0.0746 - val_mae: 0.1998\n",
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1369 - val_loss: 0.0760 - val_mae: 0.2032\n",
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1363 - val_loss: 0.0738 - val_mae: 0.1992\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1378 - val_loss: 0.0761 - val_mae: 0.1958\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1345 - val_loss: 0.0750 - val_mae: 0.2024\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1363 - val_loss: 0.0737 - val_mae: 0.1995\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1378 - val_loss: 0.0742 - val_mae: 0.2024\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1314 - val_loss: 0.0748 - val_mae: 0.2082\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1417 - val_loss: 0.0742 - val_mae: 0.2008\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1334 - val_loss: 0.0764 - val_mae: 0.1973\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1338 - val_loss: 0.0745 - val_mae: 0.1984\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1360 - val_loss: 0.0752 - val_mae: 0.1972\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1347 - val_loss: 0.0741 - val_mae: 0.1977\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1379 - val_loss: 0.0767 - val_mae: 0.1972\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1325 - val_loss: 0.0736 - val_mae: 0.2047\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1336 - val_loss: 0.0756 - val_mae: 0.2026\n",
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1387 - val_loss: 0.0775 - val_mae: 0.2034\n",
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1359 - val_loss: 0.0765 - val_mae: 0.2011\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1364 - val_loss: 0.0748 - val_mae: 0.2035\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1387 - val_loss: 0.0733 - val_mae: 0.2019\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1359 - val_loss: 0.0742 - val_mae: 0.2050\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1357 - val_loss: 0.0748 - val_mae: 0.2077\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1371 - val_loss: 0.0735 - val_mae: 0.2015\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1393 - val_loss: 0.0747 - val_mae: 0.1974\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1352 - val_loss: 0.0795 - val_mae: 0.2025\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0295 - mae: 0.1381 - val_loss: 0.0756 - val_mae: 0.1977\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0284 - mae: 0.1345 - val_loss: 0.0759 - val_mae: 0.1970\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1332 - val_loss: 0.0772 - val_mae: 0.1995\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1322 - val_loss: 0.0752 - val_mae: 0.2034\n",
      "Epoch 432/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1366 - val_loss: 0.0743 - val_mae: 0.1976\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1338 - val_loss: 0.0755 - val_mae: 0.2008\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1305 - val_loss: 0.0761 - val_mae: 0.2095\n",
      "Epoch 435/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1334 - val_loss: 0.0826 - val_mae: 0.1998\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1335 - val_loss: 0.0755 - val_mae: 0.2057\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1347 - val_loss: 0.0748 - val_mae: 0.2031\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1326 - val_loss: 0.0751 - val_mae: 0.1976\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1372 - val_loss: 0.0742 - val_mae: 0.2026\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1355 - val_loss: 0.0752 - val_mae: 0.1994\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1354 - val_loss: 0.0777 - val_mae: 0.2003\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1346 - val_loss: 0.0758 - val_mae: 0.2028\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1345 - val_loss: 0.0742 - val_mae: 0.2050\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1346 - val_loss: 0.0765 - val_mae: 0.2059\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1328 - val_loss: 0.0748 - val_mae: 0.2028\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1353 - val_loss: 0.0741 - val_mae: 0.1981\n",
      "Epoch 447/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1338 - val_loss: 0.0736 - val_mae: 0.2029\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1363 - val_loss: 0.0747 - val_mae: 0.2034\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1346 - val_loss: 0.0746 - val_mae: 0.2018\n",
      "Epoch 450/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1335 - val_loss: 0.0755 - val_mae: 0.2033\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1344 - val_loss: 0.0758 - val_mae: 0.1999\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1329 - val_loss: 0.0744 - val_mae: 0.2030\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1353 - val_loss: 0.0753 - val_mae: 0.1991\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1315 - val_loss: 0.0768 - val_mae: 0.2008\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1351 - val_loss: 0.0730 - val_mae: 0.1985\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1364 - val_loss: 0.0746 - val_mae: 0.1987\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1340 - val_loss: 0.0754 - val_mae: 0.2015\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1320 - val_loss: 0.0758 - val_mae: 0.2113\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1340 - val_loss: 0.0758 - val_mae: 0.1989\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1304 - val_loss: 0.0762 - val_mae: 0.2124\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1330 - val_loss: 0.0766 - val_mae: 0.1992\n",
      "Epoch 462/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1353 - val_loss: 0.0816 - val_mae: 0.1997\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1277 - val_loss: 0.0755 - val_mae: 0.2045\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1332 - val_loss: 0.0747 - val_mae: 0.2051\n",
      "Epoch 465/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1345 - val_loss: 0.0757 - val_mae: 0.2060\n",
      "Epoch 466/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1334 - val_loss: 0.0764 - val_mae: 0.2004\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1345 - val_loss: 0.0741 - val_mae: 0.2018\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1333 - val_loss: 0.0796 - val_mae: 0.1985\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1311 - val_loss: 0.0727 - val_mae: 0.1970\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1360 - val_loss: 0.0753 - val_mae: 0.2030\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1349 - val_loss: 0.0752 - val_mae: 0.2011\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1331 - val_loss: 0.0764 - val_mae: 0.2067\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0284 - mae: 0.1333 - val_loss: 0.0750 - val_mae: 0.2002\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0284 - mae: 0.1340 - val_loss: 0.0748 - val_mae: 0.2006\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1336 - val_loss: 0.0752 - val_mae: 0.1994\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1335 - val_loss: 0.0736 - val_mae: 0.2000\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1305 - val_loss: 0.0796 - val_mae: 0.2058\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1332 - val_loss: 0.0754 - val_mae: 0.2034\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1318 - val_loss: 0.0767 - val_mae: 0.2054\n",
      "Epoch 480/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1324 - val_loss: 0.0761 - val_mae: 0.2041\n",
      "Epoch 481/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1338 - val_loss: 0.0747 - val_mae: 0.2021\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1308 - val_loss: 0.0752 - val_mae: 0.2049\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1300 - val_loss: 0.0768 - val_mae: 0.2059\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1352 - val_loss: 0.0745 - val_mae: 0.2007\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1374 - val_loss: 0.0749 - val_mae: 0.2019\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1331 - val_loss: 0.0754 - val_mae: 0.2059\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1349 - val_loss: 0.0763 - val_mae: 0.2064\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1304 - val_loss: 0.0761 - val_mae: 0.1991\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1383 - val_loss: 0.0737 - val_mae: 0.2025\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1331 - val_loss: 0.0731 - val_mae: 0.2018\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1286 - val_loss: 0.0733 - val_mae: 0.2030\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1338 - val_loss: 0.0739 - val_mae: 0.1990\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1307 - val_loss: 0.0740 - val_mae: 0.2039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1288 - val_loss: 0.0741 - val_mae: 0.2050\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.1352 - val_loss: 0.0755 - val_mae: 0.2056\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1325 - val_loss: 0.0745 - val_mae: 0.2045\n",
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1294 - val_loss: 0.0732 - val_mae: 0.2030\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1347 - val_loss: 0.0758 - val_mae: 0.2093\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1327 - val_loss: 0.0743 - val_mae: 0.2057\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1347 - val_loss: 0.0745 - val_mae: 0.2005\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1323 - val_loss: 0.0742 - val_mae: 0.2038\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1323 - val_loss: 0.0749 - val_mae: 0.2017\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1336 - val_loss: 0.0750 - val_mae: 0.2040\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1330 - val_loss: 0.0772 - val_mae: 0.2010\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1346 - val_loss: 0.0735 - val_mae: 0.2025\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1318 - val_loss: 0.0767 - val_mae: 0.1987\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1318 - val_loss: 0.0746 - val_mae: 0.2018\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1354 - val_loss: 0.0777 - val_mae: 0.1992\n",
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1348 - val_loss: 0.0760 - val_mae: 0.2066\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1336 - val_loss: 0.0766 - val_mae: 0.2028\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1316 - val_loss: 0.0759 - val_mae: 0.2020\n",
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1349 - val_loss: 0.0753 - val_mae: 0.2019\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1337 - val_loss: 0.0737 - val_mae: 0.2029\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1302 - val_loss: 0.0742 - val_mae: 0.2039\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1330 - val_loss: 0.0736 - val_mae: 0.2028\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1336 - val_loss: 0.0736 - val_mae: 0.2041\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1332 - val_loss: 0.0755 - val_mae: 0.2059\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1319 - val_loss: 0.0769 - val_mae: 0.2007\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1302 - val_loss: 0.0824 - val_mae: 0.2003\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1348 - val_loss: 0.0747 - val_mae: 0.2007\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1329 - val_loss: 0.0746 - val_mae: 0.2036\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1340 - val_loss: 0.0757 - val_mae: 0.2031\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1310 - val_loss: 0.0758 - val_mae: 0.2012\n",
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1319 - val_loss: 0.0764 - val_mae: 0.2040\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1313 - val_loss: 0.0743 - val_mae: 0.2048\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1340 - val_loss: 0.0755 - val_mae: 0.2036\n",
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1297 - val_loss: 0.0757 - val_mae: 0.2038\n",
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1327 - val_loss: 0.0745 - val_mae: 0.2074\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1326 - val_loss: 0.0768 - val_mae: 0.2039\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1317 - val_loss: 0.0759 - val_mae: 0.2024\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1349 - val_loss: 0.0771 - val_mae: 0.2019\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1324 - val_loss: 0.0749 - val_mae: 0.2010\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1350 - val_loss: 0.0765 - val_mae: 0.2029\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1316 - val_loss: 0.0744 - val_mae: 0.2044\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1314 - val_loss: 0.0747 - val_mae: 0.2026\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1319 - val_loss: 0.0731 - val_mae: 0.2020\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1280 - val_loss: 0.0769 - val_mae: 0.1980\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1304 - val_loss: 0.0738 - val_mae: 0.2011\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1340 - val_loss: 0.0738 - val_mae: 0.2046\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1366 - val_loss: 0.0760 - val_mae: 0.2033\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1279 - val_loss: 0.0744 - val_mae: 0.2021\n",
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1315 - val_loss: 0.0746 - val_mae: 0.2040\n",
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1330 - val_loss: 0.0749 - val_mae: 0.2032\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1307 - val_loss: 0.0737 - val_mae: 0.2034\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1314 - val_loss: 0.0770 - val_mae: 0.2052\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1331 - val_loss: 0.0740 - val_mae: 0.2039\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1350 - val_loss: 0.0730 - val_mae: 0.2029\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - mae: 0.1300 - val_loss: 0.0735 - val_mae: 0.2030\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1306 - val_loss: 0.0739 - val_mae: 0.2022\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1340 - val_loss: 0.0749 - val_mae: 0.2030\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1303 - val_loss: 0.0746 - val_mae: 0.2031\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1362 - val_loss: 0.0741 - val_mae: 0.2037\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1320 - val_loss: 0.0747 - val_mae: 0.2026\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1291 - val_loss: 0.0760 - val_mae: 0.2015\n",
      "Epoch 555/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1284 - val_loss: 0.0737 - val_mae: 0.2019\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1315 - val_loss: 0.0760 - val_mae: 0.2056\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1288 - val_loss: 0.0738 - val_mae: 0.2036\n",
      "Epoch 558/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0277 - mae: 0.1316 - val_loss: 0.0757 - val_mae: 0.2015\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1318 - val_loss: 0.0800 - val_mae: 0.2050\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1315 - val_loss: 0.0733 - val_mae: 0.1998\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1319 - val_loss: 0.0764 - val_mae: 0.1974\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - mae: 0.1293 - val_loss: 0.0763 - val_mae: 0.2051\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1338 - val_loss: 0.0749 - val_mae: 0.1999\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1317 - val_loss: 0.0750 - val_mae: 0.2066\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1315 - val_loss: 0.0752 - val_mae: 0.2015\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1312 - val_loss: 0.0732 - val_mae: 0.2052\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1317 - val_loss: 0.0756 - val_mae: 0.2009\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1302 - val_loss: 0.0744 - val_mae: 0.2036\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1344 - val_loss: 0.0765 - val_mae: 0.2031\n",
      "Epoch 570/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1304 - val_loss: 0.0753 - val_mae: 0.2026\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1336 - val_loss: 0.0757 - val_mae: 0.2046\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1293 - val_loss: 0.0784 - val_mae: 0.2007\n",
      "Epoch 573/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1297 - val_loss: 0.0736 - val_mae: 0.2044\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1304 - val_loss: 0.0739 - val_mae: 0.2029\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1342 - val_loss: 0.0748 - val_mae: 0.2043\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1309 - val_loss: 0.0753 - val_mae: 0.2032\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0280 - mae: 0.1325 - val_loss: 0.0746 - val_mae: 0.2044\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1293 - val_loss: 0.0753 - val_mae: 0.2067\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1299 - val_loss: 0.0772 - val_mae: 0.2039\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1332 - val_loss: 0.0751 - val_mae: 0.2042\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1328 - val_loss: 0.0740 - val_mae: 0.2066\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1339 - val_loss: 0.0753 - val_mae: 0.2040\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1307 - val_loss: 0.0786 - val_mae: 0.2052\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0279 - mae: 0.1320 - val_loss: 0.0755 - val_mae: 0.2049\n",
      "Epoch 585/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1312 - val_loss: 0.0748 - val_mae: 0.2064\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1278 - val_loss: 0.0747 - val_mae: 0.2034\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0284 - mae: 0.1313 - val_loss: 0.0740 - val_mae: 0.2047\n",
      "Epoch 588/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1346 - val_loss: 0.0765 - val_mae: 0.2048\n",
      "Epoch 589/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1326 - val_loss: 0.0769 - val_mae: 0.2049\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1317 - val_loss: 0.0774 - val_mae: 0.2017\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1330 - val_loss: 0.0741 - val_mae: 0.2051\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1307 - val_loss: 0.0752 - val_mae: 0.2070\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1328 - val_loss: 0.0748 - val_mae: 0.2033\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1290 - val_loss: 0.0772 - val_mae: 0.2021\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1294 - val_loss: 0.0757 - val_mae: 0.2084\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1288 - val_loss: 0.0754 - val_mae: 0.2043\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1289 - val_loss: 0.0777 - val_mae: 0.1997\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1291 - val_loss: 0.0767 - val_mae: 0.2032\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1332 - val_loss: 0.0730 - val_mae: 0.2010\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1302 - val_loss: 0.0747 - val_mae: 0.2057\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "3\n",
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.7016 - mae: 0.5952 - val_loss: 0.5939 - val_mae: 0.5331\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2984 - mae: 0.4141 - val_loss: 0.3304 - val_mae: 0.4000\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2206 - mae: 0.3585 - val_loss: 0.2503 - val_mae: 0.3499\n",
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2028 - mae: 0.3444 - val_loss: 0.2317 - val_mae: 0.3565\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1834 - mae: 0.3269 - val_loss: 0.2556 - val_mae: 0.3647\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1718 - mae: 0.3219 - val_loss: 0.2221 - val_mae: 0.3350\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1514 - mae: 0.3013 - val_loss: 0.2180 - val_mae: 0.3373\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1390 - mae: 0.2833 - val_loss: 0.2003 - val_mae: 0.3058\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1250 - mae: 0.2720 - val_loss: 0.1896 - val_mae: 0.2969\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1142 - mae: 0.2593 - val_loss: 0.1761 - val_mae: 0.3010\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1029 - mae: 0.2444 - val_loss: 0.1804 - val_mae: 0.2887\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0958 - mae: 0.2316 - val_loss: 0.1522 - val_mae: 0.2788\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0911 - mae: 0.2314 - val_loss: 0.1589 - val_mae: 0.2758\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0844 - mae: 0.2184 - val_loss: 0.1408 - val_mae: 0.2593\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0803 - mae: 0.2152 - val_loss: 0.1419 - val_mae: 0.2596\n",
      "Epoch 16/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0797 - mae: 0.2123 - val_loss: 0.1407 - val_mae: 0.2568\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0747 - mae: 0.2128 - val_loss: 0.1347 - val_mae: 0.2528\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0718 - mae: 0.2040 - val_loss: 0.1281 - val_mae: 0.2480\n",
      "Epoch 19/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0731 - mae: 0.2071 - val_loss: 0.1229 - val_mae: 0.2457\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - mae: 0.2025 - val_loss: 0.1290 - val_mae: 0.2537\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0678 - mae: 0.2024 - val_loss: 0.1227 - val_mae: 0.2445\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - mae: 0.2038 - val_loss: 0.1199 - val_mae: 0.2421\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - mae: 0.1992 - val_loss: 0.1166 - val_mae: 0.2389\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0648 - mae: 0.1989 - val_loss: 0.1202 - val_mae: 0.2458\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0636 - mae: 0.1945 - val_loss: 0.1130 - val_mae: 0.2348\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0634 - mae: 0.1946 - val_loss: 0.1124 - val_mae: 0.2347\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0619 - mae: 0.1927 - val_loss: 0.1113 - val_mae: 0.2363\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0597 - mae: 0.1901 - val_loss: 0.1124 - val_mae: 0.2310\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0607 - mae: 0.1943 - val_loss: 0.1083 - val_mae: 0.2278\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0588 - mae: 0.1901 - val_loss: 0.1110 - val_mae: 0.2363\n",
      "Epoch 31/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0595 - mae: 0.1942 - val_loss: 0.1130 - val_mae: 0.2429\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0589 - mae: 0.1911 - val_loss: 0.1133 - val_mae: 0.2480\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0585 - mae: 0.1901 - val_loss: 0.1064 - val_mae: 0.2320\n",
      "Epoch 34/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - mae: 0.1824 - val_loss: 0.1059 - val_mae: 0.2314\n",
      "Epoch 35/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.1799 - val_loss: 0.1054 - val_mae: 0.2266\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - mae: 0.1882 - val_loss: 0.1025 - val_mae: 0.2291\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0538 - mae: 0.1823 - val_loss: 0.1072 - val_mae: 0.2420\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0542 - mae: 0.1831 - val_loss: 0.1040 - val_mae: 0.2343\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0523 - mae: 0.1836 - val_loss: 0.1021 - val_mae: 0.2301\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0512 - mae: 0.1801 - val_loss: 0.1023 - val_mae: 0.2344\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - mae: 0.1756 - val_loss: 0.0988 - val_mae: 0.2214\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - mae: 0.1769 - val_loss: 0.1034 - val_mae: 0.2380\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - mae: 0.1767 - val_loss: 0.1011 - val_mae: 0.2321\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1821 - val_loss: 0.0981 - val_mae: 0.2249\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0490 - mae: 0.1729 - val_loss: 0.1021 - val_mae: 0.2387\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0505 - mae: 0.1773 - val_loss: 0.0993 - val_mae: 0.2309\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.1761 - val_loss: 0.1047 - val_mae: 0.2484\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - mae: 0.1763 - val_loss: 0.0939 - val_mae: 0.2181\n",
      "Epoch 49/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0463 - mae: 0.1688 - val_loss: 0.0973 - val_mae: 0.2272\n",
      "Epoch 50/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0464 - mae: 0.1696 - val_loss: 0.0938 - val_mae: 0.2194\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0470 - mae: 0.1739 - val_loss: 0.0925 - val_mae: 0.2175\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1699 - val_loss: 0.0985 - val_mae: 0.2369\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1691 - val_loss: 0.0936 - val_mae: 0.2193\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1667 - val_loss: 0.0960 - val_mae: 0.2205\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1687 - val_loss: 0.0915 - val_mae: 0.2202\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0453 - mae: 0.1691 - val_loss: 0.0906 - val_mae: 0.2159\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.1652 - val_loss: 0.0912 - val_mae: 0.2134\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1723 - val_loss: 0.0892 - val_mae: 0.2170\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0434 - mae: 0.1659 - val_loss: 0.0922 - val_mae: 0.2213\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0434 - mae: 0.1631 - val_loss: 0.0886 - val_mae: 0.2144\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1710 - val_loss: 0.0900 - val_mae: 0.2189\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.1587 - val_loss: 0.0932 - val_mae: 0.2235\n",
      "Epoch 63/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.1641 - val_loss: 0.0880 - val_mae: 0.2195\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0418 - mae: 0.1620 - val_loss: 0.0892 - val_mae: 0.2170\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0422 - mae: 0.1607 - val_loss: 0.0878 - val_mae: 0.2200\n",
      "Epoch 66/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.1601 - val_loss: 0.0906 - val_mae: 0.2275\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 0.1693 - val_loss: 0.0875 - val_mae: 0.2148\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1575 - val_loss: 0.0967 - val_mae: 0.2318\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1698 - val_loss: 0.0880 - val_mae: 0.2210\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.1569 - val_loss: 0.0899 - val_mae: 0.2152\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0407 - mae: 0.1589 - val_loss: 0.0878 - val_mae: 0.2160\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1585 - val_loss: 0.0883 - val_mae: 0.2213\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0396 - mae: 0.1563 - val_loss: 0.0892 - val_mae: 0.2294\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1539 - val_loss: 0.0924 - val_mae: 0.2263\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1544 - val_loss: 0.0845 - val_mae: 0.2124\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0390 - mae: 0.1599 - val_loss: 0.0862 - val_mae: 0.2116\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1628 - val_loss: 0.0869 - val_mae: 0.2129\n",
      "Epoch 78/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.1564 - val_loss: 0.0844 - val_mae: 0.2117\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1566 - val_loss: 0.0884 - val_mae: 0.2162\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.1529 - val_loss: 0.0850 - val_mae: 0.2150\n",
      "Epoch 81/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1507 - val_loss: 0.0891 - val_mae: 0.2196\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1574 - val_loss: 0.0852 - val_mae: 0.2124\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0389 - mae: 0.1575 - val_loss: 0.0897 - val_mae: 0.2167\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0379 - mae: 0.1561 - val_loss: 0.0878 - val_mae: 0.2288\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1573 - val_loss: 0.0842 - val_mae: 0.2134\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1534 - val_loss: 0.0873 - val_mae: 0.2143\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0367 - mae: 0.1498 - val_loss: 0.0892 - val_mae: 0.2271\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0383 - mae: 0.1566 - val_loss: 0.0845 - val_mae: 0.2167\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0368 - mae: 0.1536 - val_loss: 0.0855 - val_mae: 0.2134\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1506 - val_loss: 0.0839 - val_mae: 0.2170\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0369 - mae: 0.1535 - val_loss: 0.0902 - val_mae: 0.2345\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1550 - val_loss: 0.0849 - val_mae: 0.2119\n",
      "Epoch 93/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1547 - val_loss: 0.0842 - val_mae: 0.2115\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0347 - mae: 0.1510 - val_loss: 0.0840 - val_mae: 0.2118\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0371 - mae: 0.1545 - val_loss: 0.0851 - val_mae: 0.2176\n",
      "Epoch 96/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - mae: 0.1464 - val_loss: 0.0857 - val_mae: 0.2163\n",
      "Epoch 97/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.1533 - val_loss: 0.0944 - val_mae: 0.2398\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1603 - val_loss: 0.0848 - val_mae: 0.2155\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1485 - val_loss: 0.0836 - val_mae: 0.2129\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1543 - val_loss: 0.0858 - val_mae: 0.2139\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0365 - mae: 0.1561 - val_loss: 0.0833 - val_mae: 0.2128\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0365 - mae: 0.1527 - val_loss: 0.0837 - val_mae: 0.2114\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1522 - val_loss: 0.0854 - val_mae: 0.2241\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1514 - val_loss: 0.0860 - val_mae: 0.2270\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1523 - val_loss: 0.0888 - val_mae: 0.2191\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1512 - val_loss: 0.0884 - val_mae: 0.2157\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1526 - val_loss: 0.0835 - val_mae: 0.2121\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0354 - mae: 0.1518 - val_loss: 0.0861 - val_mae: 0.2330\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1522 - val_loss: 0.0831 - val_mae: 0.2111\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.1466 - val_loss: 0.0836 - val_mae: 0.2134\n",
      "Epoch 111/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.1456 - val_loss: 0.0887 - val_mae: 0.2329\n",
      "Epoch 112/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0367 - mae: 0.1550 - val_loss: 0.0856 - val_mae: 0.2263\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1486 - val_loss: 0.0939 - val_mae: 0.2242\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0348 - mae: 0.1478 - val_loss: 0.0871 - val_mae: 0.2251\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0336 - mae: 0.1488 - val_loss: 0.0892 - val_mae: 0.2204\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0354 - mae: 0.1529 - val_loss: 0.0847 - val_mae: 0.2229\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0356 - mae: 0.1547 - val_loss: 0.0829 - val_mae: 0.2131\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.1524 - val_loss: 0.0845 - val_mae: 0.2200\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1440 - val_loss: 0.0847 - val_mae: 0.2154\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1493 - val_loss: 0.0873 - val_mae: 0.2200\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1528 - val_loss: 0.0850 - val_mae: 0.2261\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1491 - val_loss: 0.0876 - val_mae: 0.2285\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1484 - val_loss: 0.0865 - val_mae: 0.2148\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1471 - val_loss: 0.0863 - val_mae: 0.2214\n",
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1454 - val_loss: 0.0856 - val_mae: 0.2142\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1522 - val_loss: 0.0840 - val_mae: 0.2158\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0343 - mae: 0.1504 - val_loss: 0.0838 - val_mae: 0.2195\n",
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1465 - val_loss: 0.0878 - val_mae: 0.2237\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1549 - val_loss: 0.0834 - val_mae: 0.2128\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.1509 - val_loss: 0.0854 - val_mae: 0.2148\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1486 - val_loss: 0.0836 - val_mae: 0.2181\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1468 - val_loss: 0.0834 - val_mae: 0.2202\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1485 - val_loss: 0.0842 - val_mae: 0.2109\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1490 - val_loss: 0.0841 - val_mae: 0.2125\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1481 - val_loss: 0.0820 - val_mae: 0.2116\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1462 - val_loss: 0.0841 - val_mae: 0.2153\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0327 - mae: 0.1458 - val_loss: 0.0828 - val_mae: 0.2132\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.1492 - val_loss: 0.0894 - val_mae: 0.2386\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.1505 - val_loss: 0.0854 - val_mae: 0.2130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1460 - val_loss: 0.0895 - val_mae: 0.2325\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1441 - val_loss: 0.0882 - val_mae: 0.2229\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1472 - val_loss: 0.0854 - val_mae: 0.2304\n",
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1451 - val_loss: 0.0857 - val_mae: 0.2132\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.1442 - val_loss: 0.0837 - val_mae: 0.2143\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1401 - val_loss: 0.0920 - val_mae: 0.2304\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1420 - val_loss: 0.0845 - val_mae: 0.2204\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1417 - val_loss: 0.0852 - val_mae: 0.2196\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1472 - val_loss: 0.0840 - val_mae: 0.2125\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1505 - val_loss: 0.0856 - val_mae: 0.2189\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1474 - val_loss: 0.0928 - val_mae: 0.2354\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1459 - val_loss: 0.0849 - val_mae: 0.2312\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1482 - val_loss: 0.0836 - val_mae: 0.2117\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1448 - val_loss: 0.0869 - val_mae: 0.2324\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1490 - val_loss: 0.0842 - val_mae: 0.2117\n",
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1437 - val_loss: 0.0874 - val_mae: 0.2239\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1499 - val_loss: 0.0842 - val_mae: 0.2119\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1455 - val_loss: 0.0899 - val_mae: 0.2222\n",
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1432 - val_loss: 0.0841 - val_mae: 0.2218\n",
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1457 - val_loss: 0.0842 - val_mae: 0.2226\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1427 - val_loss: 0.0857 - val_mae: 0.2231\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1488 - val_loss: 0.0834 - val_mae: 0.2198\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1462 - val_loss: 0.0848 - val_mae: 0.2189\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1454 - val_loss: 0.0918 - val_mae: 0.2461\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1445 - val_loss: 0.0841 - val_mae: 0.2105\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1417 - val_loss: 0.0862 - val_mae: 0.2230\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1458 - val_loss: 0.0840 - val_mae: 0.2207\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1453 - val_loss: 0.0876 - val_mae: 0.2323\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1458 - val_loss: 0.0846 - val_mae: 0.2106\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1472 - val_loss: 0.0828 - val_mae: 0.2170\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1468 - val_loss: 0.0837 - val_mae: 0.2177\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1450 - val_loss: 0.0841 - val_mae: 0.2195\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1471 - val_loss: 0.0835 - val_mae: 0.2226\n",
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1460 - val_loss: 0.0855 - val_mae: 0.2128\n",
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1460 - val_loss: 0.0844 - val_mae: 0.2133\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1457 - val_loss: 0.0841 - val_mae: 0.2180\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1407 - val_loss: 0.0854 - val_mae: 0.2309\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1458 - val_loss: 0.0834 - val_mae: 0.2234\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1404 - val_loss: 0.0881 - val_mae: 0.2235\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1446 - val_loss: 0.0837 - val_mae: 0.2206\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1426 - val_loss: 0.0829 - val_mae: 0.2226\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1469 - val_loss: 0.0842 - val_mae: 0.2109\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1446 - val_loss: 0.0829 - val_mae: 0.2117\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1439 - val_loss: 0.0828 - val_mae: 0.2101\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1452 - val_loss: 0.0842 - val_mae: 0.2282\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1454 - val_loss: 0.0830 - val_mae: 0.2218\n",
      "Epoch 186/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1448 - val_loss: 0.0841 - val_mae: 0.2208\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1434 - val_loss: 0.0842 - val_mae: 0.2207\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1389 - val_loss: 0.0825 - val_mae: 0.2209\n",
      "Epoch 189/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1430 - val_loss: 0.0840 - val_mae: 0.2123\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1418 - val_loss: 0.0836 - val_mae: 0.2261\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1396 - val_loss: 0.0847 - val_mae: 0.2242\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1501 - val_loss: 0.0830 - val_mae: 0.2144\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1420 - val_loss: 0.0865 - val_mae: 0.2118\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1420 - val_loss: 0.0834 - val_mae: 0.2163\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1421 - val_loss: 0.0896 - val_mae: 0.2254\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1431 - val_loss: 0.0845 - val_mae: 0.2132\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1383 - val_loss: 0.0862 - val_mae: 0.2364\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1383 - val_loss: 0.0866 - val_mae: 0.2357\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1418 - val_loss: 0.0855 - val_mae: 0.2110\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1440 - val_loss: 0.0822 - val_mae: 0.2140\n",
      "Epoch 201/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1435 - val_loss: 0.0869 - val_mae: 0.2376\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1443 - val_loss: 0.0865 - val_mae: 0.2349\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1454 - val_loss: 0.0842 - val_mae: 0.2228\n",
      "Epoch 204/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1380 - val_loss: 0.0834 - val_mae: 0.2247\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1405 - val_loss: 0.0864 - val_mae: 0.2303\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1402 - val_loss: 0.0860 - val_mae: 0.2350\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1424 - val_loss: 0.0887 - val_mae: 0.2231\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1420 - val_loss: 0.0869 - val_mae: 0.2241\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1413 - val_loss: 0.0823 - val_mae: 0.2172\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1349 - val_loss: 0.0862 - val_mae: 0.2271\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1398 - val_loss: 0.0860 - val_mae: 0.2144\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0311 - mae: 0.1420 - val_loss: 0.0853 - val_mae: 0.2143\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1394 - val_loss: 0.0858 - val_mae: 0.2316\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1415 - val_loss: 0.0854 - val_mae: 0.2306\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1419 - val_loss: 0.0854 - val_mae: 0.2335\n",
      "Epoch 216/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1431 - val_loss: 0.0827 - val_mae: 0.2216\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1407 - val_loss: 0.0833 - val_mae: 0.2238\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1414 - val_loss: 0.0842 - val_mae: 0.2150\n",
      "Epoch 219/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1404 - val_loss: 0.0843 - val_mae: 0.2206\n",
      "Epoch 220/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1400 - val_loss: 0.0849 - val_mae: 0.2214\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1354 - val_loss: 0.0864 - val_mae: 0.2236\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1417 - val_loss: 0.0847 - val_mae: 0.2243\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1400 - val_loss: 0.0865 - val_mae: 0.2327\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1398 - val_loss: 0.0867 - val_mae: 0.2162\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1385 - val_loss: 0.0883 - val_mae: 0.2188\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1429 - val_loss: 0.0850 - val_mae: 0.2211\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1380 - val_loss: 0.0877 - val_mae: 0.2222\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1363 - val_loss: 0.0890 - val_mae: 0.2152\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1399 - val_loss: 0.0853 - val_mae: 0.2253\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1358 - val_loss: 0.0861 - val_mae: 0.2181\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - mae: 0.1434 - val_loss: 0.0843 - val_mae: 0.2196\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1405 - val_loss: 0.0858 - val_mae: 0.2163\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1351 - val_loss: 0.0861 - val_mae: 0.2160\n",
      "Epoch 234/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1417 - val_loss: 0.0862 - val_mae: 0.2259\n",
      "Epoch 235/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1415 - val_loss: 0.0878 - val_mae: 0.2233\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1418 - val_loss: 0.0848 - val_mae: 0.2195\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1411 - val_loss: 0.0865 - val_mae: 0.2302\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1419 - val_loss: 0.0843 - val_mae: 0.2208\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1428 - val_loss: 0.0847 - val_mae: 0.2227\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1389 - val_loss: 0.0849 - val_mae: 0.2194\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1348 - val_loss: 0.0874 - val_mae: 0.2264\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1345 - val_loss: 0.0864 - val_mae: 0.2177\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1370 - val_loss: 0.0860 - val_mae: 0.2223\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1403 - val_loss: 0.0859 - val_mae: 0.2198\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1422 - val_loss: 0.0870 - val_mae: 0.2293\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1393 - val_loss: 0.0868 - val_mae: 0.2218\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1388 - val_loss: 0.0865 - val_mae: 0.2240\n",
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1405 - val_loss: 0.0865 - val_mae: 0.2198\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1330 - val_loss: 0.0923 - val_mae: 0.2299\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1363 - val_loss: 0.0885 - val_mae: 0.2308\n",
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1353 - val_loss: 0.0885 - val_mae: 0.2351\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1358 - val_loss: 0.0869 - val_mae: 0.2345\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0300 - mae: 0.1396 - val_loss: 0.0853 - val_mae: 0.2298\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1377 - val_loss: 0.0852 - val_mae: 0.2228\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1401 - val_loss: 0.0894 - val_mae: 0.2294\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1388 - val_loss: 0.0913 - val_mae: 0.2366\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1410 - val_loss: 0.0864 - val_mae: 0.2216\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1329 - val_loss: 0.0879 - val_mae: 0.2380\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1402 - val_loss: 0.0889 - val_mae: 0.2387\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1407 - val_loss: 0.0871 - val_mae: 0.2312\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1405 - val_loss: 0.0873 - val_mae: 0.2307\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1371 - val_loss: 0.0876 - val_mae: 0.2179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1384 - val_loss: 0.0876 - val_mae: 0.2257\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1410 - val_loss: 0.0873 - val_mae: 0.2258\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1360 - val_loss: 0.0891 - val_mae: 0.2219\n",
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1327 - val_loss: 0.1028 - val_mae: 0.2498\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1440 - val_loss: 0.0880 - val_mae: 0.2253\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1388 - val_loss: 0.0892 - val_mae: 0.2358\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1392 - val_loss: 0.0864 - val_mae: 0.2231\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1377 - val_loss: 0.0868 - val_mae: 0.2209\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1372 - val_loss: 0.0891 - val_mae: 0.2364\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1370 - val_loss: 0.0918 - val_mae: 0.2161\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1388 - val_loss: 0.0872 - val_mae: 0.2279\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0303 - mae: 0.1419 - val_loss: 0.0869 - val_mae: 0.2284\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1336 - val_loss: 0.0860 - val_mae: 0.2239\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1374 - val_loss: 0.0879 - val_mae: 0.2209\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1370 - val_loss: 0.0895 - val_mae: 0.2332\n",
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1368 - val_loss: 0.0882 - val_mae: 0.2261\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1325 - val_loss: 0.0900 - val_mae: 0.2346\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1399 - val_loss: 0.0866 - val_mae: 0.2268\n",
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1396 - val_loss: 0.0884 - val_mae: 0.2317\n",
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1369 - val_loss: 0.0866 - val_mae: 0.2302\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1399 - val_loss: 0.0875 - val_mae: 0.2255\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1355 - val_loss: 0.0874 - val_mae: 0.2276\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1359 - val_loss: 0.0928 - val_mae: 0.2312\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1370 - val_loss: 0.0885 - val_mae: 0.2302\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1399 - val_loss: 0.0879 - val_mae: 0.2245\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1373 - val_loss: 0.0919 - val_mae: 0.2329\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1367 - val_loss: 0.0881 - val_mae: 0.2223\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1384 - val_loss: 0.0872 - val_mae: 0.2297\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1351 - val_loss: 0.0866 - val_mae: 0.2264\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1370 - val_loss: 0.0876 - val_mae: 0.2353\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1395 - val_loss: 0.0869 - val_mae: 0.2272\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1335 - val_loss: 0.0876 - val_mae: 0.2309\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1339 - val_loss: 0.0897 - val_mae: 0.2310\n",
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1390 - val_loss: 0.0896 - val_mae: 0.2285\n",
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1366 - val_loss: 0.0873 - val_mae: 0.2230\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0285 - mae: 0.1360 - val_loss: 0.0926 - val_mae: 0.2192\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1414 - val_loss: 0.0877 - val_mae: 0.2291\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1373 - val_loss: 0.0908 - val_mae: 0.2359\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1360 - val_loss: 0.0907 - val_mae: 0.2302\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1411 - val_loss: 0.0902 - val_mae: 0.2310\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1318 - val_loss: 0.0918 - val_mae: 0.2340\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1337 - val_loss: 0.0907 - val_mae: 0.2368\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1335 - val_loss: 0.0902 - val_mae: 0.2285\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1404 - val_loss: 0.0906 - val_mae: 0.2337\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1347 - val_loss: 0.0935 - val_mae: 0.2258\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1365 - val_loss: 0.0909 - val_mae: 0.2402\n",
      "Epoch 309/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1371 - val_loss: 0.0877 - val_mae: 0.2280\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1372 - val_loss: 0.0875 - val_mae: 0.2261\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1325 - val_loss: 0.0975 - val_mae: 0.2522\n",
      "Epoch 312/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1359 - val_loss: 0.0941 - val_mae: 0.2383\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1392 - val_loss: 0.0903 - val_mae: 0.2389\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1404 - val_loss: 0.0894 - val_mae: 0.2328\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1362 - val_loss: 0.0889 - val_mae: 0.2330\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1362 - val_loss: 0.0899 - val_mae: 0.2335\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1311 - val_loss: 0.0910 - val_mae: 0.2332\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1402 - val_loss: 0.0892 - val_mae: 0.2233\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1343 - val_loss: 0.0927 - val_mae: 0.2398\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1377 - val_loss: 0.0931 - val_mae: 0.2480\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1376 - val_loss: 0.0929 - val_mae: 0.2369\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1379 - val_loss: 0.0906 - val_mae: 0.2338\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1350 - val_loss: 0.0938 - val_mae: 0.2493\n",
      "Epoch 324/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1374 - val_loss: 0.0909 - val_mae: 0.2357\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1352 - val_loss: 0.0880 - val_mae: 0.2318\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0300 - mae: 0.1417 - val_loss: 0.0888 - val_mae: 0.2347\n",
      "Epoch 327/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1356 - val_loss: 0.0912 - val_mae: 0.2330\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1334 - val_loss: 0.0890 - val_mae: 0.2305\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1384 - val_loss: 0.0897 - val_mae: 0.2331\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1331 - val_loss: 0.0918 - val_mae: 0.2403\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1385 - val_loss: 0.0919 - val_mae: 0.2383\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1348 - val_loss: 0.0934 - val_mae: 0.2280\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1366 - val_loss: 0.0897 - val_mae: 0.2330\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1362 - val_loss: 0.0889 - val_mae: 0.2302\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1334 - val_loss: 0.0895 - val_mae: 0.2274\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0285 - mae: 0.1341 - val_loss: 0.0901 - val_mae: 0.2287\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1375 - val_loss: 0.0903 - val_mae: 0.2339\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1335 - val_loss: 0.0893 - val_mae: 0.2311\n",
      "Epoch 339/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1367 - val_loss: 0.0925 - val_mae: 0.2264\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1315 - val_loss: 0.0927 - val_mae: 0.2394\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1317 - val_loss: 0.0942 - val_mae: 0.2410\n",
      "Epoch 342/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1406 - val_loss: 0.0909 - val_mae: 0.2339\n",
      "Epoch 343/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1307 - val_loss: 0.0952 - val_mae: 0.2462\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1344 - val_loss: 0.0902 - val_mae: 0.2380\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1355 - val_loss: 0.0894 - val_mae: 0.2300\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1339 - val_loss: 0.0898 - val_mae: 0.2254\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1377 - val_loss: 0.0894 - val_mae: 0.2289\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1346 - val_loss: 0.0940 - val_mae: 0.2462\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1373 - val_loss: 0.0917 - val_mae: 0.2409\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1372 - val_loss: 0.0915 - val_mae: 0.2322\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1357 - val_loss: 0.0922 - val_mae: 0.2390\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1377 - val_loss: 0.0902 - val_mae: 0.2349\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1346 - val_loss: 0.0900 - val_mae: 0.2311\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1377 - val_loss: 0.0936 - val_mae: 0.2456\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1342 - val_loss: 0.0921 - val_mae: 0.2293\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1375 - val_loss: 0.0902 - val_mae: 0.2318\n",
      "Epoch 357/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1348 - val_loss: 0.0913 - val_mae: 0.2373\n",
      "Epoch 358/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1355 - val_loss: 0.0944 - val_mae: 0.2251\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1359 - val_loss: 0.0922 - val_mae: 0.2336\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1352 - val_loss: 0.0916 - val_mae: 0.2295\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1343 - val_loss: 0.0904 - val_mae: 0.2353\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1302 - val_loss: 0.0961 - val_mae: 0.2316\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1423 - val_loss: 0.0907 - val_mae: 0.2366\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1339 - val_loss: 0.0902 - val_mae: 0.2321\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0280 - mae: 0.1341 - val_loss: 0.0921 - val_mae: 0.2285\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1366 - val_loss: 0.0943 - val_mae: 0.2465\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1338 - val_loss: 0.0950 - val_mae: 0.2358\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1350 - val_loss: 0.0925 - val_mae: 0.2385\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1342 - val_loss: 0.0904 - val_mae: 0.2338\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1372 - val_loss: 0.0917 - val_mae: 0.2339\n",
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1388 - val_loss: 0.0913 - val_mae: 0.2409\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0273 - mae: 0.1314 - val_loss: 0.0912 - val_mae: 0.2389\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1375 - val_loss: 0.0910 - val_mae: 0.2382\n",
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1355 - val_loss: 0.0914 - val_mae: 0.2429\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0291 - mae: 0.1360 - val_loss: 0.0910 - val_mae: 0.2367\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1358 - val_loss: 0.0911 - val_mae: 0.2343\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1348 - val_loss: 0.0920 - val_mae: 0.2362\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1357 - val_loss: 0.0928 - val_mae: 0.2381\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1375 - val_loss: 0.0911 - val_mae: 0.2334\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1368 - val_loss: 0.0916 - val_mae: 0.2364\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1349 - val_loss: 0.0918 - val_mae: 0.2290\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1322 - val_loss: 0.0977 - val_mae: 0.2276\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1363 - val_loss: 0.0955 - val_mae: 0.2339\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1331 - val_loss: 0.0973 - val_mae: 0.2481\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1407 - val_loss: 0.0914 - val_mae: 0.2349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1341 - val_loss: 0.0929 - val_mae: 0.2420\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1384 - val_loss: 0.0914 - val_mae: 0.2359\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1333 - val_loss: 0.0967 - val_mae: 0.2335\n",
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1322 - val_loss: 0.0967 - val_mae: 0.2472\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1337 - val_loss: 0.0915 - val_mae: 0.2344\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1298 - val_loss: 0.0916 - val_mae: 0.2379\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1328 - val_loss: 0.0946 - val_mae: 0.2325\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1351 - val_loss: 0.0910 - val_mae: 0.2379\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1362 - val_loss: 0.0934 - val_mae: 0.2377\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1348 - val_loss: 0.0924 - val_mae: 0.2351\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1333 - val_loss: 0.0992 - val_mae: 0.2570\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1343 - val_loss: 0.0912 - val_mae: 0.2353\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1343 - val_loss: 0.0976 - val_mae: 0.2519\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1342 - val_loss: 0.0976 - val_mae: 0.2485\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1407 - val_loss: 0.0941 - val_mae: 0.2456\n",
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1312 - val_loss: 0.0966 - val_mae: 0.2430\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1393 - val_loss: 0.0920 - val_mae: 0.2381\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1325 - val_loss: 0.0909 - val_mae: 0.2376\n",
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1349 - val_loss: 0.0925 - val_mae: 0.2423\n",
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1338 - val_loss: 0.0932 - val_mae: 0.2408\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1348 - val_loss: 0.0925 - val_mae: 0.2322\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1328 - val_loss: 0.0978 - val_mae: 0.2419\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1348 - val_loss: 0.0956 - val_mae: 0.2372\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1350 - val_loss: 0.0948 - val_mae: 0.2363\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1355 - val_loss: 0.0954 - val_mae: 0.2356\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1350 - val_loss: 0.0943 - val_mae: 0.2354\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1354 - val_loss: 0.0954 - val_mae: 0.2429\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1320 - val_loss: 0.0947 - val_mae: 0.2478\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1311 - val_loss: 0.1017 - val_mae: 0.2580\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1370 - val_loss: 0.0948 - val_mae: 0.2449\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1324 - val_loss: 0.0942 - val_mae: 0.2401\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1329 - val_loss: 0.0941 - val_mae: 0.2367\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1369 - val_loss: 0.0937 - val_mae: 0.2460\n",
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1304 - val_loss: 0.0930 - val_mae: 0.2319\n",
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1338 - val_loss: 0.0960 - val_mae: 0.2287\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1330 - val_loss: 0.0932 - val_mae: 0.2394\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1357 - val_loss: 0.0933 - val_mae: 0.2359\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0277 - mae: 0.1348 - val_loss: 0.0974 - val_mae: 0.2510\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1338 - val_loss: 0.0993 - val_mae: 0.2434\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1354 - val_loss: 0.0955 - val_mae: 0.2401\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1303 - val_loss: 0.0930 - val_mae: 0.2309\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1335 - val_loss: 0.0954 - val_mae: 0.2506\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1363 - val_loss: 0.0987 - val_mae: 0.2502\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1346 - val_loss: 0.0944 - val_mae: 0.2434\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1314 - val_loss: 0.0975 - val_mae: 0.2537\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1339 - val_loss: 0.0934 - val_mae: 0.2400\n",
      "Epoch 432/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1315 - val_loss: 0.0973 - val_mae: 0.2547\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1337 - val_loss: 0.0937 - val_mae: 0.2369\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1334 - val_loss: 0.0942 - val_mae: 0.2450\n",
      "Epoch 435/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1357 - val_loss: 0.0934 - val_mae: 0.2455\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1371 - val_loss: 0.0935 - val_mae: 0.2424\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1325 - val_loss: 0.0950 - val_mae: 0.2394\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1346 - val_loss: 0.1000 - val_mae: 0.2416\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1352 - val_loss: 0.0923 - val_mae: 0.2356\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1339 - val_loss: 0.0956 - val_mae: 0.2433\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1376 - val_loss: 0.0932 - val_mae: 0.2420\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1331 - val_loss: 0.0928 - val_mae: 0.2381\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1301 - val_loss: 0.0948 - val_mae: 0.2402\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1353 - val_loss: 0.0918 - val_mae: 0.2385\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1325 - val_loss: 0.0921 - val_mae: 0.2376\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1318 - val_loss: 0.0945 - val_mae: 0.2481\n",
      "Epoch 447/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1339 - val_loss: 0.0926 - val_mae: 0.2457\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1360 - val_loss: 0.0948 - val_mae: 0.2477\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1328 - val_loss: 0.0930 - val_mae: 0.2390\n",
      "Epoch 450/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1355 - val_loss: 0.0940 - val_mae: 0.2452\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1269 - val_loss: 0.0949 - val_mae: 0.2500\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1318 - val_loss: 0.0981 - val_mae: 0.2539\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1335 - val_loss: 0.0941 - val_mae: 0.2484\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1335 - val_loss: 0.0951 - val_mae: 0.2519\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1339 - val_loss: 0.0973 - val_mae: 0.2422\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1335 - val_loss: 0.0950 - val_mae: 0.2444\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1314 - val_loss: 0.0960 - val_mae: 0.2439\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1326 - val_loss: 0.0926 - val_mae: 0.2418\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1312 - val_loss: 0.0974 - val_mae: 0.2326\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1339 - val_loss: 0.0953 - val_mae: 0.2428\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1350 - val_loss: 0.0967 - val_mae: 0.2475\n",
      "Epoch 462/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1351 - val_loss: 0.0952 - val_mae: 0.2506\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1353 - val_loss: 0.0933 - val_mae: 0.2438\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1351 - val_loss: 0.0940 - val_mae: 0.2449\n",
      "Epoch 465/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1312 - val_loss: 0.0932 - val_mae: 0.2416\n",
      "Epoch 466/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1295 - val_loss: 0.0944 - val_mae: 0.2476\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1329 - val_loss: 0.0960 - val_mae: 0.2374\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1353 - val_loss: 0.0946 - val_mae: 0.2409\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1294 - val_loss: 0.0953 - val_mae: 0.2425\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1324 - val_loss: 0.0935 - val_mae: 0.2357\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1330 - val_loss: 0.0942 - val_mae: 0.2464\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1325 - val_loss: 0.0971 - val_mae: 0.2418\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1306 - val_loss: 0.0937 - val_mae: 0.2357\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1327 - val_loss: 0.0973 - val_mae: 0.2419\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1353 - val_loss: 0.0985 - val_mae: 0.2558\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1323 - val_loss: 0.0990 - val_mae: 0.2527\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1328 - val_loss: 0.0947 - val_mae: 0.2358\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1340 - val_loss: 0.0941 - val_mae: 0.2385\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1275 - val_loss: 0.0945 - val_mae: 0.2393\n",
      "Epoch 480/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1272 - val_loss: 0.1011 - val_mae: 0.2368\n",
      "Epoch 481/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1340 - val_loss: 0.0959 - val_mae: 0.2352\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1376 - val_loss: 0.0945 - val_mae: 0.2482\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1309 - val_loss: 0.0989 - val_mae: 0.2487\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1311 - val_loss: 0.0943 - val_mae: 0.2377\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1313 - val_loss: 0.0958 - val_mae: 0.2456\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1290 - val_loss: 0.0936 - val_mae: 0.2351\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1300 - val_loss: 0.0914 - val_mae: 0.2371\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1306 - val_loss: 0.0958 - val_mae: 0.2512\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1350 - val_loss: 0.0934 - val_mae: 0.2446\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1368 - val_loss: 0.0942 - val_mae: 0.2396\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1305 - val_loss: 0.0981 - val_mae: 0.2461\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1357 - val_loss: 0.0954 - val_mae: 0.2500\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1353 - val_loss: 0.0934 - val_mae: 0.2464\n",
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1325 - val_loss: 0.0984 - val_mae: 0.2541\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1353 - val_loss: 0.0969 - val_mae: 0.2506\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1342 - val_loss: 0.0982 - val_mae: 0.2534\n",
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1304 - val_loss: 0.0968 - val_mae: 0.2455\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1359 - val_loss: 0.0954 - val_mae: 0.2437\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1311 - val_loss: 0.0961 - val_mae: 0.2432\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1379 - val_loss: 0.0965 - val_mae: 0.2486\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.1342 - val_loss: 0.0951 - val_mae: 0.2393\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0258 - mae: 0.1301 - val_loss: 0.0976 - val_mae: 0.2454\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0273 - mae: 0.1331 - val_loss: 0.0962 - val_mae: 0.2492\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0276 - mae: 0.1332 - val_loss: 0.1009 - val_mae: 0.2602\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0278 - mae: 0.1346 - val_loss: 0.0953 - val_mae: 0.2504\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0267 - mae: 0.1314 - val_loss: 0.0959 - val_mae: 0.2378\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1306 - val_loss: 0.0991 - val_mae: 0.2571\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1352 - val_loss: 0.0943 - val_mae: 0.2405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1345 - val_loss: 0.0965 - val_mae: 0.2479\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0285 - mae: 0.1348 - val_loss: 0.0945 - val_mae: 0.2448\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1315 - val_loss: 0.0962 - val_mae: 0.2400\n",
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - mae: 0.1322 - val_loss: 0.0993 - val_mae: 0.2348\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1340 - val_loss: 0.0962 - val_mae: 0.2447\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1346 - val_loss: 0.0976 - val_mae: 0.2533\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0262 - mae: 0.1294 - val_loss: 0.0946 - val_mae: 0.2378\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1364 - val_loss: 0.0941 - val_mae: 0.2430\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1313 - val_loss: 0.0934 - val_mae: 0.2450\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0267 - mae: 0.1324 - val_loss: 0.0951 - val_mae: 0.2470\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0273 - mae: 0.1304 - val_loss: 0.0936 - val_mae: 0.2420\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1335 - val_loss: 0.0941 - val_mae: 0.2408\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0273 - mae: 0.1309 - val_loss: 0.0966 - val_mae: 0.2492\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1315 - val_loss: 0.0937 - val_mae: 0.2449\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1327 - val_loss: 0.0938 - val_mae: 0.2437\n",
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1337 - val_loss: 0.0946 - val_mae: 0.2403\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1333 - val_loss: 0.0945 - val_mae: 0.2411\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1327 - val_loss: 0.0947 - val_mae: 0.2460\n",
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - mae: 0.1333 - val_loss: 0.0971 - val_mae: 0.2526\n",
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0266 - mae: 0.1312 - val_loss: 0.0958 - val_mae: 0.2435\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1360 - val_loss: 0.0934 - val_mae: 0.2422\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1391 - val_loss: 0.0939 - val_mae: 0.2460\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1271 - val_loss: 0.0975 - val_mae: 0.2379\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1328 - val_loss: 0.0984 - val_mae: 0.2342\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1353 - val_loss: 0.0940 - val_mae: 0.2442\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1334 - val_loss: 0.0957 - val_mae: 0.2472\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0269 - mae: 0.1307 - val_loss: 0.0981 - val_mae: 0.2429\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1321 - val_loss: 0.0954 - val_mae: 0.2489\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1349 - val_loss: 0.0950 - val_mae: 0.2411\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1332 - val_loss: 0.0947 - val_mae: 0.2452\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1327 - val_loss: 0.0956 - val_mae: 0.2499\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1307 - val_loss: 0.0968 - val_mae: 0.2514\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1343 - val_loss: 0.0948 - val_mae: 0.2379\n",
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0273 - mae: 0.1273 - val_loss: 0.0947 - val_mae: 0.2428\n",
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1339 - val_loss: 0.0994 - val_mae: 0.2574\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1343 - val_loss: 0.0960 - val_mae: 0.2505\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1300 - val_loss: 0.0956 - val_mae: 0.2354\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1345 - val_loss: 0.0954 - val_mae: 0.2482\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1362 - val_loss: 0.0936 - val_mae: 0.2431\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1361 - val_loss: 0.0930 - val_mae: 0.2432\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1310 - val_loss: 0.0987 - val_mae: 0.2564\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1319 - val_loss: 0.0933 - val_mae: 0.2386\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1355 - val_loss: 0.0968 - val_mae: 0.2506\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1328 - val_loss: 0.0948 - val_mae: 0.2463\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1333 - val_loss: 0.0949 - val_mae: 0.2464\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0268 - mae: 0.1320 - val_loss: 0.0952 - val_mae: 0.2452\n",
      "Epoch 555/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1346 - val_loss: 0.0986 - val_mae: 0.2400\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0268 - mae: 0.1309 - val_loss: 0.0962 - val_mae: 0.2408\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1306 - val_loss: 0.0983 - val_mae: 0.2550\n",
      "Epoch 558/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1330 - val_loss: 0.0942 - val_mae: 0.2434\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1344 - val_loss: 0.0960 - val_mae: 0.2375\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1336 - val_loss: 0.0950 - val_mae: 0.2391\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1344 - val_loss: 0.0951 - val_mae: 0.2482\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1312 - val_loss: 0.0978 - val_mae: 0.2372\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1318 - val_loss: 0.0955 - val_mae: 0.2402\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1328 - val_loss: 0.0959 - val_mae: 0.2487\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1385 - val_loss: 0.0963 - val_mae: 0.2463\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1353 - val_loss: 0.0994 - val_mae: 0.2539\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1303 - val_loss: 0.0999 - val_mae: 0.2591\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1337 - val_loss: 0.0957 - val_mae: 0.2504\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1278 - val_loss: 0.1022 - val_mae: 0.2479\n",
      "Epoch 570/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1389 - val_loss: 0.0963 - val_mae: 0.2474\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1310 - val_loss: 0.0954 - val_mae: 0.2448\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1295 - val_loss: 0.0990 - val_mae: 0.2549\n",
      "Epoch 573/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1354 - val_loss: 0.0998 - val_mae: 0.2481\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1334 - val_loss: 0.0965 - val_mae: 0.2468\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1332 - val_loss: 0.0961 - val_mae: 0.2468\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1350 - val_loss: 0.0990 - val_mae: 0.2564\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1303 - val_loss: 0.0968 - val_mae: 0.2421\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1368 - val_loss: 0.0985 - val_mae: 0.2401\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1314 - val_loss: 0.0967 - val_mae: 0.2492\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1373 - val_loss: 0.0971 - val_mae: 0.2385\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1314 - val_loss: 0.0964 - val_mae: 0.2461\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1321 - val_loss: 0.0975 - val_mae: 0.2507\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1330 - val_loss: 0.0953 - val_mae: 0.2453\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1332 - val_loss: 0.0954 - val_mae: 0.2428\n",
      "Epoch 585/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1320 - val_loss: 0.0982 - val_mae: 0.2529\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0262 - mae: 0.1300 - val_loss: 0.0973 - val_mae: 0.2390\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1346 - val_loss: 0.0999 - val_mae: 0.2484\n",
      "Epoch 588/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1337 - val_loss: 0.0965 - val_mae: 0.2426\n",
      "Epoch 589/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1368 - val_loss: 0.0989 - val_mae: 0.2420\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1295 - val_loss: 0.1027 - val_mae: 0.2529\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1363 - val_loss: 0.0974 - val_mae: 0.2519\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0275 - mae: 0.1343 - val_loss: 0.0951 - val_mae: 0.2451\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0273 - mae: 0.1316 - val_loss: 0.0979 - val_mae: 0.2395\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1317 - val_loss: 0.0955 - val_mae: 0.2440\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0268 - mae: 0.1323 - val_loss: 0.0962 - val_mae: 0.2425\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0258 - mae: 0.1274 - val_loss: 0.1066 - val_mae: 0.2670\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1283 - val_loss: 0.0966 - val_mae: 0.2531\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1339 - val_loss: 0.0963 - val_mae: 0.2497\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1260 - val_loss: 0.0961 - val_mae: 0.2499\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1341 - val_loss: 0.0956 - val_mae: 0.2391\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "4\n",
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.9318 - mae: 0.7089 - val_loss: 0.6976 - val_mae: 0.5986\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4169 - mae: 0.4790 - val_loss: 0.3854 - val_mae: 0.4504\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2719 - mae: 0.3952 - val_loss: 0.2935 - val_mae: 0.3962\n",
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2149 - mae: 0.3587 - val_loss: 0.2165 - val_mae: 0.3336\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1752 - mae: 0.3291 - val_loss: 0.1800 - val_mae: 0.3059\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1432 - mae: 0.2950 - val_loss: 0.1796 - val_mae: 0.3012\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1226 - mae: 0.2740 - val_loss: 0.1599 - val_mae: 0.2697\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1070 - mae: 0.2497 - val_loss: 0.1499 - val_mae: 0.2666\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0941 - mae: 0.2348 - val_loss: 0.1487 - val_mae: 0.2744\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0855 - mae: 0.2257 - val_loss: 0.1387 - val_mae: 0.2610\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0794 - mae: 0.2185 - val_loss: 0.1300 - val_mae: 0.2504\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0790 - mae: 0.2135 - val_loss: 0.1291 - val_mae: 0.2555\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0748 - mae: 0.2139 - val_loss: 0.1293 - val_mae: 0.2489\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0715 - mae: 0.2072 - val_loss: 0.1381 - val_mae: 0.2652\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0726 - mae: 0.2098 - val_loss: 0.1388 - val_mae: 0.2668\n",
      "Epoch 16/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0716 - mae: 0.2056 - val_loss: 0.1235 - val_mae: 0.2488\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0710 - mae: 0.2070 - val_loss: 0.1273 - val_mae: 0.2511\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0701 - mae: 0.2008 - val_loss: 0.1227 - val_mae: 0.2472\n",
      "Epoch 19/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0686 - mae: 0.2054 - val_loss: 0.1311 - val_mae: 0.2579\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0718 - mae: 0.2092 - val_loss: 0.1233 - val_mae: 0.2501\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0669 - mae: 0.2028 - val_loss: 0.1257 - val_mae: 0.2521\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0653 - mae: 0.1996 - val_loss: 0.1273 - val_mae: 0.2571\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0657 - mae: 0.1989 - val_loss: 0.1175 - val_mae: 0.2483\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0624 - mae: 0.1955 - val_loss: 0.1347 - val_mae: 0.2633\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0665 - mae: 0.2050 - val_loss: 0.1212 - val_mae: 0.2529\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0625 - mae: 0.1938 - val_loss: 0.1141 - val_mae: 0.2379\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0622 - mae: 0.1955 - val_loss: 0.1116 - val_mae: 0.2365\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0605 - mae: 0.1970 - val_loss: 0.1219 - val_mae: 0.2483\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0640 - mae: 0.1972 - val_loss: 0.1099 - val_mae: 0.2357\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0608 - mae: 0.1943 - val_loss: 0.1135 - val_mae: 0.2441\n",
      "Epoch 31/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0591 - mae: 0.1895 - val_loss: 0.1173 - val_mae: 0.2537\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0624 - mae: 0.1928 - val_loss: 0.1117 - val_mae: 0.2460\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0596 - mae: 0.1930 - val_loss: 0.1062 - val_mae: 0.2300\n",
      "Epoch 34/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0583 - mae: 0.1846 - val_loss: 0.1052 - val_mae: 0.2313\n",
      "Epoch 35/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0543 - mae: 0.1823 - val_loss: 0.1072 - val_mae: 0.2332\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - mae: 0.1909 - val_loss: 0.1040 - val_mae: 0.2205\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - mae: 0.1913 - val_loss: 0.1053 - val_mae: 0.2210\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0547 - mae: 0.1858 - val_loss: 0.1033 - val_mae: 0.2292\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0558 - mae: 0.1860 - val_loss: 0.1187 - val_mae: 0.2602\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0571 - mae: 0.1924 - val_loss: 0.1040 - val_mae: 0.2295\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0534 - mae: 0.1872 - val_loss: 0.1001 - val_mae: 0.2262\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0547 - mae: 0.1867 - val_loss: 0.0997 - val_mae: 0.2196\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0529 - mae: 0.1830 - val_loss: 0.1033 - val_mae: 0.2383\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0543 - mae: 0.1872 - val_loss: 0.1052 - val_mae: 0.2355\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0542 - mae: 0.1888 - val_loss: 0.1002 - val_mae: 0.2245\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0539 - mae: 0.1862 - val_loss: 0.0998 - val_mae: 0.2196\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0527 - mae: 0.1832 - val_loss: 0.1001 - val_mae: 0.2393\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0529 - mae: 0.1884 - val_loss: 0.0985 - val_mae: 0.2182\n",
      "Epoch 49/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0518 - mae: 0.1850 - val_loss: 0.0950 - val_mae: 0.2156\n",
      "Epoch 50/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - mae: 0.1873 - val_loss: 0.0964 - val_mae: 0.2250\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0526 - mae: 0.1852 - val_loss: 0.0975 - val_mae: 0.2246\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0519 - mae: 0.1853 - val_loss: 0.0979 - val_mae: 0.2267\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0525 - mae: 0.1846 - val_loss: 0.0959 - val_mae: 0.2224\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0487 - mae: 0.1772 - val_loss: 0.0929 - val_mae: 0.2216\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0518 - mae: 0.1841 - val_loss: 0.0949 - val_mae: 0.2236\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0494 - mae: 0.1810 - val_loss: 0.0952 - val_mae: 0.2103\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0490 - mae: 0.1772 - val_loss: 0.0948 - val_mae: 0.2193\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0515 - mae: 0.1834 - val_loss: 0.0934 - val_mae: 0.2182\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0487 - mae: 0.1784 - val_loss: 0.0948 - val_mae: 0.2150\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0483 - mae: 0.1752 - val_loss: 0.0989 - val_mae: 0.2242\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0486 - mae: 0.1798 - val_loss: 0.0939 - val_mae: 0.2128\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0491 - mae: 0.1804 - val_loss: 0.0914 - val_mae: 0.2155\n",
      "Epoch 63/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0488 - mae: 0.1813 - val_loss: 0.0929 - val_mae: 0.2222\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - mae: 0.1764 - val_loss: 0.0939 - val_mae: 0.2247\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0481 - mae: 0.1760 - val_loss: 0.0954 - val_mae: 0.2304\n",
      "Epoch 66/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0488 - mae: 0.1814 - val_loss: 0.0926 - val_mae: 0.2240\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 0.1705 - val_loss: 0.0897 - val_mae: 0.2067\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1791 - val_loss: 0.0914 - val_mae: 0.2238\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0480 - mae: 0.1752 - val_loss: 0.0902 - val_mae: 0.2174\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0459 - mae: 0.1726 - val_loss: 0.0903 - val_mae: 0.2114\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.1736 - val_loss: 0.0909 - val_mae: 0.2219\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0463 - mae: 0.1776 - val_loss: 0.0868 - val_mae: 0.2054\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0436 - mae: 0.1733 - val_loss: 0.0892 - val_mae: 0.2213\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0446 - mae: 0.1698 - val_loss: 0.0964 - val_mae: 0.2322\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.1740 - val_loss: 0.0877 - val_mae: 0.2175\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0464 - mae: 0.1746 - val_loss: 0.0865 - val_mae: 0.2058\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1728 - val_loss: 0.0875 - val_mae: 0.2156\n",
      "Epoch 78/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.1679 - val_loss: 0.0854 - val_mae: 0.2036\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 0.1725 - val_loss: 0.0864 - val_mae: 0.2028\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0444 - mae: 0.1739 - val_loss: 0.0838 - val_mae: 0.1984\n",
      "Epoch 81/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0447 - mae: 0.1708 - val_loss: 0.0853 - val_mae: 0.2037\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0445 - mae: 0.1729 - val_loss: 0.0872 - val_mae: 0.2097\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1681 - val_loss: 0.0836 - val_mae: 0.2054\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0417 - mae: 0.1678 - val_loss: 0.0899 - val_mae: 0.2243\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.1675 - val_loss: 0.0855 - val_mae: 0.2067\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 0.1700 - val_loss: 0.0919 - val_mae: 0.2277\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.1701 - val_loss: 0.0873 - val_mae: 0.2179\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0418 - mae: 0.1690 - val_loss: 0.0865 - val_mae: 0.2162\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1700 - val_loss: 0.0836 - val_mae: 0.2090\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1662 - val_loss: 0.0854 - val_mae: 0.2218\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1667 - val_loss: 0.0820 - val_mae: 0.2036\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0395 - mae: 0.1621 - val_loss: 0.0865 - val_mae: 0.2172\n",
      "Epoch 93/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.1654 - val_loss: 0.0855 - val_mae: 0.2118\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - mae: 0.1641 - val_loss: 0.0851 - val_mae: 0.2155\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1684 - val_loss: 0.0820 - val_mae: 0.2030\n",
      "Epoch 96/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - mae: 0.1643 - val_loss: 0.0854 - val_mae: 0.2095\n",
      "Epoch 97/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1646 - val_loss: 0.0841 - val_mae: 0.2043\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0388 - mae: 0.1635 - val_loss: 0.0907 - val_mae: 0.2195\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - mae: 0.1620 - val_loss: 0.0811 - val_mae: 0.2004\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - mae: 0.1618 - val_loss: 0.0827 - val_mae: 0.2025\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0397 - mae: 0.1640 - val_loss: 0.0810 - val_mae: 0.2065\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0392 - mae: 0.1602 - val_loss: 0.0873 - val_mae: 0.2097\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0383 - mae: 0.1589 - val_loss: 0.0823 - val_mae: 0.2005\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0367 - mae: 0.1573 - val_loss: 0.0921 - val_mae: 0.2363\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - mae: 0.1623 - val_loss: 0.0846 - val_mae: 0.2045\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0378 - mae: 0.1575 - val_loss: 0.0813 - val_mae: 0.2056\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0379 - mae: 0.1598 - val_loss: 0.0861 - val_mae: 0.2221\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - mae: 0.1582 - val_loss: 0.0835 - val_mae: 0.2167\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0384 - mae: 0.1583 - val_loss: 0.0816 - val_mae: 0.2095\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1615 - val_loss: 0.0800 - val_mae: 0.2000\n",
      "Epoch 111/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0394 - mae: 0.1606 - val_loss: 0.0789 - val_mae: 0.1984\n",
      "Epoch 112/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0383 - mae: 0.1567 - val_loss: 0.0789 - val_mae: 0.1988\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0374 - mae: 0.1586 - val_loss: 0.0799 - val_mae: 0.2033\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1577 - val_loss: 0.0804 - val_mae: 0.1994\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0383 - mae: 0.1553 - val_loss: 0.0838 - val_mae: 0.2048\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0359 - mae: 0.1544 - val_loss: 0.0868 - val_mae: 0.2202\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0379 - mae: 0.1562 - val_loss: 0.0823 - val_mae: 0.2165\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0364 - mae: 0.1498 - val_loss: 0.0843 - val_mae: 0.2237\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0369 - mae: 0.1546 - val_loss: 0.0806 - val_mae: 0.2060\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1535 - val_loss: 0.0779 - val_mae: 0.1985\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0366 - mae: 0.1570 - val_loss: 0.0808 - val_mae: 0.2053\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - mae: 0.1506 - val_loss: 0.0832 - val_mae: 0.2031\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1561 - val_loss: 0.0788 - val_mae: 0.1997\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0359 - mae: 0.1501 - val_loss: 0.0810 - val_mae: 0.2125\n",
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1530 - val_loss: 0.0825 - val_mae: 0.2160\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1570 - val_loss: 0.0831 - val_mae: 0.2080\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0358 - mae: 0.1555 - val_loss: 0.0830 - val_mae: 0.2151\n",
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0368 - mae: 0.1575 - val_loss: 0.0786 - val_mae: 0.2022\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1540 - val_loss: 0.0782 - val_mae: 0.2024\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.1496 - val_loss: 0.0813 - val_mae: 0.1998\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0343 - mae: 0.1508 - val_loss: 0.0830 - val_mae: 0.2043\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1529 - val_loss: 0.0797 - val_mae: 0.2055\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0335 - mae: 0.1476 - val_loss: 0.0903 - val_mae: 0.2172\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1492 - val_loss: 0.0816 - val_mae: 0.2102\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1544 - val_loss: 0.0807 - val_mae: 0.1999\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1501 - val_loss: 0.0795 - val_mae: 0.2016\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1527 - val_loss: 0.0767 - val_mae: 0.1958\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1499 - val_loss: 0.0780 - val_mae: 0.2023\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1551 - val_loss: 0.0790 - val_mae: 0.2020\n",
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0352 - mae: 0.1523 - val_loss: 0.0778 - val_mae: 0.1959\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0346 - mae: 0.1517 - val_loss: 0.0804 - val_mae: 0.2082\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0349 - mae: 0.1511 - val_loss: 0.0829 - val_mae: 0.2112\n",
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1519 - val_loss: 0.0817 - val_mae: 0.2009\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1500 - val_loss: 0.0817 - val_mae: 0.2092\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1505 - val_loss: 0.0803 - val_mae: 0.1972\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1442 - val_loss: 0.0900 - val_mae: 0.2164\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1454 - val_loss: 0.0758 - val_mae: 0.1971\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1494 - val_loss: 0.0766 - val_mae: 0.1948\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1484 - val_loss: 0.0777 - val_mae: 0.1975\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1478 - val_loss: 0.0773 - val_mae: 0.1963\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.1515 - val_loss: 0.0781 - val_mae: 0.1994\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1495 - val_loss: 0.0775 - val_mae: 0.1954\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1491 - val_loss: 0.0765 - val_mae: 0.1944\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1469 - val_loss: 0.0753 - val_mae: 0.1923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - mae: 0.1476 - val_loss: 0.0781 - val_mae: 0.1954\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1481 - val_loss: 0.0793 - val_mae: 0.2024\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1477 - val_loss: 0.0808 - val_mae: 0.1976\n",
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1479 - val_loss: 0.0791 - val_mae: 0.2008\n",
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.1466 - val_loss: 0.0782 - val_mae: 0.1993\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1453 - val_loss: 0.0779 - val_mae: 0.2025\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1493 - val_loss: 0.0800 - val_mae: 0.2067\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1501 - val_loss: 0.0795 - val_mae: 0.2077\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1478 - val_loss: 0.0775 - val_mae: 0.1983\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - mae: 0.1476 - val_loss: 0.0776 - val_mae: 0.1989\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1460 - val_loss: 0.0773 - val_mae: 0.1980\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1508 - val_loss: 0.0791 - val_mae: 0.2042\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1400 - val_loss: 0.0794 - val_mae: 0.1963\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1430 - val_loss: 0.0822 - val_mae: 0.2086\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1433 - val_loss: 0.0775 - val_mae: 0.1996\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1469 - val_loss: 0.0785 - val_mae: 0.1999\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1456 - val_loss: 0.0769 - val_mae: 0.1953\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1419 - val_loss: 0.0798 - val_mae: 0.2039\n",
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1451 - val_loss: 0.0798 - val_mae: 0.1957\n",
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1413 - val_loss: 0.0779 - val_mae: 0.2026\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1502 - val_loss: 0.0786 - val_mae: 0.1972\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1427 - val_loss: 0.0821 - val_mae: 0.2061\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1489 - val_loss: 0.0807 - val_mae: 0.2033\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1465 - val_loss: 0.0775 - val_mae: 0.1995\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1444 - val_loss: 0.0792 - val_mae: 0.1971\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1384 - val_loss: 0.0841 - val_mae: 0.2127\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1446 - val_loss: 0.0775 - val_mae: 0.1986\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1448 - val_loss: 0.0789 - val_mae: 0.1968\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0326 - mae: 0.1475 - val_loss: 0.0806 - val_mae: 0.2056\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1443 - val_loss: 0.0797 - val_mae: 0.2018\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1411 - val_loss: 0.0759 - val_mae: 0.1969\n",
      "Epoch 186/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1413 - val_loss: 0.0789 - val_mae: 0.1987\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1421 - val_loss: 0.0802 - val_mae: 0.2076\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1388 - val_loss: 0.0804 - val_mae: 0.1956\n",
      "Epoch 189/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1441 - val_loss: 0.0794 - val_mae: 0.2065\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1467 - val_loss: 0.0781 - val_mae: 0.2026\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1471 - val_loss: 0.0791 - val_mae: 0.2052\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1410 - val_loss: 0.0810 - val_mae: 0.1983\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1427 - val_loss: 0.0777 - val_mae: 0.2015\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1463 - val_loss: 0.0764 - val_mae: 0.1981\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1453 - val_loss: 0.0765 - val_mae: 0.2005\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1462 - val_loss: 0.0786 - val_mae: 0.1999\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0300 - mae: 0.1381 - val_loss: 0.0834 - val_mae: 0.2102\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1443 - val_loss: 0.0773 - val_mae: 0.1982\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1440 - val_loss: 0.0803 - val_mae: 0.2008\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1473 - val_loss: 0.0803 - val_mae: 0.2014\n",
      "Epoch 201/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1422 - val_loss: 0.0783 - val_mae: 0.2050\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1429 - val_loss: 0.0795 - val_mae: 0.1960\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1432 - val_loss: 0.0771 - val_mae: 0.1973\n",
      "Epoch 204/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1459 - val_loss: 0.0773 - val_mae: 0.1980\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1430 - val_loss: 0.0796 - val_mae: 0.1988\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.1421 - val_loss: 0.0787 - val_mae: 0.2019\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1424 - val_loss: 0.0818 - val_mae: 0.2093\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1364 - val_loss: 0.0840 - val_mae: 0.2105\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1444 - val_loss: 0.0799 - val_mae: 0.2014\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1382 - val_loss: 0.0817 - val_mae: 0.2001\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1375 - val_loss: 0.0789 - val_mae: 0.2089\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0318 - mae: 0.1427 - val_loss: 0.0762 - val_mae: 0.1971\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1400 - val_loss: 0.0791 - val_mae: 0.1985\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1435 - val_loss: 0.0834 - val_mae: 0.2053\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1433 - val_loss: 0.0782 - val_mae: 0.1951\n",
      "Epoch 216/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0317 - mae: 0.1436 - val_loss: 0.0765 - val_mae: 0.2006\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1389 - val_loss: 0.0765 - val_mae: 0.2020\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0308 - mae: 0.1405 - val_loss: 0.0805 - val_mae: 0.2105\n",
      "Epoch 219/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1431 - val_loss: 0.0769 - val_mae: 0.2006\n",
      "Epoch 220/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1427 - val_loss: 0.0776 - val_mae: 0.2009\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1422 - val_loss: 0.0788 - val_mae: 0.2022\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0306 - mae: 0.1473 - val_loss: 0.0787 - val_mae: 0.2058\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1350 - val_loss: 0.0805 - val_mae: 0.2045\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0310 - mae: 0.1440 - val_loss: 0.0776 - val_mae: 0.2035\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1371 - val_loss: 0.0814 - val_mae: 0.1971\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1362 - val_loss: 0.0794 - val_mae: 0.2102\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1430 - val_loss: 0.0794 - val_mae: 0.2040\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1367 - val_loss: 0.0826 - val_mae: 0.2067\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1418 - val_loss: 0.0806 - val_mae: 0.2095\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1398 - val_loss: 0.0774 - val_mae: 0.1999\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1400 - val_loss: 0.0819 - val_mae: 0.2002\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1396 - val_loss: 0.0782 - val_mae: 0.2065\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1407 - val_loss: 0.0778 - val_mae: 0.2030\n",
      "Epoch 234/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1436 - val_loss: 0.0779 - val_mae: 0.2029\n",
      "Epoch 235/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1411 - val_loss: 0.0772 - val_mae: 0.2025\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1460 - val_loss: 0.0784 - val_mae: 0.1989\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1377 - val_loss: 0.0767 - val_mae: 0.2006\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1442 - val_loss: 0.0768 - val_mae: 0.1989\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1382 - val_loss: 0.0857 - val_mae: 0.2187\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1367 - val_loss: 0.0825 - val_mae: 0.2072\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1432 - val_loss: 0.0784 - val_mae: 0.2052\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0308 - mae: 0.1421 - val_loss: 0.0778 - val_mae: 0.2002\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1415 - val_loss: 0.0755 - val_mae: 0.2061\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1410 - val_loss: 0.0757 - val_mae: 0.2002\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0306 - mae: 0.1414 - val_loss: 0.0756 - val_mae: 0.2024\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1410 - val_loss: 0.0809 - val_mae: 0.2172\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1390 - val_loss: 0.0754 - val_mae: 0.2017\n",
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1417 - val_loss: 0.0804 - val_mae: 0.2134\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1420 - val_loss: 0.0777 - val_mae: 0.2014\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1330 - val_loss: 0.0788 - val_mae: 0.1979\n",
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1411 - val_loss: 0.0787 - val_mae: 0.2100\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1348 - val_loss: 0.0784 - val_mae: 0.2100\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1397 - val_loss: 0.0783 - val_mae: 0.2014\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1411 - val_loss: 0.0765 - val_mae: 0.2029\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1448 - val_loss: 0.0788 - val_mae: 0.2055\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1375 - val_loss: 0.0765 - val_mae: 0.2035\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1373 - val_loss: 0.0822 - val_mae: 0.2172\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1444 - val_loss: 0.0767 - val_mae: 0.2046\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - mae: 0.1468 - val_loss: 0.0767 - val_mae: 0.2022\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1402 - val_loss: 0.0792 - val_mae: 0.2085\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1398 - val_loss: 0.0771 - val_mae: 0.2067\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1395 - val_loss: 0.0883 - val_mae: 0.2279\n",
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1368 - val_loss: 0.0806 - val_mae: 0.2145\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.1383 - val_loss: 0.0814 - val_mae: 0.2041\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0323 - mae: 0.1431 - val_loss: 0.0801 - val_mae: 0.2060\n",
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1388 - val_loss: 0.0799 - val_mae: 0.2083\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1342 - val_loss: 0.0782 - val_mae: 0.2080\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1369 - val_loss: 0.0785 - val_mae: 0.2017\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0298 - mae: 0.1397 - val_loss: 0.0837 - val_mae: 0.2163\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1418 - val_loss: 0.0827 - val_mae: 0.2147\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1381 - val_loss: 0.0784 - val_mae: 0.2068\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1389 - val_loss: 0.0782 - val_mae: 0.2078\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0311 - mae: 0.1441 - val_loss: 0.0791 - val_mae: 0.2076\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1399 - val_loss: 0.0779 - val_mae: 0.2079\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1385 - val_loss: 0.0776 - val_mae: 0.2074\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1403 - val_loss: 0.0773 - val_mae: 0.2039\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1406 - val_loss: 0.0766 - val_mae: 0.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1363 - val_loss: 0.0787 - val_mae: 0.2082\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1426 - val_loss: 0.0779 - val_mae: 0.2101\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1380 - val_loss: 0.0837 - val_mae: 0.2111\n",
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1413 - val_loss: 0.0819 - val_mae: 0.2148\n",
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1368 - val_loss: 0.0798 - val_mae: 0.2155\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1389 - val_loss: 0.0803 - val_mae: 0.2107\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1403 - val_loss: 0.0768 - val_mae: 0.2059\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1422 - val_loss: 0.0795 - val_mae: 0.2040\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1359 - val_loss: 0.0784 - val_mae: 0.2147\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1419 - val_loss: 0.0807 - val_mae: 0.2126\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1401 - val_loss: 0.0788 - val_mae: 0.2085\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1391 - val_loss: 0.0781 - val_mae: 0.2053\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1414 - val_loss: 0.0782 - val_mae: 0.2046\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1404 - val_loss: 0.0772 - val_mae: 0.2071\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1419 - val_loss: 0.0785 - val_mae: 0.2067\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1396 - val_loss: 0.0819 - val_mae: 0.2088\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1404 - val_loss: 0.0810 - val_mae: 0.2210\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1451 - val_loss: 0.0807 - val_mae: 0.2132\n",
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1392 - val_loss: 0.0807 - val_mae: 0.2065\n",
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1397 - val_loss: 0.0805 - val_mae: 0.2055\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1396 - val_loss: 0.0813 - val_mae: 0.2096\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1351 - val_loss: 0.0824 - val_mae: 0.2122\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1365 - val_loss: 0.0829 - val_mae: 0.2132\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1401 - val_loss: 0.0789 - val_mae: 0.2137\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1370 - val_loss: 0.0800 - val_mae: 0.2144\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1395 - val_loss: 0.0789 - val_mae: 0.2125\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1405 - val_loss: 0.0806 - val_mae: 0.2107\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1357 - val_loss: 0.0786 - val_mae: 0.2128\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0286 - mae: 0.1402 - val_loss: 0.0830 - val_mae: 0.2086\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1368 - val_loss: 0.0862 - val_mae: 0.2279\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1365 - val_loss: 0.0813 - val_mae: 0.2193\n",
      "Epoch 309/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1379 - val_loss: 0.0779 - val_mae: 0.2125\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - mae: 0.1432 - val_loss: 0.0771 - val_mae: 0.2051\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1396 - val_loss: 0.0792 - val_mae: 0.2108\n",
      "Epoch 312/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1387 - val_loss: 0.0786 - val_mae: 0.2068\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1332 - val_loss: 0.0827 - val_mae: 0.2181\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1354 - val_loss: 0.0791 - val_mae: 0.2072\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1413 - val_loss: 0.0774 - val_mae: 0.2052\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1376 - val_loss: 0.0777 - val_mae: 0.2063\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1401 - val_loss: 0.0838 - val_mae: 0.2100\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1396 - val_loss: 0.0775 - val_mae: 0.2059\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1354 - val_loss: 0.0767 - val_mae: 0.2069\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1371 - val_loss: 0.0813 - val_mae: 0.2106\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1374 - val_loss: 0.0832 - val_mae: 0.2072\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1380 - val_loss: 0.0784 - val_mae: 0.2065\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1395 - val_loss: 0.0773 - val_mae: 0.2085\n",
      "Epoch 324/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1398 - val_loss: 0.0843 - val_mae: 0.2157\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0296 - mae: 0.1410 - val_loss: 0.0782 - val_mae: 0.2130\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1350 - val_loss: 0.0808 - val_mae: 0.2045\n",
      "Epoch 327/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1363 - val_loss: 0.0799 - val_mae: 0.2053\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1340 - val_loss: 0.0776 - val_mae: 0.2099\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1348 - val_loss: 0.0781 - val_mae: 0.2086\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1412 - val_loss: 0.0808 - val_mae: 0.2198\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - mae: 0.1353 - val_loss: 0.0771 - val_mae: 0.2088\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1389 - val_loss: 0.0848 - val_mae: 0.2119\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0290 - mae: 0.1361 - val_loss: 0.0804 - val_mae: 0.2068\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.1374 - val_loss: 0.0811 - val_mae: 0.2086\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0285 - mae: 0.1386 - val_loss: 0.0819 - val_mae: 0.2201\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1395 - val_loss: 0.0774 - val_mae: 0.2113\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1391 - val_loss: 0.0780 - val_mae: 0.2118\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1416 - val_loss: 0.0781 - val_mae: 0.2091\n",
      "Epoch 339/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1405 - val_loss: 0.0793 - val_mae: 0.2097\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1332 - val_loss: 0.0804 - val_mae: 0.2098\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1387 - val_loss: 0.0781 - val_mae: 0.2088\n",
      "Epoch 342/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1327 - val_loss: 0.0835 - val_mae: 0.2206\n",
      "Epoch 343/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1395 - val_loss: 0.0784 - val_mae: 0.2094\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1414 - val_loss: 0.0794 - val_mae: 0.2097\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1332 - val_loss: 0.0786 - val_mae: 0.2110\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1388 - val_loss: 0.0814 - val_mae: 0.2099\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1412 - val_loss: 0.0803 - val_mae: 0.2085\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1349 - val_loss: 0.0829 - val_mae: 0.2130\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1420 - val_loss: 0.0782 - val_mae: 0.2148\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1386 - val_loss: 0.0773 - val_mae: 0.2097\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1380 - val_loss: 0.0823 - val_mae: 0.2098\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1369 - val_loss: 0.0846 - val_mae: 0.2160\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1334 - val_loss: 0.0784 - val_mae: 0.2118\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1383 - val_loss: 0.0787 - val_mae: 0.2088\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0284 - mae: 0.1367 - val_loss: 0.0803 - val_mae: 0.2093\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1387 - val_loss: 0.0810 - val_mae: 0.2128\n",
      "Epoch 357/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0294 - mae: 0.1360 - val_loss: 0.0800 - val_mae: 0.2114\n",
      "Epoch 358/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1350 - val_loss: 0.0785 - val_mae: 0.2114\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1378 - val_loss: 0.0805 - val_mae: 0.2112\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1323 - val_loss: 0.0812 - val_mae: 0.2198\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.1351 - val_loss: 0.0799 - val_mae: 0.2169\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1348 - val_loss: 0.0791 - val_mae: 0.2126\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0301 - mae: 0.1398 - val_loss: 0.0795 - val_mae: 0.2121\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.1352 - val_loss: 0.0782 - val_mae: 0.2141\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1385 - val_loss: 0.0829 - val_mae: 0.2146\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1412 - val_loss: 0.0855 - val_mae: 0.2270\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1383 - val_loss: 0.0809 - val_mae: 0.2118\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1352 - val_loss: 0.0807 - val_mae: 0.2104\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0295 - mae: 0.1375 - val_loss: 0.0886 - val_mae: 0.2287\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1367 - val_loss: 0.0812 - val_mae: 0.2195\n",
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1363 - val_loss: 0.0805 - val_mae: 0.2119\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1358 - val_loss: 0.0789 - val_mae: 0.2109\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1331 - val_loss: 0.0821 - val_mae: 0.2103\n",
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1364 - val_loss: 0.0847 - val_mae: 0.2120\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1341 - val_loss: 0.0781 - val_mae: 0.2121\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1342 - val_loss: 0.0810 - val_mae: 0.2223\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1381 - val_loss: 0.0843 - val_mae: 0.2129\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1339 - val_loss: 0.0816 - val_mae: 0.2133\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1370 - val_loss: 0.0806 - val_mae: 0.2172\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1348 - val_loss: 0.0804 - val_mae: 0.2179\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1337 - val_loss: 0.0797 - val_mae: 0.2146\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1363 - val_loss: 0.0799 - val_mae: 0.2180\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1367 - val_loss: 0.0803 - val_mae: 0.2120\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1355 - val_loss: 0.0835 - val_mae: 0.2146\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1368 - val_loss: 0.0834 - val_mae: 0.2139\n",
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1383 - val_loss: 0.0813 - val_mae: 0.2182\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1352 - val_loss: 0.0833 - val_mae: 0.2210\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1397 - val_loss: 0.0831 - val_mae: 0.2236\n",
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0301 - mae: 0.1387 - val_loss: 0.0839 - val_mae: 0.2157\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1346 - val_loss: 0.0795 - val_mae: 0.2138\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - mae: 0.1310 - val_loss: 0.0876 - val_mae: 0.2199\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1412 - val_loss: 0.0800 - val_mae: 0.2148\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1383 - val_loss: 0.0799 - val_mae: 0.2143\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1363 - val_loss: 0.0813 - val_mae: 0.2147\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1315 - val_loss: 0.0832 - val_mae: 0.2162\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1329 - val_loss: 0.0840 - val_mae: 0.2201\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1312 - val_loss: 0.0902 - val_mae: 0.2168\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1383 - val_loss: 0.0826 - val_mae: 0.2150\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1326 - val_loss: 0.0909 - val_mae: 0.2176\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1353 - val_loss: 0.0914 - val_mae: 0.2251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1380 - val_loss: 0.0831 - val_mae: 0.2198\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1393 - val_loss: 0.0809 - val_mae: 0.2155\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1313 - val_loss: 0.0829 - val_mae: 0.2165\n",
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1369 - val_loss: 0.0912 - val_mae: 0.2296\n",
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1358 - val_loss: 0.0801 - val_mae: 0.2141\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1330 - val_loss: 0.0807 - val_mae: 0.2210\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1369 - val_loss: 0.0845 - val_mae: 0.2167\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1373 - val_loss: 0.0847 - val_mae: 0.2176\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1326 - val_loss: 0.0819 - val_mae: 0.2179\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1337 - val_loss: 0.0812 - val_mae: 0.2156\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1368 - val_loss: 0.0838 - val_mae: 0.2146\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1346 - val_loss: 0.0809 - val_mae: 0.2208\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1371 - val_loss: 0.0804 - val_mae: 0.2149\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1287 - val_loss: 0.0825 - val_mae: 0.2169\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1378 - val_loss: 0.0812 - val_mae: 0.2134\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1349 - val_loss: 0.0878 - val_mae: 0.2198\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0296 - mae: 0.1387 - val_loss: 0.0804 - val_mae: 0.2155\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1322 - val_loss: 0.0817 - val_mae: 0.2151\n",
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1336 - val_loss: 0.0849 - val_mae: 0.2230\n",
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1334 - val_loss: 0.0826 - val_mae: 0.2135\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1358 - val_loss: 0.0802 - val_mae: 0.2126\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1292 - val_loss: 0.0793 - val_mae: 0.2123\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1322 - val_loss: 0.0891 - val_mae: 0.2315\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1361 - val_loss: 0.0818 - val_mae: 0.2212\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1363 - val_loss: 0.0829 - val_mae: 0.2151\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1345 - val_loss: 0.0808 - val_mae: 0.2143\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1322 - val_loss: 0.0864 - val_mae: 0.2185\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1344 - val_loss: 0.0823 - val_mae: 0.2142\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1373 - val_loss: 0.0839 - val_mae: 0.2150\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1354 - val_loss: 0.0786 - val_mae: 0.2126\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1373 - val_loss: 0.0793 - val_mae: 0.2157\n",
      "Epoch 432/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1318 - val_loss: 0.0807 - val_mae: 0.2175\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1271 - val_loss: 0.0812 - val_mae: 0.2195\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1340 - val_loss: 0.0813 - val_mae: 0.2167\n",
      "Epoch 435/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0286 - mae: 0.1351 - val_loss: 0.0820 - val_mae: 0.2197\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1359 - val_loss: 0.0808 - val_mae: 0.2145\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1334 - val_loss: 0.0822 - val_mae: 0.2197\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1363 - val_loss: 0.0830 - val_mae: 0.2211\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1349 - val_loss: 0.0889 - val_mae: 0.2178\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1366 - val_loss: 0.0819 - val_mae: 0.2155\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1307 - val_loss: 0.0833 - val_mae: 0.2198\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1392 - val_loss: 0.0837 - val_mae: 0.2165\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0300 - mae: 0.1380 - val_loss: 0.0860 - val_mae: 0.2154\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1345 - val_loss: 0.0817 - val_mae: 0.2163\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1326 - val_loss: 0.0852 - val_mae: 0.2189\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1321 - val_loss: 0.0808 - val_mae: 0.2164\n",
      "Epoch 447/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1321 - val_loss: 0.0839 - val_mae: 0.2199\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1246 - val_loss: 0.0870 - val_mae: 0.2251\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1344 - val_loss: 0.0827 - val_mae: 0.2244\n",
      "Epoch 450/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1380 - val_loss: 0.0812 - val_mae: 0.2191\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.1328 - val_loss: 0.0805 - val_mae: 0.2164\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.1371 - val_loss: 0.0806 - val_mae: 0.2168\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1321 - val_loss: 0.0826 - val_mae: 0.2215\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.1342 - val_loss: 0.0866 - val_mae: 0.2194\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1330 - val_loss: 0.0801 - val_mae: 0.2175\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1338 - val_loss: 0.0816 - val_mae: 0.2119\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.1349 - val_loss: 0.0807 - val_mae: 0.2140\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0297 - mae: 0.1382 - val_loss: 0.0804 - val_mae: 0.2156\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0268 - mae: 0.1301 - val_loss: 0.0815 - val_mae: 0.2231\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.1339 - val_loss: 0.0810 - val_mae: 0.2195\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0278 - mae: 0.1338 - val_loss: 0.0823 - val_mae: 0.2179\n",
      "Epoch 462/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1334 - val_loss: 0.0828 - val_mae: 0.2167\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1363 - val_loss: 0.0866 - val_mae: 0.2180\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1297 - val_loss: 0.0870 - val_mae: 0.2263\n",
      "Epoch 465/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1375 - val_loss: 0.0816 - val_mae: 0.2165\n",
      "Epoch 466/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1333 - val_loss: 0.0843 - val_mae: 0.2171\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.1345 - val_loss: 0.0834 - val_mae: 0.2176\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1346 - val_loss: 0.0826 - val_mae: 0.2183\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1311 - val_loss: 0.0823 - val_mae: 0.2221\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0303 - mae: 0.1350 - val_loss: 0.0832 - val_mae: 0.2176\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1356 - val_loss: 0.0826 - val_mae: 0.2169\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1295 - val_loss: 0.0823 - val_mae: 0.2177\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1322 - val_loss: 0.0826 - val_mae: 0.2226\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1361 - val_loss: 0.0831 - val_mae: 0.2155\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1367 - val_loss: 0.0824 - val_mae: 0.2169\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1345 - val_loss: 0.0815 - val_mae: 0.2187\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.1358 - val_loss: 0.0819 - val_mae: 0.2158\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1341 - val_loss: 0.0828 - val_mae: 0.2166\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.1307 - val_loss: 0.0833 - val_mae: 0.2181\n",
      "Epoch 480/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1327 - val_loss: 0.0828 - val_mae: 0.2240\n",
      "Epoch 481/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1361 - val_loss: 0.0863 - val_mae: 0.2180\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1362 - val_loss: 0.0850 - val_mae: 0.2174\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1294 - val_loss: 0.0907 - val_mae: 0.2196\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1368 - val_loss: 0.0821 - val_mae: 0.2177\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1379 - val_loss: 0.0850 - val_mae: 0.2174\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1316 - val_loss: 0.0858 - val_mae: 0.2202\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1323 - val_loss: 0.0839 - val_mae: 0.2182\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1340 - val_loss: 0.0863 - val_mae: 0.2199\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1317 - val_loss: 0.0822 - val_mae: 0.2158\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1326 - val_loss: 0.0820 - val_mae: 0.2149\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1244 - val_loss: 0.0873 - val_mae: 0.2374\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1342 - val_loss: 0.0868 - val_mae: 0.2237\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1329 - val_loss: 0.0825 - val_mae: 0.2177\n",
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1346 - val_loss: 0.0863 - val_mae: 0.2182\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1341 - val_loss: 0.0826 - val_mae: 0.2175\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.1305 - val_loss: 0.0884 - val_mae: 0.2225\n",
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1336 - val_loss: 0.0835 - val_mae: 0.2166\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1403 - val_loss: 0.0852 - val_mae: 0.2184\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1369 - val_loss: 0.0855 - val_mae: 0.2199\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1316 - val_loss: 0.0841 - val_mae: 0.2204\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1315 - val_loss: 0.0842 - val_mae: 0.2194\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1320 - val_loss: 0.0954 - val_mae: 0.2333\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1281 - val_loss: 0.0915 - val_mae: 0.2246\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1340 - val_loss: 0.0830 - val_mae: 0.2141\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1313 - val_loss: 0.0877 - val_mae: 0.2165\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1397 - val_loss: 0.0812 - val_mae: 0.2167\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0269 - mae: 0.1316 - val_loss: 0.0848 - val_mae: 0.2242\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1308 - val_loss: 0.0836 - val_mae: 0.2205\n",
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1385 - val_loss: 0.0820 - val_mae: 0.2180\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1297 - val_loss: 0.0822 - val_mae: 0.2206\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0265 - mae: 0.1284 - val_loss: 0.0869 - val_mae: 0.2226\n",
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1339 - val_loss: 0.0868 - val_mae: 0.2224\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1334 - val_loss: 0.0821 - val_mae: 0.2200\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1291 - val_loss: 0.0866 - val_mae: 0.2183\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1321 - val_loss: 0.0855 - val_mae: 0.2187\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1286 - val_loss: 0.0841 - val_mae: 0.2219\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1345 - val_loss: 0.0846 - val_mae: 0.2243\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1305 - val_loss: 0.0855 - val_mae: 0.2260\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1331 - val_loss: 0.0832 - val_mae: 0.2220\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0282 - mae: 0.1294 - val_loss: 0.0826 - val_mae: 0.2201\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1302 - val_loss: 0.0853 - val_mae: 0.2187\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1338 - val_loss: 0.0850 - val_mae: 0.2189\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1306 - val_loss: 0.0874 - val_mae: 0.2241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1318 - val_loss: 0.0857 - val_mae: 0.2181\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0904 - val_mae: 0.2315\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1366 - val_loss: 0.0834 - val_mae: 0.2186\n",
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1295 - val_loss: 0.0961 - val_mae: 0.2337\n",
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1292 - val_loss: 0.0863 - val_mae: 0.2207\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.1377 - val_loss: 0.0829 - val_mae: 0.2180\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1330 - val_loss: 0.0847 - val_mae: 0.2192\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1289 - val_loss: 0.0851 - val_mae: 0.2188\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1342 - val_loss: 0.0877 - val_mae: 0.2201\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1352 - val_loss: 0.0827 - val_mae: 0.2195\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1333 - val_loss: 0.0869 - val_mae: 0.2243\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1375 - val_loss: 0.0847 - val_mae: 0.2228\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1318 - val_loss: 0.0860 - val_mae: 0.2260\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1338 - val_loss: 0.0832 - val_mae: 0.2205\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1366 - val_loss: 0.0832 - val_mae: 0.2191\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0276 - mae: 0.1306 - val_loss: 0.0833 - val_mae: 0.2230\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1297 - val_loss: 0.0830 - val_mae: 0.2195\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1296 - val_loss: 0.0897 - val_mae: 0.2302\n",
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1331 - val_loss: 0.0825 - val_mae: 0.2192\n",
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0275 - mae: 0.1326 - val_loss: 0.0866 - val_mae: 0.2284\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1304 - val_loss: 0.0867 - val_mae: 0.2250\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1305 - val_loss: 0.0888 - val_mae: 0.2233\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1353 - val_loss: 0.0849 - val_mae: 0.2205\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1292 - val_loss: 0.0824 - val_mae: 0.2188\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1319 - val_loss: 0.0838 - val_mae: 0.2224\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1317 - val_loss: 0.0834 - val_mae: 0.2202\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1303 - val_loss: 0.0867 - val_mae: 0.2214\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1317 - val_loss: 0.0855 - val_mae: 0.2219\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.1325 - val_loss: 0.0824 - val_mae: 0.2205\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1317 - val_loss: 0.0868 - val_mae: 0.2200\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1329 - val_loss: 0.0897 - val_mae: 0.2282\n",
      "Epoch 555/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1353 - val_loss: 0.0834 - val_mae: 0.2169\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1308 - val_loss: 0.0833 - val_mae: 0.2186\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1298 - val_loss: 0.0867 - val_mae: 0.2191\n",
      "Epoch 558/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1311 - val_loss: 0.0856 - val_mae: 0.2208\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1297 - val_loss: 0.0887 - val_mae: 0.2237\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1324 - val_loss: 0.0837 - val_mae: 0.2229\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1329 - val_loss: 0.0858 - val_mae: 0.2229\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1320 - val_loss: 0.0885 - val_mae: 0.2330\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1284 - val_loss: 0.0830 - val_mae: 0.2200\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1338 - val_loss: 0.0827 - val_mae: 0.2186\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1314 - val_loss: 0.0823 - val_mae: 0.2179\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1315 - val_loss: 0.0861 - val_mae: 0.2189\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.1355 - val_loss: 0.0809 - val_mae: 0.2164\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1290 - val_loss: 0.0911 - val_mae: 0.2335\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1378 - val_loss: 0.0822 - val_mae: 0.2178\n",
      "Epoch 570/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.1354 - val_loss: 0.0909 - val_mae: 0.2243\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1320 - val_loss: 0.0855 - val_mae: 0.2214\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1333 - val_loss: 0.0836 - val_mae: 0.2231\n",
      "Epoch 573/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1364 - val_loss: 0.0836 - val_mae: 0.2198\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1312 - val_loss: 0.0829 - val_mae: 0.2227\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.1305 - val_loss: 0.0809 - val_mae: 0.2180\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1272 - val_loss: 0.0826 - val_mae: 0.2186\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1318 - val_loss: 0.0842 - val_mae: 0.2183\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0260 - mae: 0.1256 - val_loss: 0.0833 - val_mae: 0.2181\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1333 - val_loss: 0.0862 - val_mae: 0.2207\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1319 - val_loss: 0.0841 - val_mae: 0.2282\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0905 - val_mae: 0.2240\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1341 - val_loss: 0.0836 - val_mae: 0.2209\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.1346 - val_loss: 0.0846 - val_mae: 0.2201\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1319 - val_loss: 0.0843 - val_mae: 0.2215\n",
      "Epoch 585/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0285 - mae: 0.1345 - val_loss: 0.0878 - val_mae: 0.2223\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1284 - val_loss: 0.0908 - val_mae: 0.2264\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1300 - val_loss: 0.0886 - val_mae: 0.2229\n",
      "Epoch 588/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1350 - val_loss: 0.0872 - val_mae: 0.2225\n",
      "Epoch 589/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1303 - val_loss: 0.0838 - val_mae: 0.2209\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1285 - val_loss: 0.0864 - val_mae: 0.2196\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1306 - val_loss: 0.0849 - val_mae: 0.2192\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1346 - val_loss: 0.0847 - val_mae: 0.2206\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1312 - val_loss: 0.0858 - val_mae: 0.2223\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1337 - val_loss: 0.0887 - val_mae: 0.2211\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0266 - mae: 0.1296 - val_loss: 0.0850 - val_mae: 0.2243\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1342 - val_loss: 0.0861 - val_mae: 0.2209\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1298 - val_loss: 0.0879 - val_mae: 0.2221\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1299 - val_loss: 0.0848 - val_mae: 0.2200\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1332 - val_loss: 0.0848 - val_mae: 0.2192\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1286 - val_loss: 0.0841 - val_mae: 0.2202\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024BB4D88820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024BB4D88820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "6\n",
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.7796 - mae: 0.6398 - val_loss: 0.6228 - val_mae: 0.5548\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3621 - mae: 0.4288 - val_loss: 0.3773 - val_mae: 0.4509\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2855 - mae: 0.4079 - val_loss: 0.3298 - val_mae: 0.4376\n",
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2514 - mae: 0.3883 - val_loss: 0.2935 - val_mae: 0.4190\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2254 - mae: 0.3693 - val_loss: 0.2477 - val_mae: 0.3803\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2039 - mae: 0.3584 - val_loss: 0.2320 - val_mae: 0.3596\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1803 - mae: 0.3337 - val_loss: 0.2139 - val_mae: 0.3421\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1576 - mae: 0.3110 - val_loss: 0.2010 - val_mae: 0.3272\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1383 - mae: 0.2920 - val_loss: 0.1766 - val_mae: 0.2988\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1239 - mae: 0.2755 - val_loss: 0.1598 - val_mae: 0.2744\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1068 - mae: 0.2496 - val_loss: 0.1517 - val_mae: 0.2870\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0947 - mae: 0.2374 - val_loss: 0.1385 - val_mae: 0.2651\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0864 - mae: 0.2250 - val_loss: 0.1324 - val_mae: 0.2569\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0825 - mae: 0.2197 - val_loss: 0.1263 - val_mae: 0.2507\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - mae: 0.2126 - val_loss: 0.1354 - val_mae: 0.2711\n",
      "Epoch 16/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0731 - mae: 0.2113 - val_loss: 0.1241 - val_mae: 0.2504\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - mae: 0.2038 - val_loss: 0.1265 - val_mae: 0.2571\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0697 - mae: 0.2044 - val_loss: 0.1198 - val_mae: 0.2469\n",
      "Epoch 19/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - mae: 0.2014 - val_loss: 0.1151 - val_mae: 0.2401\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0659 - mae: 0.1990 - val_loss: 0.1201 - val_mae: 0.2557\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0642 - mae: 0.1967 - val_loss: 0.1293 - val_mae: 0.2658\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0650 - mae: 0.2009 - val_loss: 0.1135 - val_mae: 0.2408\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - mae: 0.1934 - val_loss: 0.1157 - val_mae: 0.2451\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0615 - mae: 0.1916 - val_loss: 0.1113 - val_mae: 0.2353\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0608 - mae: 0.1950 - val_loss: 0.1086 - val_mae: 0.2330\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0588 - mae: 0.1899 - val_loss: 0.1080 - val_mae: 0.2312\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0565 - mae: 0.1851 - val_loss: 0.1085 - val_mae: 0.2327\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - mae: 0.1940 - val_loss: 0.1135 - val_mae: 0.2497\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - mae: 0.1865 - val_loss: 0.1045 - val_mae: 0.2257\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - mae: 0.1880 - val_loss: 0.1097 - val_mae: 0.2483\n",
      "Epoch 31/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - mae: 0.1823 - val_loss: 0.1060 - val_mae: 0.2322\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - mae: 0.1823 - val_loss: 0.1001 - val_mae: 0.2229\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0539 - mae: 0.1836 - val_loss: 0.1128 - val_mae: 0.2548\n",
      "Epoch 34/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - mae: 0.1786 - val_loss: 0.1009 - val_mae: 0.2272\n",
      "Epoch 35/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0522 - mae: 0.1800 - val_loss: 0.0983 - val_mae: 0.2173\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1781 - val_loss: 0.1057 - val_mae: 0.2443\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0530 - mae: 0.1840 - val_loss: 0.0977 - val_mae: 0.2233\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0518 - mae: 0.1822 - val_loss: 0.0957 - val_mae: 0.2174\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0499 - mae: 0.1781 - val_loss: 0.1054 - val_mae: 0.2456\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - mae: 0.1815 - val_loss: 0.0961 - val_mae: 0.2234\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - mae: 0.1745 - val_loss: 0.0982 - val_mae: 0.2319\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.1731 - val_loss: 0.1006 - val_mae: 0.2374\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0504 - mae: 0.1772 - val_loss: 0.0951 - val_mae: 0.2223\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - mae: 0.1789 - val_loss: 0.0982 - val_mae: 0.2308\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0481 - mae: 0.1745 - val_loss: 0.0964 - val_mae: 0.2214\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0463 - mae: 0.1719 - val_loss: 0.0942 - val_mae: 0.2197\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.1730 - val_loss: 0.0987 - val_mae: 0.2334\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0468 - mae: 0.1718 - val_loss: 0.0988 - val_mae: 0.2197\n",
      "Epoch 49/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1713 - val_loss: 0.0933 - val_mae: 0.2213\n",
      "Epoch 50/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1740 - val_loss: 0.0952 - val_mae: 0.2246\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.1730 - val_loss: 0.0969 - val_mae: 0.2290\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1714 - val_loss: 0.0932 - val_mae: 0.2222\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1701 - val_loss: 0.0913 - val_mae: 0.2176\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 0.1701 - val_loss: 0.0930 - val_mae: 0.2207\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1708 - val_loss: 0.0922 - val_mae: 0.2189\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.1699 - val_loss: 0.0931 - val_mae: 0.2192\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0465 - mae: 0.1708 - val_loss: 0.0911 - val_mae: 0.2168\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0426 - mae: 0.1639 - val_loss: 0.0960 - val_mae: 0.2288\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0459 - mae: 0.1690 - val_loss: 0.0898 - val_mae: 0.2166\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0466 - mae: 0.1684 - val_loss: 0.0895 - val_mae: 0.2158\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0450 - mae: 0.1683 - val_loss: 0.0905 - val_mae: 0.2140\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0452 - mae: 0.1639 - val_loss: 0.0918 - val_mae: 0.2177\n",
      "Epoch 63/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0433 - mae: 0.1600 - val_loss: 0.0930 - val_mae: 0.2252\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1640 - val_loss: 0.0902 - val_mae: 0.2175\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0434 - mae: 0.1670 - val_loss: 0.0871 - val_mae: 0.2120\n",
      "Epoch 66/600\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0451 - mae: 0.1718 - val_loss: 0.0888 - val_mae: 0.2132\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 0.1587 - val_loss: 0.0929 - val_mae: 0.2253\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0440 - mae: 0.1673 - val_loss: 0.0896 - val_mae: 0.2158\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0424 - mae: 0.1648 - val_loss: 0.0876 - val_mae: 0.2151\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0432 - mae: 0.1645 - val_loss: 0.0898 - val_mae: 0.2204\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1629 - val_loss: 0.0874 - val_mae: 0.2122\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0426 - mae: 0.1622 - val_loss: 0.0901 - val_mae: 0.2151\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.1669 - val_loss: 0.0880 - val_mae: 0.2137\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0407 - mae: 0.1567 - val_loss: 0.0868 - val_mae: 0.2131\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1644 - val_loss: 0.0873 - val_mae: 0.2162\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 0.1621 - val_loss: 0.0867 - val_mae: 0.2130\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1586 - val_loss: 0.0867 - val_mae: 0.2149\n",
      "Epoch 78/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1627 - val_loss: 0.0873 - val_mae: 0.2152\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0408 - mae: 0.1602 - val_loss: 0.0860 - val_mae: 0.2173\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - mae: 0.1598 - val_loss: 0.0894 - val_mae: 0.2197\n",
      "Epoch 81/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1632 - val_loss: 0.0846 - val_mae: 0.2124\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.1603 - val_loss: 0.0881 - val_mae: 0.2204\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1580 - val_loss: 0.0864 - val_mae: 0.2142\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1563 - val_loss: 0.0955 - val_mae: 0.2310\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1594 - val_loss: 0.0871 - val_mae: 0.2146\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1591 - val_loss: 0.0861 - val_mae: 0.2156\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1568 - val_loss: 0.0850 - val_mae: 0.2138\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - mae: 0.1578 - val_loss: 0.0854 - val_mae: 0.2156\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1594 - val_loss: 0.0835 - val_mae: 0.2106\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1596 - val_loss: 0.0867 - val_mae: 0.2186\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1576 - val_loss: 0.0859 - val_mae: 0.2136\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.1558 - val_loss: 0.0862 - val_mae: 0.2171\n",
      "Epoch 93/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0397 - mae: 0.1592 - val_loss: 0.0893 - val_mae: 0.2256\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.1569 - val_loss: 0.0834 - val_mae: 0.2188\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1501 - val_loss: 0.0902 - val_mae: 0.2273\n",
      "Epoch 96/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0401 - mae: 0.1617 - val_loss: 0.0864 - val_mae: 0.2209\n",
      "Epoch 97/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1562 - val_loss: 0.0901 - val_mae: 0.2260\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1585 - val_loss: 0.0865 - val_mae: 0.2196\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0396 - mae: 0.1581 - val_loss: 0.0842 - val_mae: 0.2188\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0386 - mae: 0.1568 - val_loss: 0.0855 - val_mae: 0.2217\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1575 - val_loss: 0.0844 - val_mae: 0.2147\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1586 - val_loss: 0.0851 - val_mae: 0.2158\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1572 - val_loss: 0.0840 - val_mae: 0.2205\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1554 - val_loss: 0.0833 - val_mae: 0.2154\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1545 - val_loss: 0.0905 - val_mae: 0.2243\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1560 - val_loss: 0.0848 - val_mae: 0.2180\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1573 - val_loss: 0.0846 - val_mae: 0.2138\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1552 - val_loss: 0.0826 - val_mae: 0.2137\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0368 - mae: 0.1536 - val_loss: 0.0866 - val_mae: 0.2163\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - mae: 0.1558 - val_loss: 0.0824 - val_mae: 0.2152\n",
      "Epoch 111/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0370 - mae: 0.1578 - val_loss: 0.0818 - val_mae: 0.2142\n",
      "Epoch 112/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - mae: 0.1487 - val_loss: 0.0822 - val_mae: 0.2190\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1527 - val_loss: 0.0886 - val_mae: 0.2234\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - mae: 0.1559 - val_loss: 0.0825 - val_mae: 0.2177\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1515 - val_loss: 0.0919 - val_mae: 0.2308\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0386 - mae: 0.1607 - val_loss: 0.0815 - val_mae: 0.2186\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1522 - val_loss: 0.0878 - val_mae: 0.2255\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0375 - mae: 0.1558 - val_loss: 0.0860 - val_mae: 0.2154\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0367 - mae: 0.1512 - val_loss: 0.0836 - val_mae: 0.2196\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0358 - mae: 0.1497 - val_loss: 0.0844 - val_mae: 0.2169\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0376 - mae: 0.1563 - val_loss: 0.0824 - val_mae: 0.2206\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0372 - mae: 0.1544 - val_loss: 0.0823 - val_mae: 0.2186\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0353 - mae: 0.1530 - val_loss: 0.0855 - val_mae: 0.2256\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0354 - mae: 0.1494 - val_loss: 0.0828 - val_mae: 0.2235\n",
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1501 - val_loss: 0.0924 - val_mae: 0.2213\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0359 - mae: 0.1469 - val_loss: 0.0818 - val_mae: 0.2172\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0376 - mae: 0.1536 - val_loss: 0.0820 - val_mae: 0.2220\n",
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1517 - val_loss: 0.0857 - val_mae: 0.2233\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0345 - mae: 0.1484 - val_loss: 0.0846 - val_mae: 0.2147\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1505 - val_loss: 0.0842 - val_mae: 0.2203\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1540 - val_loss: 0.0820 - val_mae: 0.2230\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1507 - val_loss: 0.0839 - val_mae: 0.2219\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1495 - val_loss: 0.0861 - val_mae: 0.2280\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0369 - mae: 0.1567 - val_loss: 0.0841 - val_mae: 0.2233\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - mae: 0.1543 - val_loss: 0.0832 - val_mae: 0.2244\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.1571 - val_loss: 0.0824 - val_mae: 0.2225\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1517 - val_loss: 0.0844 - val_mae: 0.2188\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.1511 - val_loss: 0.0831 - val_mae: 0.2204\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.1512 - val_loss: 0.0827 - val_mae: 0.2185\n",
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.1481 - val_loss: 0.0823 - val_mae: 0.2238\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0344 - mae: 0.1466 - val_loss: 0.0847 - val_mae: 0.2287\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0371 - mae: 0.1579 - val_loss: 0.0843 - val_mae: 0.2294\n",
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1529 - val_loss: 0.0850 - val_mae: 0.2222\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1505 - val_loss: 0.0853 - val_mae: 0.2158\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0347 - mae: 0.1518 - val_loss: 0.0913 - val_mae: 0.2219\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.1535 - val_loss: 0.0834 - val_mae: 0.2225\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - mae: 0.1507 - val_loss: 0.0821 - val_mae: 0.2261\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0358 - mae: 0.1526 - val_loss: 0.0813 - val_mae: 0.2193\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.1557 - val_loss: 0.0830 - val_mae: 0.2201\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0351 - mae: 0.1485 - val_loss: 0.0823 - val_mae: 0.2198\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1521 - val_loss: 0.0852 - val_mae: 0.2229\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1549 - val_loss: 0.0814 - val_mae: 0.2233\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1479 - val_loss: 0.0828 - val_mae: 0.2266\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0354 - mae: 0.1498 - val_loss: 0.0832 - val_mae: 0.2184\n",
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1552 - val_loss: 0.0825 - val_mae: 0.2220\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1524 - val_loss: 0.0846 - val_mae: 0.2184\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1505 - val_loss: 0.0830 - val_mae: 0.2204\n",
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.1483 - val_loss: 0.0861 - val_mae: 0.2217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0349 - mae: 0.1533 - val_loss: 0.0828 - val_mae: 0.2277\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0344 - mae: 0.1502 - val_loss: 0.0848 - val_mae: 0.2203\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0359 - mae: 0.1519 - val_loss: 0.0818 - val_mae: 0.2216\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0356 - mae: 0.1542 - val_loss: 0.0812 - val_mae: 0.2240\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0361 - mae: 0.1519 - val_loss: 0.0835 - val_mae: 0.2212\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1465 - val_loss: 0.0859 - val_mae: 0.2324\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0356 - mae: 0.1509 - val_loss: 0.0840 - val_mae: 0.2295\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0354 - mae: 0.1529 - val_loss: 0.0863 - val_mae: 0.2196\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0339 - mae: 0.1434 - val_loss: 0.0824 - val_mae: 0.2240\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0354 - mae: 0.1532 - val_loss: 0.0874 - val_mae: 0.2236\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0359 - mae: 0.1548 - val_loss: 0.0824 - val_mae: 0.2178\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0346 - mae: 0.1506 - val_loss: 0.0827 - val_mae: 0.2266\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0331 - mae: 0.1466 - val_loss: 0.0840 - val_mae: 0.2265\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0345 - mae: 0.1533 - val_loss: 0.0834 - val_mae: 0.2233\n",
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0342 - mae: 0.1481 - val_loss: 0.0853 - val_mae: 0.2228\n",
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0327 - mae: 0.1485 - val_loss: 0.0835 - val_mae: 0.2279\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0333 - mae: 0.1478 - val_loss: 0.0855 - val_mae: 0.2325\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0348 - mae: 0.1523 - val_loss: 0.0848 - val_mae: 0.2238\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0348 - mae: 0.1479 - val_loss: 0.0827 - val_mae: 0.2223\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0345 - mae: 0.1526 - val_loss: 0.0852 - val_mae: 0.2320\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1480 - val_loss: 0.0891 - val_mae: 0.2352\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0349 - mae: 0.1520 - val_loss: 0.0821 - val_mae: 0.2251\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0331 - mae: 0.1461 - val_loss: 0.0853 - val_mae: 0.2304\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0358 - mae: 0.1558 - val_loss: 0.0842 - val_mae: 0.2205\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1494 - val_loss: 0.0852 - val_mae: 0.2186\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1560 - val_loss: 0.0831 - val_mae: 0.2265\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1470 - val_loss: 0.0832 - val_mae: 0.2244\n",
      "Epoch 186/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0345 - mae: 0.1504 - val_loss: 0.0829 - val_mae: 0.2187\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0332 - mae: 0.1494 - val_loss: 0.0853 - val_mae: 0.2276\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0343 - mae: 0.1526 - val_loss: 0.0844 - val_mae: 0.2206\n",
      "Epoch 189/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0349 - mae: 0.1509 - val_loss: 0.0847 - val_mae: 0.2255\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0338 - mae: 0.1505 - val_loss: 0.0840 - val_mae: 0.2232\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0335 - mae: 0.1448 - val_loss: 0.0895 - val_mae: 0.2267\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0337 - mae: 0.1488 - val_loss: 0.0828 - val_mae: 0.2196\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1476 - val_loss: 0.0824 - val_mae: 0.2209\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0359 - mae: 0.1542 - val_loss: 0.0814 - val_mae: 0.2219\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1550 - val_loss: 0.0853 - val_mae: 0.2177\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1515 - val_loss: 0.0854 - val_mae: 0.2289\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.1490 - val_loss: 0.0856 - val_mae: 0.2188\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0338 - mae: 0.1531 - val_loss: 0.0876 - val_mae: 0.2261\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1519 - val_loss: 0.0837 - val_mae: 0.2272\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0331 - mae: 0.1528 - val_loss: 0.0865 - val_mae: 0.2241\n",
      "Epoch 201/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0345 - mae: 0.1515 - val_loss: 0.0846 - val_mae: 0.2212\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1447 - val_loss: 0.0828 - val_mae: 0.2249\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0332 - mae: 0.1510 - val_loss: 0.0846 - val_mae: 0.2260\n",
      "Epoch 204/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0343 - mae: 0.1508 - val_loss: 0.0847 - val_mae: 0.2200\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0337 - mae: 0.1494 - val_loss: 0.0844 - val_mae: 0.2205\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0336 - mae: 0.1511 - val_loss: 0.0810 - val_mae: 0.2201\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0335 - mae: 0.1480 - val_loss: 0.0832 - val_mae: 0.2178\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0330 - mae: 0.1519 - val_loss: 0.0839 - val_mae: 0.2220\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1522 - val_loss: 0.0841 - val_mae: 0.2172\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1513 - val_loss: 0.0821 - val_mae: 0.2221\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1534 - val_loss: 0.0821 - val_mae: 0.2210\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1427 - val_loss: 0.0836 - val_mae: 0.2186\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1536 - val_loss: 0.0825 - val_mae: 0.2200\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0336 - mae: 0.1477 - val_loss: 0.0834 - val_mae: 0.2235\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1445 - val_loss: 0.0896 - val_mae: 0.2331\n",
      "Epoch 216/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0337 - mae: 0.1520 - val_loss: 0.0814 - val_mae: 0.2227\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0332 - mae: 0.1512 - val_loss: 0.0807 - val_mae: 0.2213\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0322 - mae: 0.1484 - val_loss: 0.0841 - val_mae: 0.2237\n",
      "Epoch 219/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0328 - mae: 0.1481 - val_loss: 0.0818 - val_mae: 0.2231\n",
      "Epoch 220/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0344 - mae: 0.1539 - val_loss: 0.0901 - val_mae: 0.2235\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0350 - mae: 0.1545 - val_loss: 0.0817 - val_mae: 0.2233\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1488 - val_loss: 0.0821 - val_mae: 0.2217\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0333 - mae: 0.1509 - val_loss: 0.0799 - val_mae: 0.2223\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1484 - val_loss: 0.0815 - val_mae: 0.2168\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0316 - mae: 0.1433 - val_loss: 0.0815 - val_mae: 0.2230\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1525 - val_loss: 0.0849 - val_mae: 0.2177\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1508 - val_loss: 0.0845 - val_mae: 0.2204\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1447 - val_loss: 0.0806 - val_mae: 0.2223\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0325 - mae: 0.1461 - val_loss: 0.0840 - val_mae: 0.2220\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0329 - mae: 0.1496 - val_loss: 0.0842 - val_mae: 0.2189\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0331 - mae: 0.1519 - val_loss: 0.0828 - val_mae: 0.2180\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0337 - mae: 0.1528 - val_loss: 0.0805 - val_mae: 0.2203\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0339 - mae: 0.1515 - val_loss: 0.0831 - val_mae: 0.2196\n",
      "Epoch 234/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0334 - mae: 0.1495 - val_loss: 0.0838 - val_mae: 0.2197\n",
      "Epoch 235/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1368 - val_loss: 0.0844 - val_mae: 0.2195\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0313 - mae: 0.1419 - val_loss: 0.0818 - val_mae: 0.2219\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0335 - mae: 0.1547 - val_loss: 0.0871 - val_mae: 0.2176\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0328 - mae: 0.1505 - val_loss: 0.0815 - val_mae: 0.2224\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0333 - mae: 0.1516 - val_loss: 0.0843 - val_mae: 0.2181\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0333 - mae: 0.1517 - val_loss: 0.0851 - val_mae: 0.2215\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0325 - mae: 0.1509 - val_loss: 0.0815 - val_mae: 0.2206\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1489 - val_loss: 0.0806 - val_mae: 0.2229\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0321 - mae: 0.1513 - val_loss: 0.0819 - val_mae: 0.2212\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0343 - mae: 0.1535 - val_loss: 0.0812 - val_mae: 0.2216\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0325 - mae: 0.1518 - val_loss: 0.0813 - val_mae: 0.2258\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0347 - mae: 0.1585 - val_loss: 0.0802 - val_mae: 0.2210\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1494 - val_loss: 0.0824 - val_mae: 0.2191\n",
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1498 - val_loss: 0.0805 - val_mae: 0.2208\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1471 - val_loss: 0.0842 - val_mae: 0.2196\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1541 - val_loss: 0.0825 - val_mae: 0.2221\n",
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0344 - mae: 0.1543 - val_loss: 0.0802 - val_mae: 0.2202\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1484 - val_loss: 0.0834 - val_mae: 0.2160\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0321 - mae: 0.1481 - val_loss: 0.0809 - val_mae: 0.2236\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1541 - val_loss: 0.0828 - val_mae: 0.2194\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0313 - mae: 0.1468 - val_loss: 0.0831 - val_mae: 0.2212\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.1515 - val_loss: 0.0821 - val_mae: 0.2183\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1498 - val_loss: 0.0862 - val_mae: 0.2199\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1525 - val_loss: 0.0811 - val_mae: 0.2166\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - mae: 0.1500 - val_loss: 0.0799 - val_mae: 0.2185\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1481 - val_loss: 0.0798 - val_mae: 0.2199\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1503 - val_loss: 0.0824 - val_mae: 0.2162\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1425 - val_loss: 0.0835 - val_mae: 0.2144\n",
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1466 - val_loss: 0.0830 - val_mae: 0.2334\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0329 - mae: 0.1522 - val_loss: 0.0802 - val_mae: 0.2179\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1500 - val_loss: 0.0823 - val_mae: 0.2162\n",
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0311 - mae: 0.1453 - val_loss: 0.0806 - val_mae: 0.2212\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0323 - mae: 0.1484 - val_loss: 0.0831 - val_mae: 0.2164\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - mae: 0.1422 - val_loss: 0.0793 - val_mae: 0.2175\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1505 - val_loss: 0.0854 - val_mae: 0.2144\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1520 - val_loss: 0.0804 - val_mae: 0.2171\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.1411 - val_loss: 0.0826 - val_mae: 0.2197\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1448 - val_loss: 0.0855 - val_mae: 0.2205\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1502 - val_loss: 0.0793 - val_mae: 0.2175\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1465 - val_loss: 0.0791 - val_mae: 0.2157\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1468 - val_loss: 0.0860 - val_mae: 0.2158\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.1472 - val_loss: 0.0800 - val_mae: 0.2141\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1486 - val_loss: 0.0801 - val_mae: 0.2246\n",
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0344 - mae: 0.1541 - val_loss: 0.0793 - val_mae: 0.2210\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1489 - val_loss: 0.0793 - val_mae: 0.2157\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0307 - mae: 0.1459 - val_loss: 0.0824 - val_mae: 0.2120\n",
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1456 - val_loss: 0.0794 - val_mae: 0.2152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1467 - val_loss: 0.0856 - val_mae: 0.2113\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1456 - val_loss: 0.0823 - val_mae: 0.2270\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0343 - mae: 0.1546 - val_loss: 0.0808 - val_mae: 0.2157\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1520 - val_loss: 0.0816 - val_mae: 0.2194\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - mae: 0.1480 - val_loss: 0.0828 - val_mae: 0.2335\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - mae: 0.1445 - val_loss: 0.0794 - val_mae: 0.2139\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1487 - val_loss: 0.0798 - val_mae: 0.2154\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1490 - val_loss: 0.0851 - val_mae: 0.2135\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1448 - val_loss: 0.0825 - val_mae: 0.2152\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1458 - val_loss: 0.0813 - val_mae: 0.2127\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1479 - val_loss: 0.0835 - val_mae: 0.2154\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1477 - val_loss: 0.0789 - val_mae: 0.2156\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1447 - val_loss: 0.0799 - val_mae: 0.2193\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1479 - val_loss: 0.0783 - val_mae: 0.2156\n",
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1530 - val_loss: 0.0786 - val_mae: 0.2140\n",
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1490 - val_loss: 0.0900 - val_mae: 0.2192\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.1512 - val_loss: 0.0816 - val_mae: 0.2130\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1460 - val_loss: 0.0795 - val_mae: 0.2116\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1462 - val_loss: 0.0835 - val_mae: 0.2112\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1365 - val_loss: 0.0895 - val_mae: 0.2110\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1519 - val_loss: 0.0795 - val_mae: 0.2084\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0315 - mae: 0.1493 - val_loss: 0.0781 - val_mae: 0.2130\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1412 - val_loss: 0.0783 - val_mae: 0.2135\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0314 - mae: 0.1477 - val_loss: 0.0784 - val_mae: 0.2116\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1490 - val_loss: 0.0814 - val_mae: 0.2119\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1508 - val_loss: 0.0801 - val_mae: 0.2141\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1462 - val_loss: 0.0807 - val_mae: 0.2171\n",
      "Epoch 309/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1498 - val_loss: 0.0818 - val_mae: 0.2223\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1449 - val_loss: 0.0854 - val_mae: 0.2120\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1435 - val_loss: 0.0782 - val_mae: 0.2163\n",
      "Epoch 312/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1471 - val_loss: 0.0788 - val_mae: 0.2254\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1449 - val_loss: 0.0810 - val_mae: 0.2161\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1498 - val_loss: 0.0842 - val_mae: 0.2114\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.1530 - val_loss: 0.0820 - val_mae: 0.2093\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0321 - mae: 0.1492 - val_loss: 0.0795 - val_mae: 0.2110\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1430 - val_loss: 0.0852 - val_mae: 0.2191\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1416 - val_loss: 0.0773 - val_mae: 0.2100\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1457 - val_loss: 0.0791 - val_mae: 0.2138\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1430 - val_loss: 0.0838 - val_mae: 0.2145\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1479 - val_loss: 0.0809 - val_mae: 0.2186\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1491 - val_loss: 0.0812 - val_mae: 0.2119\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1454 - val_loss: 0.0803 - val_mae: 0.2110\n",
      "Epoch 324/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - mae: 0.1445 - val_loss: 0.0787 - val_mae: 0.2124\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1467 - val_loss: 0.0842 - val_mae: 0.2338\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1464 - val_loss: 0.0820 - val_mae: 0.2150\n",
      "Epoch 327/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0315 - mae: 0.1458 - val_loss: 0.0824 - val_mae: 0.2104\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1450 - val_loss: 0.0818 - val_mae: 0.2120\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0319 - mae: 0.1464 - val_loss: 0.0816 - val_mae: 0.2100\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1477 - val_loss: 0.0801 - val_mae: 0.2128\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0319 - mae: 0.1473 - val_loss: 0.0789 - val_mae: 0.2111\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0317 - mae: 0.1455 - val_loss: 0.0793 - val_mae: 0.2203\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1390 - val_loss: 0.0782 - val_mae: 0.2134\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1481 - val_loss: 0.0791 - val_mae: 0.2205\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1454 - val_loss: 0.0837 - val_mae: 0.2082\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1464 - val_loss: 0.0788 - val_mae: 0.2101\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1452 - val_loss: 0.0810 - val_mae: 0.2236\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1469 - val_loss: 0.0783 - val_mae: 0.2151\n",
      "Epoch 339/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0328 - mae: 0.1489 - val_loss: 0.0811 - val_mae: 0.2087\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1431 - val_loss: 0.0787 - val_mae: 0.2120\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1491 - val_loss: 0.0835 - val_mae: 0.2093\n",
      "Epoch 342/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - mae: 0.1449 - val_loss: 0.0779 - val_mae: 0.2108\n",
      "Epoch 343/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1452 - val_loss: 0.0782 - val_mae: 0.2116\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - mae: 0.1464 - val_loss: 0.0783 - val_mae: 0.2114\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0311 - mae: 0.1457 - val_loss: 0.0802 - val_mae: 0.2087\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1451 - val_loss: 0.0788 - val_mae: 0.2148\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0325 - mae: 0.1478 - val_loss: 0.0796 - val_mae: 0.2136\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1461 - val_loss: 0.0788 - val_mae: 0.2174\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1421 - val_loss: 0.0811 - val_mae: 0.2186\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1447 - val_loss: 0.0821 - val_mae: 0.2253\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - mae: 0.1474 - val_loss: 0.0801 - val_mae: 0.2073\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1488 - val_loss: 0.0790 - val_mae: 0.2094\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0305 - mae: 0.1438 - val_loss: 0.0803 - val_mae: 0.2116\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0310 - mae: 0.1456 - val_loss: 0.0795 - val_mae: 0.2093\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1488 - val_loss: 0.0788 - val_mae: 0.2176\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1497 - val_loss: 0.0784 - val_mae: 0.2102\n",
      "Epoch 357/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1418 - val_loss: 0.0781 - val_mae: 0.2142\n",
      "Epoch 358/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1449 - val_loss: 0.0832 - val_mae: 0.2127\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1424 - val_loss: 0.0799 - val_mae: 0.2065\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1443 - val_loss: 0.0791 - val_mae: 0.2059\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1482 - val_loss: 0.0830 - val_mae: 0.2068\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1453 - val_loss: 0.0810 - val_mae: 0.2165\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1480 - val_loss: 0.0792 - val_mae: 0.2091\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1443 - val_loss: 0.0866 - val_mae: 0.2151\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1441 - val_loss: 0.0785 - val_mae: 0.2138\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1508 - val_loss: 0.0779 - val_mae: 0.2139\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1470 - val_loss: 0.0792 - val_mae: 0.2082\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1421 - val_loss: 0.0824 - val_mae: 0.2120\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1420 - val_loss: 0.0777 - val_mae: 0.2091\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1452 - val_loss: 0.0876 - val_mae: 0.2092\n",
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1385 - val_loss: 0.0821 - val_mae: 0.2287\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0297 - mae: 0.1404 - val_loss: 0.0799 - val_mae: 0.2243\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1453 - val_loss: 0.0782 - val_mae: 0.2060\n",
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1442 - val_loss: 0.0803 - val_mae: 0.2078\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1442 - val_loss: 0.0813 - val_mae: 0.2059\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1487 - val_loss: 0.0791 - val_mae: 0.2225\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1458 - val_loss: 0.0804 - val_mae: 0.2309\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1459 - val_loss: 0.0778 - val_mae: 0.2091\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1485 - val_loss: 0.0798 - val_mae: 0.2075\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1470 - val_loss: 0.0778 - val_mae: 0.2097\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - mae: 0.1455 - val_loss: 0.0792 - val_mae: 0.2266\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.1436 - val_loss: 0.0862 - val_mae: 0.2164\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1454 - val_loss: 0.0813 - val_mae: 0.2219\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1464 - val_loss: 0.0839 - val_mae: 0.2091\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1399 - val_loss: 0.0842 - val_mae: 0.2099\n",
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1461 - val_loss: 0.0810 - val_mae: 0.2077\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0313 - mae: 0.1464 - val_loss: 0.0794 - val_mae: 0.2127\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1472 - val_loss: 0.0815 - val_mae: 0.2048\n",
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0305 - mae: 0.1402 - val_loss: 0.0776 - val_mae: 0.2107\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - mae: 0.1490 - val_loss: 0.0781 - val_mae: 0.2070\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1433 - val_loss: 0.0774 - val_mae: 0.2131\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1455 - val_loss: 0.0794 - val_mae: 0.2139\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1372 - val_loss: 0.0831 - val_mae: 0.2344\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1436 - val_loss: 0.0797 - val_mae: 0.2101\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1495 - val_loss: 0.0790 - val_mae: 0.2201\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1513 - val_loss: 0.0804 - val_mae: 0.2206\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1447 - val_loss: 0.0798 - val_mae: 0.2210\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1410 - val_loss: 0.0827 - val_mae: 0.2094\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1420 - val_loss: 0.0790 - val_mae: 0.2177\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1442 - val_loss: 0.0882 - val_mae: 0.2065\n",
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - mae: 0.1451 - val_loss: 0.0793 - val_mae: 0.2122\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1457 - val_loss: 0.0795 - val_mae: 0.2122\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1417 - val_loss: 0.0792 - val_mae: 0.2081\n",
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1466 - val_loss: 0.0811 - val_mae: 0.2165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1453 - val_loss: 0.0799 - val_mae: 0.2089\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1390 - val_loss: 0.0791 - val_mae: 0.2133\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1436 - val_loss: 0.0810 - val_mae: 0.2051\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0285 - mae: 0.1413 - val_loss: 0.0893 - val_mae: 0.2290\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1445 - val_loss: 0.0782 - val_mae: 0.2221\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1377 - val_loss: 0.0826 - val_mae: 0.2130\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1421 - val_loss: 0.0786 - val_mae: 0.2064\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1467 - val_loss: 0.0789 - val_mae: 0.2270\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1463 - val_loss: 0.0814 - val_mae: 0.2059\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - mae: 0.1425 - val_loss: 0.0803 - val_mae: 0.2133\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1401 - val_loss: 0.0807 - val_mae: 0.2085\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0307 - mae: 0.1481 - val_loss: 0.0792 - val_mae: 0.2177\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1404 - val_loss: 0.0776 - val_mae: 0.2095\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1450 - val_loss: 0.0793 - val_mae: 0.2101\n",
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1426 - val_loss: 0.0807 - val_mae: 0.2116\n",
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1397 - val_loss: 0.0871 - val_mae: 0.2137\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1442 - val_loss: 0.0799 - val_mae: 0.2098\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1412 - val_loss: 0.0865 - val_mae: 0.2363\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1466 - val_loss: 0.0809 - val_mae: 0.2106\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - mae: 0.1469 - val_loss: 0.0805 - val_mae: 0.2114\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0298 - mae: 0.1416 - val_loss: 0.0796 - val_mae: 0.2120\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1424 - val_loss: 0.0804 - val_mae: 0.2073\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1405 - val_loss: 0.0797 - val_mae: 0.2198\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0314 - mae: 0.1448 - val_loss: 0.0827 - val_mae: 0.2071\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1443 - val_loss: 0.0842 - val_mae: 0.2093\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1449 - val_loss: 0.0793 - val_mae: 0.2136\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - mae: 0.1417 - val_loss: 0.0793 - val_mae: 0.2134\n",
      "Epoch 432/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0308 - mae: 0.1436 - val_loss: 0.0794 - val_mae: 0.2120\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1384 - val_loss: 0.0905 - val_mae: 0.2257\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.1408 - val_loss: 0.0907 - val_mae: 0.2251\n",
      "Epoch 435/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1474 - val_loss: 0.0838 - val_mae: 0.2185\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1410 - val_loss: 0.0797 - val_mae: 0.2197\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1345 - val_loss: 0.0906 - val_mae: 0.2115\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0286 - mae: 0.1362 - val_loss: 0.0831 - val_mae: 0.2160\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1463 - val_loss: 0.0821 - val_mae: 0.2122\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1446 - val_loss: 0.0812 - val_mae: 0.2064\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1500 - val_loss: 0.0807 - val_mae: 0.2062\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1429 - val_loss: 0.0799 - val_mae: 0.2107\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1410 - val_loss: 0.0807 - val_mae: 0.2270\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1432 - val_loss: 0.0839 - val_mae: 0.2152\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1385 - val_loss: 0.0933 - val_mae: 0.2381\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1400 - val_loss: 0.0834 - val_mae: 0.2195\n",
      "Epoch 447/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1399 - val_loss: 0.0832 - val_mae: 0.2126\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1396 - val_loss: 0.0807 - val_mae: 0.2148\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1408 - val_loss: 0.0869 - val_mae: 0.2195\n",
      "Epoch 450/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1418 - val_loss: 0.0816 - val_mae: 0.2247\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1380 - val_loss: 0.0883 - val_mae: 0.2194\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1367 - val_loss: 0.0788 - val_mae: 0.2175\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1413 - val_loss: 0.0810 - val_mae: 0.2092\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - mae: 0.1461 - val_loss: 0.0812 - val_mae: 0.2073\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1445 - val_loss: 0.0812 - val_mae: 0.2091\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0298 - mae: 0.1421 - val_loss: 0.0828 - val_mae: 0.2070\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0301 - mae: 0.1398 - val_loss: 0.0830 - val_mae: 0.2285\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1403 - val_loss: 0.0916 - val_mae: 0.2338\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1449 - val_loss: 0.0795 - val_mae: 0.2129\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1434 - val_loss: 0.0806 - val_mae: 0.2111\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1398 - val_loss: 0.0792 - val_mae: 0.2223\n",
      "Epoch 462/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1430 - val_loss: 0.0810 - val_mae: 0.2118\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - mae: 0.1471 - val_loss: 0.0833 - val_mae: 0.2089\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0304 - mae: 0.1453 - val_loss: 0.0797 - val_mae: 0.2122\n",
      "Epoch 465/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1439 - val_loss: 0.0835 - val_mae: 0.2287\n",
      "Epoch 466/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0295 - mae: 0.1411 - val_loss: 0.0792 - val_mae: 0.2114\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1390 - val_loss: 0.0842 - val_mae: 0.2106\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0309 - mae: 0.1396 - val_loss: 0.0788 - val_mae: 0.2184\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - mae: 0.1406 - val_loss: 0.0806 - val_mae: 0.2093\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - mae: 0.1413 - val_loss: 0.0852 - val_mae: 0.2097\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1425 - val_loss: 0.0816 - val_mae: 0.2135\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1425 - val_loss: 0.0881 - val_mae: 0.2085\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1385 - val_loss: 0.0806 - val_mae: 0.2121\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1392 - val_loss: 0.0878 - val_mae: 0.2197\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0297 - mae: 0.1410 - val_loss: 0.0820 - val_mae: 0.2120\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1431 - val_loss: 0.0850 - val_mae: 0.2087\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1445 - val_loss: 0.0810 - val_mae: 0.2262\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0297 - mae: 0.1432 - val_loss: 0.0837 - val_mae: 0.2077\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1441 - val_loss: 0.0796 - val_mae: 0.2181\n",
      "Epoch 480/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1387 - val_loss: 0.0811 - val_mae: 0.2133\n",
      "Epoch 481/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1416 - val_loss: 0.0824 - val_mae: 0.2072\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1441 - val_loss: 0.0810 - val_mae: 0.2092\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0319 - mae: 0.1447 - val_loss: 0.0798 - val_mae: 0.2118\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1384 - val_loss: 0.0796 - val_mae: 0.2157\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1440 - val_loss: 0.0810 - val_mae: 0.2144\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0306 - mae: 0.1442 - val_loss: 0.0827 - val_mae: 0.2198\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.1443 - val_loss: 0.0808 - val_mae: 0.2125\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1474 - val_loss: 0.0796 - val_mae: 0.2204\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1404 - val_loss: 0.0812 - val_mae: 0.2104\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0303 - mae: 0.1424 - val_loss: 0.0807 - val_mae: 0.2242\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1399 - val_loss: 0.0828 - val_mae: 0.2082\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1395 - val_loss: 0.0813 - val_mae: 0.2261\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1377 - val_loss: 0.0818 - val_mae: 0.2106\n",
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0287 - mae: 0.1395 - val_loss: 0.0866 - val_mae: 0.2089\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0301 - mae: 0.1391 - val_loss: 0.0814 - val_mae: 0.2236\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1396 - val_loss: 0.0860 - val_mae: 0.2183\n",
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1383 - val_loss: 0.0812 - val_mae: 0.2216\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0302 - mae: 0.1417 - val_loss: 0.0824 - val_mae: 0.2076\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0296 - mae: 0.1383 - val_loss: 0.0861 - val_mae: 0.2124\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1422 - val_loss: 0.0860 - val_mae: 0.2077\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1430 - val_loss: 0.0832 - val_mae: 0.2324\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1411 - val_loss: 0.0826 - val_mae: 0.2300\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.1426 - val_loss: 0.0830 - val_mae: 0.2131\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - mae: 0.1479 - val_loss: 0.0820 - val_mae: 0.2120\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1404 - val_loss: 0.0886 - val_mae: 0.2226\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1373 - val_loss: 0.0862 - val_mae: 0.2406\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1429 - val_loss: 0.0829 - val_mae: 0.2105\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1366 - val_loss: 0.0841 - val_mae: 0.2092\n",
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1404 - val_loss: 0.0889 - val_mae: 0.2133\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1409 - val_loss: 0.0825 - val_mae: 0.2213\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1453 - val_loss: 0.0807 - val_mae: 0.2160\n",
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1371 - val_loss: 0.0812 - val_mae: 0.2142\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1476 - val_loss: 0.0841 - val_mae: 0.2132\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1386 - val_loss: 0.0847 - val_mae: 0.2147\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1418 - val_loss: 0.0823 - val_mae: 0.2105\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1416 - val_loss: 0.0807 - val_mae: 0.2147\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.1398 - val_loss: 0.0812 - val_mae: 0.2168\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1410 - val_loss: 0.0826 - val_mae: 0.2098\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1399 - val_loss: 0.0840 - val_mae: 0.2137\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1412 - val_loss: 0.0817 - val_mae: 0.2102\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1401 - val_loss: 0.0886 - val_mae: 0.2092\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1446 - val_loss: 0.0807 - val_mae: 0.2122\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1441 - val_loss: 0.0828 - val_mae: 0.2118\n",
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1436 - val_loss: 0.0816 - val_mae: 0.2124\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1423 - val_loss: 0.0811 - val_mae: 0.2172\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1409 - val_loss: 0.0822 - val_mae: 0.2135\n",
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1403 - val_loss: 0.0839 - val_mae: 0.2107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0313 - mae: 0.1436 - val_loss: 0.0808 - val_mae: 0.2152\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1388 - val_loss: 0.0842 - val_mae: 0.2143\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1400 - val_loss: 0.0809 - val_mae: 0.2184\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1429 - val_loss: 0.0834 - val_mae: 0.2299\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1470 - val_loss: 0.0809 - val_mae: 0.2221\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1430 - val_loss: 0.0891 - val_mae: 0.2239\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1424 - val_loss: 0.0884 - val_mae: 0.2204\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1424 - val_loss: 0.0825 - val_mae: 0.2178\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1406 - val_loss: 0.0818 - val_mae: 0.2172\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1390 - val_loss: 0.0815 - val_mae: 0.2156\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1483 - val_loss: 0.0838 - val_mae: 0.2114\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1386 - val_loss: 0.0819 - val_mae: 0.2123\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1400 - val_loss: 0.0908 - val_mae: 0.2232\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1468 - val_loss: 0.0820 - val_mae: 0.2155\n",
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1379 - val_loss: 0.0836 - val_mae: 0.2124\n",
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1387 - val_loss: 0.0825 - val_mae: 0.2191\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1444 - val_loss: 0.0807 - val_mae: 0.2220\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1444 - val_loss: 0.0827 - val_mae: 0.2142\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1392 - val_loss: 0.0886 - val_mae: 0.2237\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1436 - val_loss: 0.0967 - val_mae: 0.2233\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1365 - val_loss: 0.0823 - val_mae: 0.2152\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0303 - mae: 0.1442 - val_loss: 0.0836 - val_mae: 0.2262\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1350 - val_loss: 0.0814 - val_mae: 0.2209\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1424 - val_loss: 0.0833 - val_mae: 0.2134\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1425 - val_loss: 0.0872 - val_mae: 0.2096\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1402 - val_loss: 0.0873 - val_mae: 0.2118\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1409 - val_loss: 0.0839 - val_mae: 0.2137\n",
      "Epoch 555/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1428 - val_loss: 0.0816 - val_mae: 0.2122\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.1386 - val_loss: 0.0807 - val_mae: 0.2153\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1407 - val_loss: 0.0809 - val_mae: 0.2188\n",
      "Epoch 558/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1414 - val_loss: 0.0833 - val_mae: 0.2109\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1432 - val_loss: 0.0852 - val_mae: 0.2124\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1467 - val_loss: 0.0829 - val_mae: 0.2113\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1403 - val_loss: 0.0819 - val_mae: 0.2147\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0299 - mae: 0.1422 - val_loss: 0.0822 - val_mae: 0.2141\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1306 - val_loss: 0.0857 - val_mae: 0.2158\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1429 - val_loss: 0.0847 - val_mae: 0.2137\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1389 - val_loss: 0.0819 - val_mae: 0.2165\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1396 - val_loss: 0.0839 - val_mae: 0.2125\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1384 - val_loss: 0.0833 - val_mae: 0.2153\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0315 - mae: 0.1445 - val_loss: 0.0853 - val_mae: 0.2152\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.1402 - val_loss: 0.0822 - val_mae: 0.2162\n",
      "Epoch 570/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1430 - val_loss: 0.0882 - val_mae: 0.2185\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1388 - val_loss: 0.0819 - val_mae: 0.2139\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1401 - val_loss: 0.0820 - val_mae: 0.2147\n",
      "Epoch 573/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0313 - mae: 0.1450 - val_loss: 0.0821 - val_mae: 0.2137\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1391 - val_loss: 0.0865 - val_mae: 0.2201\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1412 - val_loss: 0.0847 - val_mae: 0.2127\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1388 - val_loss: 0.0817 - val_mae: 0.2180\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1391 - val_loss: 0.0823 - val_mae: 0.2191\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1343 - val_loss: 0.0841 - val_mae: 0.2339\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1425 - val_loss: 0.0828 - val_mae: 0.2126\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1426 - val_loss: 0.0829 - val_mae: 0.2119\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.1408 - val_loss: 0.0817 - val_mae: 0.2128\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1384 - val_loss: 0.0815 - val_mae: 0.2143\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1408 - val_loss: 0.0826 - val_mae: 0.2172\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1405 - val_loss: 0.0825 - val_mae: 0.2114\n",
      "Epoch 585/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1411 - val_loss: 0.0806 - val_mae: 0.2158\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1378 - val_loss: 0.0815 - val_mae: 0.2169\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0287 - mae: 0.1379 - val_loss: 0.0813 - val_mae: 0.2152\n",
      "Epoch 588/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1394 - val_loss: 0.0825 - val_mae: 0.2117\n",
      "Epoch 589/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1414 - val_loss: 0.0808 - val_mae: 0.2169\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1398 - val_loss: 0.0809 - val_mae: 0.2196\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1386 - val_loss: 0.0883 - val_mae: 0.2226\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1436 - val_loss: 0.0845 - val_mae: 0.2161\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1397 - val_loss: 0.0832 - val_mae: 0.2159\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1402 - val_loss: 0.0850 - val_mae: 0.2143\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1420 - val_loss: 0.0849 - val_mae: 0.2158\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1380 - val_loss: 0.0827 - val_mae: 0.2292\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0296 - mae: 0.1366 - val_loss: 0.0830 - val_mae: 0.2162\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1363 - val_loss: 0.0812 - val_mae: 0.2233\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1431 - val_loss: 0.0827 - val_mae: 0.2126\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1409 - val_loss: 0.0820 - val_mae: 0.2181\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "8\n",
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.7883 - mae: 0.6830 - val_loss: 0.6279 - val_mae: 0.6020\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2828 - mae: 0.4365 - val_loss: 0.2840 - val_mae: 0.4175\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1921 - mae: 0.3704 - val_loss: 0.2329 - val_mae: 0.3821\n",
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1557 - mae: 0.3307 - val_loss: 0.1818 - val_mae: 0.3285\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1291 - mae: 0.2888 - val_loss: 0.2049 - val_mae: 0.3470\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1145 - mae: 0.2715 - val_loss: 0.1894 - val_mae: 0.3360\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0982 - mae: 0.2517 - val_loss: 0.1570 - val_mae: 0.3103\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0841 - mae: 0.2327 - val_loss: 0.1300 - val_mae: 0.2714\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0789 - mae: 0.2222 - val_loss: 0.1407 - val_mae: 0.2855\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748 - mae: 0.2161 - val_loss: 0.1281 - val_mae: 0.2656\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0671 - mae: 0.2021 - val_loss: 0.1157 - val_mae: 0.2473\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0644 - mae: 0.1997 - val_loss: 0.1320 - val_mae: 0.2672\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0682 - mae: 0.2045 - val_loss: 0.1153 - val_mae: 0.2459\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - mae: 0.2034 - val_loss: 0.1110 - val_mae: 0.2401\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - mae: 0.1981 - val_loss: 0.1149 - val_mae: 0.2481\n",
      "Epoch 16/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0633 - mae: 0.1972 - val_loss: 0.1089 - val_mae: 0.2364\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0644 - mae: 0.1983 - val_loss: 0.1122 - val_mae: 0.2513\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0615 - mae: 0.1948 - val_loss: 0.1107 - val_mae: 0.2494\n",
      "Epoch 19/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0605 - mae: 0.1936 - val_loss: 0.1102 - val_mae: 0.2418\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - mae: 0.1938 - val_loss: 0.1047 - val_mae: 0.2287\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0618 - mae: 0.1971 - val_loss: 0.1024 - val_mae: 0.2301\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - mae: 0.1888 - val_loss: 0.1059 - val_mae: 0.2262\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0598 - mae: 0.1900 - val_loss: 0.1027 - val_mae: 0.2219\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0590 - mae: 0.1869 - val_loss: 0.1036 - val_mae: 0.2259\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - mae: 0.1886 - val_loss: 0.1110 - val_mae: 0.2432\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0574 - mae: 0.1885 - val_loss: 0.1010 - val_mae: 0.2300\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0548 - mae: 0.1831 - val_loss: 0.1035 - val_mae: 0.2402\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0563 - mae: 0.1896 - val_loss: 0.1000 - val_mae: 0.2224\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - mae: 0.1859 - val_loss: 0.1003 - val_mae: 0.2244\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0532 - mae: 0.1842 - val_loss: 0.1038 - val_mae: 0.2385\n",
      "Epoch 31/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0516 - mae: 0.1765 - val_loss: 0.1088 - val_mae: 0.2510\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0544 - mae: 0.1865 - val_loss: 0.0996 - val_mae: 0.2353\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - mae: 0.1842 - val_loss: 0.0999 - val_mae: 0.2345\n",
      "Epoch 34/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0507 - mae: 0.1822 - val_loss: 0.0963 - val_mae: 0.2199\n",
      "Epoch 35/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.1838 - val_loss: 0.0963 - val_mae: 0.2240\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0524 - mae: 0.1836 - val_loss: 0.0987 - val_mae: 0.2286\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - mae: 0.1774 - val_loss: 0.0989 - val_mae: 0.2312\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - mae: 0.1787 - val_loss: 0.0915 - val_mae: 0.2171\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0498 - mae: 0.1767 - val_loss: 0.0991 - val_mae: 0.2329\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0503 - mae: 0.1766 - val_loss: 0.0967 - val_mae: 0.2269\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.1744 - val_loss: 0.0933 - val_mae: 0.2203\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - mae: 0.1771 - val_loss: 0.0932 - val_mae: 0.2204\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0498 - mae: 0.1804 - val_loss: 0.0924 - val_mae: 0.2151\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0501 - mae: 0.1780 - val_loss: 0.0924 - val_mae: 0.2163\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - mae: 0.1701 - val_loss: 0.0928 - val_mae: 0.2177\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0507 - mae: 0.1816 - val_loss: 0.0909 - val_mae: 0.2166\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0461 - mae: 0.1725 - val_loss: 0.0939 - val_mae: 0.2276\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - mae: 0.1694 - val_loss: 0.0929 - val_mae: 0.2162\n",
      "Epoch 49/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1725 - val_loss: 0.0950 - val_mae: 0.2289\n",
      "Epoch 50/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0463 - mae: 0.1713 - val_loss: 0.0889 - val_mae: 0.2144\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0470 - mae: 0.1751 - val_loss: 0.0900 - val_mae: 0.2131\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0474 - mae: 0.1715 - val_loss: 0.0977 - val_mae: 0.2384\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - mae: 0.1713 - val_loss: 0.0937 - val_mae: 0.2211\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - mae: 0.1678 - val_loss: 0.0879 - val_mae: 0.2150\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0446 - mae: 0.1701 - val_loss: 0.0885 - val_mae: 0.2096\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0449 - mae: 0.1711 - val_loss: 0.0899 - val_mae: 0.2118\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0452 - mae: 0.1701 - val_loss: 0.0887 - val_mae: 0.2131\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0440 - mae: 0.1699 - val_loss: 0.0875 - val_mae: 0.2124\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0439 - mae: 0.1671 - val_loss: 0.0877 - val_mae: 0.2103\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 0.1630 - val_loss: 0.0911 - val_mae: 0.2269\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1648 - val_loss: 0.0874 - val_mae: 0.2188\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0418 - mae: 0.1650 - val_loss: 0.0871 - val_mae: 0.2111\n",
      "Epoch 63/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1654 - val_loss: 0.0882 - val_mae: 0.2160\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1655 - val_loss: 0.0877 - val_mae: 0.2084\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0444 - mae: 0.1676 - val_loss: 0.0902 - val_mae: 0.2176\n",
      "Epoch 66/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.1649 - val_loss: 0.0865 - val_mae: 0.2125\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1619 - val_loss: 0.0862 - val_mae: 0.2115\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0415 - mae: 0.1589 - val_loss: 0.0877 - val_mae: 0.2170\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1656 - val_loss: 0.0826 - val_mae: 0.2064\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0422 - mae: 0.1632 - val_loss: 0.0860 - val_mae: 0.2148\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1618 - val_loss: 0.0858 - val_mae: 0.2087\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1597 - val_loss: 0.0841 - val_mae: 0.2055\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.1601 - val_loss: 0.0837 - val_mae: 0.2085\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0418 - mae: 0.1646 - val_loss: 0.0833 - val_mae: 0.2034\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0401 - mae: 0.1605 - val_loss: 0.0835 - val_mae: 0.2058\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.1619 - val_loss: 0.0883 - val_mae: 0.2171\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - mae: 0.1627 - val_loss: 0.0819 - val_mae: 0.2077\n",
      "Epoch 78/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - mae: 0.1638 - val_loss: 0.0845 - val_mae: 0.2064\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0398 - mae: 0.1571 - val_loss: 0.0836 - val_mae: 0.2135\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0403 - mae: 0.1619 - val_loss: 0.0817 - val_mae: 0.2073\n",
      "Epoch 81/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0390 - mae: 0.1556 - val_loss: 0.0827 - val_mae: 0.2024\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0403 - mae: 0.1582 - val_loss: 0.0834 - val_mae: 0.2136\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1582 - val_loss: 0.0841 - val_mae: 0.2070\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0390 - mae: 0.1582 - val_loss: 0.0851 - val_mae: 0.2087\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0375 - mae: 0.1532 - val_loss: 0.0831 - val_mae: 0.2109\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1572 - val_loss: 0.0892 - val_mae: 0.2282\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1608 - val_loss: 0.0824 - val_mae: 0.2105\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1582 - val_loss: 0.0844 - val_mae: 0.2166\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0388 - mae: 0.1570 - val_loss: 0.0832 - val_mae: 0.2122\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0369 - mae: 0.1538 - val_loss: 0.0916 - val_mae: 0.2145\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0394 - mae: 0.1564 - val_loss: 0.0817 - val_mae: 0.2090\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1530 - val_loss: 0.0864 - val_mae: 0.2191\n",
      "Epoch 93/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1571 - val_loss: 0.0820 - val_mae: 0.2084\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1542 - val_loss: 0.0870 - val_mae: 0.2211\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1595 - val_loss: 0.0797 - val_mae: 0.2063\n",
      "Epoch 96/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0370 - mae: 0.1544 - val_loss: 0.0805 - val_mae: 0.2087\n",
      "Epoch 97/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1495 - val_loss: 0.0799 - val_mae: 0.2028\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0369 - mae: 0.1522 - val_loss: 0.0806 - val_mae: 0.2093\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0388 - mae: 0.1554 - val_loss: 0.0828 - val_mae: 0.2020\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1510 - val_loss: 0.0813 - val_mae: 0.2091\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0368 - mae: 0.1557 - val_loss: 0.0848 - val_mae: 0.2169\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0363 - mae: 0.1535 - val_loss: 0.0809 - val_mae: 0.2123\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - mae: 0.1570 - val_loss: 0.0803 - val_mae: 0.2054\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1519 - val_loss: 0.0811 - val_mae: 0.2081\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1552 - val_loss: 0.0794 - val_mae: 0.2046\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1487 - val_loss: 0.0796 - val_mae: 0.2060\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1510 - val_loss: 0.0815 - val_mae: 0.2080\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - mae: 0.1473 - val_loss: 0.0813 - val_mae: 0.2082\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.1577 - val_loss: 0.0817 - val_mae: 0.2093\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1494 - val_loss: 0.0803 - val_mae: 0.2042\n",
      "Epoch 111/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1460 - val_loss: 0.0829 - val_mae: 0.2086\n",
      "Epoch 112/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0365 - mae: 0.1526 - val_loss: 0.0794 - val_mae: 0.2074\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0354 - mae: 0.1493 - val_loss: 0.0808 - val_mae: 0.1990\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0327 - mae: 0.1455 - val_loss: 0.0790 - val_mae: 0.2031\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0337 - mae: 0.1486 - val_loss: 0.0899 - val_mae: 0.2246\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1533 - val_loss: 0.0850 - val_mae: 0.2149\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1443 - val_loss: 0.0798 - val_mae: 0.2058\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1489 - val_loss: 0.0807 - val_mae: 0.2040\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0323 - mae: 0.1436 - val_loss: 0.0844 - val_mae: 0.2084\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1473 - val_loss: 0.0807 - val_mae: 0.2084\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1486 - val_loss: 0.0815 - val_mae: 0.2020\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.1492 - val_loss: 0.0820 - val_mae: 0.2027\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1471 - val_loss: 0.0808 - val_mae: 0.1991\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - mae: 0.1493 - val_loss: 0.0848 - val_mae: 0.2089\n",
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.1511 - val_loss: 0.0817 - val_mae: 0.2070\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1474 - val_loss: 0.0799 - val_mae: 0.2006\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0343 - mae: 0.1480 - val_loss: 0.0815 - val_mae: 0.2028\n",
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1458 - val_loss: 0.0793 - val_mae: 0.1999\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1484 - val_loss: 0.0814 - val_mae: 0.2064\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0315 - mae: 0.1448 - val_loss: 0.0818 - val_mae: 0.2099\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - mae: 0.1510 - val_loss: 0.0807 - val_mae: 0.2040\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1485 - val_loss: 0.0819 - val_mae: 0.2046\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1420 - val_loss: 0.0814 - val_mae: 0.2052\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.1440 - val_loss: 0.0802 - val_mae: 0.2031\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1469 - val_loss: 0.0803 - val_mae: 0.2051\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1429 - val_loss: 0.0794 - val_mae: 0.2018\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1419 - val_loss: 0.0797 - val_mae: 0.2048\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1515 - val_loss: 0.0804 - val_mae: 0.2007\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1481 - val_loss: 0.0807 - val_mae: 0.2054\n",
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1473 - val_loss: 0.0811 - val_mae: 0.2079\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0341 - mae: 0.1493 - val_loss: 0.0801 - val_mae: 0.2060\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1466 - val_loss: 0.0838 - val_mae: 0.2122\n",
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1522 - val_loss: 0.0816 - val_mae: 0.2081\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0334 - mae: 0.1473 - val_loss: 0.0794 - val_mae: 0.2034\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1459 - val_loss: 0.0811 - val_mae: 0.2051\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1470 - val_loss: 0.0838 - val_mae: 0.2094\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1402 - val_loss: 0.0800 - val_mae: 0.2000\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1534 - val_loss: 0.0817 - val_mae: 0.2011\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1458 - val_loss: 0.0800 - val_mae: 0.1990\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1450 - val_loss: 0.0810 - val_mae: 0.2026\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1492 - val_loss: 0.0814 - val_mae: 0.2045\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1456 - val_loss: 0.0799 - val_mae: 0.2068\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - mae: 0.1462 - val_loss: 0.0807 - val_mae: 0.2048\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0336 - mae: 0.1483 - val_loss: 0.0837 - val_mae: 0.2047\n",
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1462 - val_loss: 0.0817 - val_mae: 0.2006\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1445 - val_loss: 0.0838 - val_mae: 0.2097\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1463 - val_loss: 0.0818 - val_mae: 0.2143\n",
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1443 - val_loss: 0.0850 - val_mae: 0.2166\n",
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1490 - val_loss: 0.0854 - val_mae: 0.2194\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1427 - val_loss: 0.0800 - val_mae: 0.2079\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0321 - mae: 0.1463 - val_loss: 0.0806 - val_mae: 0.2050\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1396 - val_loss: 0.0805 - val_mae: 0.2022\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1508 - val_loss: 0.0860 - val_mae: 0.2200\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1475 - val_loss: 0.0792 - val_mae: 0.2065\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1421 - val_loss: 0.0823 - val_mae: 0.2042\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1452 - val_loss: 0.0802 - val_mae: 0.2080\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1416 - val_loss: 0.0827 - val_mae: 0.2075\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1494 - val_loss: 0.0812 - val_mae: 0.2085\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1415 - val_loss: 0.0791 - val_mae: 0.2069\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1492 - val_loss: 0.0804 - val_mae: 0.2033\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - mae: 0.1419 - val_loss: 0.0826 - val_mae: 0.2215\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0334 - mae: 0.1491 - val_loss: 0.0818 - val_mae: 0.2171\n",
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1461 - val_loss: 0.0833 - val_mae: 0.2067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1465 - val_loss: 0.0806 - val_mae: 0.2017\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1408 - val_loss: 0.0812 - val_mae: 0.2093\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1436 - val_loss: 0.0801 - val_mae: 0.2018\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1417 - val_loss: 0.0819 - val_mae: 0.2174\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0315 - mae: 0.1388 - val_loss: 0.0797 - val_mae: 0.2063\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - mae: 0.1463 - val_loss: 0.0826 - val_mae: 0.2090\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1440 - val_loss: 0.0809 - val_mae: 0.2114\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1462 - val_loss: 0.0863 - val_mae: 0.2167\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1428 - val_loss: 0.0851 - val_mae: 0.2229\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - mae: 0.1431 - val_loss: 0.0835 - val_mae: 0.2137\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1473 - val_loss: 0.0801 - val_mae: 0.2041\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1439 - val_loss: 0.0815 - val_mae: 0.2070\n",
      "Epoch 186/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1443 - val_loss: 0.0841 - val_mae: 0.2136\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1425 - val_loss: 0.0877 - val_mae: 0.2221\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - mae: 0.1465 - val_loss: 0.0848 - val_mae: 0.2102\n",
      "Epoch 189/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1411 - val_loss: 0.0817 - val_mae: 0.2064\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1431 - val_loss: 0.0820 - val_mae: 0.2064\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1436 - val_loss: 0.0785 - val_mae: 0.2080\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1439 - val_loss: 0.0810 - val_mae: 0.2143\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0316 - mae: 0.1426 - val_loss: 0.0821 - val_mae: 0.2105\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1418 - val_loss: 0.0778 - val_mae: 0.2048\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1490 - val_loss: 0.0799 - val_mae: 0.2156\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1429 - val_loss: 0.0819 - val_mae: 0.2070\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1389 - val_loss: 0.0857 - val_mae: 0.2194\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - mae: 0.1422 - val_loss: 0.0820 - val_mae: 0.2030\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1436 - val_loss: 0.0823 - val_mae: 0.2132\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1454 - val_loss: 0.0846 - val_mae: 0.2150\n",
      "Epoch 201/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1447 - val_loss: 0.0849 - val_mae: 0.2138\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1468 - val_loss: 0.0808 - val_mae: 0.2094\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1430 - val_loss: 0.0838 - val_mae: 0.2069\n",
      "Epoch 204/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1443 - val_loss: 0.0793 - val_mae: 0.2099\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0294 - mae: 0.1391 - val_loss: 0.0821 - val_mae: 0.2062\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1429 - val_loss: 0.0838 - val_mae: 0.2122\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1484 - val_loss: 0.0810 - val_mae: 0.2076\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1422 - val_loss: 0.0801 - val_mae: 0.2064\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1479 - val_loss: 0.0827 - val_mae: 0.2122\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1452 - val_loss: 0.0816 - val_mae: 0.2181\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1422 - val_loss: 0.0783 - val_mae: 0.2075\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1467 - val_loss: 0.0798 - val_mae: 0.2140\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1415 - val_loss: 0.0800 - val_mae: 0.2059\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1481 - val_loss: 0.0811 - val_mae: 0.2076\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1414 - val_loss: 0.0852 - val_mae: 0.2202\n",
      "Epoch 216/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - mae: 0.1430 - val_loss: 0.0846 - val_mae: 0.2155\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1452 - val_loss: 0.0843 - val_mae: 0.2253\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1460 - val_loss: 0.0820 - val_mae: 0.2095\n",
      "Epoch 219/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1396 - val_loss: 0.0812 - val_mae: 0.2135\n",
      "Epoch 220/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1443 - val_loss: 0.0798 - val_mae: 0.2169\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1413 - val_loss: 0.0788 - val_mae: 0.2170\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0325 - mae: 0.1458 - val_loss: 0.0783 - val_mae: 0.2110\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1461 - val_loss: 0.0846 - val_mae: 0.2102\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1446 - val_loss: 0.0825 - val_mae: 0.2045\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1437 - val_loss: 0.0829 - val_mae: 0.2197\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1429 - val_loss: 0.0803 - val_mae: 0.2057\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1424 - val_loss: 0.0783 - val_mae: 0.2132\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.1394 - val_loss: 0.0791 - val_mae: 0.2198\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.1422 - val_loss: 0.0804 - val_mae: 0.2225\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1506 - val_loss: 0.0783 - val_mae: 0.2118\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1454 - val_loss: 0.0849 - val_mae: 0.2155\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1449 - val_loss: 0.0782 - val_mae: 0.2089\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1378 - val_loss: 0.0825 - val_mae: 0.2060\n",
      "Epoch 234/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1437 - val_loss: 0.0803 - val_mae: 0.2128\n",
      "Epoch 235/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1453 - val_loss: 0.0787 - val_mae: 0.2104\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1426 - val_loss: 0.0802 - val_mae: 0.2145\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0318 - mae: 0.1430 - val_loss: 0.0785 - val_mae: 0.2078\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1496 - val_loss: 0.0804 - val_mae: 0.2145\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1442 - val_loss: 0.0808 - val_mae: 0.2126\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1436 - val_loss: 0.0808 - val_mae: 0.2076\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1434 - val_loss: 0.0836 - val_mae: 0.2132\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1417 - val_loss: 0.0789 - val_mae: 0.2146\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1445 - val_loss: 0.0803 - val_mae: 0.2083\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1450 - val_loss: 0.0794 - val_mae: 0.2105\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1463 - val_loss: 0.0792 - val_mae: 0.2139\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1454 - val_loss: 0.0790 - val_mae: 0.2116\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1457 - val_loss: 0.0826 - val_mae: 0.2164\n",
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1417 - val_loss: 0.0785 - val_mae: 0.2150\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1458 - val_loss: 0.0786 - val_mae: 0.2137\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1421 - val_loss: 0.0848 - val_mae: 0.2188\n",
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0307 - mae: 0.1443 - val_loss: 0.0798 - val_mae: 0.2154\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1453 - val_loss: 0.0782 - val_mae: 0.2082\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1476 - val_loss: 0.0790 - val_mae: 0.2143\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1425 - val_loss: 0.0846 - val_mae: 0.2256\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1403 - val_loss: 0.0805 - val_mae: 0.2117\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1405 - val_loss: 0.0860 - val_mae: 0.2168\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1459 - val_loss: 0.0827 - val_mae: 0.2072\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1475 - val_loss: 0.0807 - val_mae: 0.2177\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1432 - val_loss: 0.0811 - val_mae: 0.2099\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1417 - val_loss: 0.0786 - val_mae: 0.2101\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1438 - val_loss: 0.0836 - val_mae: 0.2099\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1433 - val_loss: 0.0829 - val_mae: 0.2179\n",
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1416 - val_loss: 0.0841 - val_mae: 0.2110\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1439 - val_loss: 0.0777 - val_mae: 0.2100\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1496 - val_loss: 0.0774 - val_mae: 0.2099\n",
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1429 - val_loss: 0.0776 - val_mae: 0.2161\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1455 - val_loss: 0.0853 - val_mae: 0.2191\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1443 - val_loss: 0.0785 - val_mae: 0.2083\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1440 - val_loss: 0.0784 - val_mae: 0.2152\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1455 - val_loss: 0.0778 - val_mae: 0.2105\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1452 - val_loss: 0.0805 - val_mae: 0.2058\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1441 - val_loss: 0.0799 - val_mae: 0.2076\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1445 - val_loss: 0.0794 - val_mae: 0.2201\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1407 - val_loss: 0.0800 - val_mae: 0.2126\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1472 - val_loss: 0.0773 - val_mae: 0.2129\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.1422 - val_loss: 0.0793 - val_mae: 0.2066\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1395 - val_loss: 0.0766 - val_mae: 0.2146\n",
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1401 - val_loss: 0.0761 - val_mae: 0.2062\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1400 - val_loss: 0.0814 - val_mae: 0.2092\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1386 - val_loss: 0.0771 - val_mae: 0.2106\n",
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1456 - val_loss: 0.0788 - val_mae: 0.2069\n",
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1423 - val_loss: 0.0869 - val_mae: 0.2217\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1444 - val_loss: 0.0788 - val_mae: 0.2113\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1403 - val_loss: 0.0790 - val_mae: 0.2111\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1416 - val_loss: 0.0780 - val_mae: 0.2135\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1468 - val_loss: 0.0787 - val_mae: 0.2079\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1402 - val_loss: 0.0851 - val_mae: 0.2152\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1448 - val_loss: 0.0800 - val_mae: 0.2144\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1423 - val_loss: 0.0823 - val_mae: 0.2128\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1481 - val_loss: 0.0803 - val_mae: 0.2096\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1392 - val_loss: 0.0794 - val_mae: 0.2100\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1471 - val_loss: 0.0782 - val_mae: 0.2123\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1399 - val_loss: 0.0798 - val_mae: 0.2066\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1490 - val_loss: 0.0805 - val_mae: 0.2066\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1410 - val_loss: 0.0828 - val_mae: 0.2202\n",
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1443 - val_loss: 0.0807 - val_mae: 0.2095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1385 - val_loss: 0.0826 - val_mae: 0.2111\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1478 - val_loss: 0.0809 - val_mae: 0.2070\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.1386 - val_loss: 0.0835 - val_mae: 0.2144\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1406 - val_loss: 0.0807 - val_mae: 0.2180\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1419 - val_loss: 0.0792 - val_mae: 0.2114\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1379 - val_loss: 0.0799 - val_mae: 0.2084\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1434 - val_loss: 0.0798 - val_mae: 0.2130\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0299 - mae: 0.1422 - val_loss: 0.0828 - val_mae: 0.2237\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1456 - val_loss: 0.0790 - val_mae: 0.2138\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1418 - val_loss: 0.0800 - val_mae: 0.2183\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1395 - val_loss: 0.0831 - val_mae: 0.2113\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1454 - val_loss: 0.0791 - val_mae: 0.2143\n",
      "Epoch 309/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1364 - val_loss: 0.0808 - val_mae: 0.2249\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1447 - val_loss: 0.0855 - val_mae: 0.2184\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1406 - val_loss: 0.0840 - val_mae: 0.2085\n",
      "Epoch 312/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1453 - val_loss: 0.0783 - val_mae: 0.2139\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1477 - val_loss: 0.0841 - val_mae: 0.2149\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1429 - val_loss: 0.0828 - val_mae: 0.2131\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1460 - val_loss: 0.0798 - val_mae: 0.2170\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1419 - val_loss: 0.0797 - val_mae: 0.2094\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0325 - mae: 0.1474 - val_loss: 0.0807 - val_mae: 0.2102\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1431 - val_loss: 0.0826 - val_mae: 0.2248\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1484 - val_loss: 0.0798 - val_mae: 0.2204\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1448 - val_loss: 0.0782 - val_mae: 0.2146\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1450 - val_loss: 0.0774 - val_mae: 0.2119\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1434 - val_loss: 0.0786 - val_mae: 0.2060\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1434 - val_loss: 0.0783 - val_mae: 0.2124\n",
      "Epoch 324/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1380 - val_loss: 0.0782 - val_mae: 0.2099\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1426 - val_loss: 0.0792 - val_mae: 0.2171\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1423 - val_loss: 0.0795 - val_mae: 0.2069\n",
      "Epoch 327/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1419 - val_loss: 0.0792 - val_mae: 0.2125\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.1445 - val_loss: 0.0780 - val_mae: 0.2121\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1404 - val_loss: 0.0867 - val_mae: 0.2253\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1447 - val_loss: 0.0786 - val_mae: 0.2065\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1392 - val_loss: 0.0798 - val_mae: 0.2134\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1351 - val_loss: 0.0786 - val_mae: 0.2066\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1458 - val_loss: 0.0831 - val_mae: 0.2236\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1420 - val_loss: 0.0843 - val_mae: 0.2110\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1402 - val_loss: 0.0786 - val_mae: 0.2118\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1401 - val_loss: 0.0823 - val_mae: 0.2114\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1432 - val_loss: 0.0807 - val_mae: 0.2204\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1448 - val_loss: 0.0774 - val_mae: 0.2115\n",
      "Epoch 339/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1447 - val_loss: 0.0793 - val_mae: 0.2144\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1421 - val_loss: 0.0831 - val_mae: 0.2156\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1446 - val_loss: 0.0801 - val_mae: 0.2069\n",
      "Epoch 342/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1401 - val_loss: 0.0792 - val_mae: 0.2181\n",
      "Epoch 343/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1401 - val_loss: 0.0787 - val_mae: 0.2126\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1403 - val_loss: 0.0785 - val_mae: 0.2133\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1432 - val_loss: 0.0809 - val_mae: 0.2065\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1478 - val_loss: 0.0778 - val_mae: 0.2100\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1421 - val_loss: 0.0791 - val_mae: 0.2077\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1471 - val_loss: 0.0794 - val_mae: 0.2126\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1425 - val_loss: 0.0789 - val_mae: 0.2160\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1379 - val_loss: 0.0771 - val_mae: 0.2080\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - mae: 0.1435 - val_loss: 0.0789 - val_mae: 0.2080\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1361 - val_loss: 0.0771 - val_mae: 0.2139\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1442 - val_loss: 0.0781 - val_mae: 0.2183\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1410 - val_loss: 0.0809 - val_mae: 0.2108\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1393 - val_loss: 0.0777 - val_mae: 0.2099\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1469 - val_loss: 0.0796 - val_mae: 0.2171\n",
      "Epoch 357/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1379 - val_loss: 0.0839 - val_mae: 0.2205\n",
      "Epoch 358/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1413 - val_loss: 0.0803 - val_mae: 0.2204\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1452 - val_loss: 0.0768 - val_mae: 0.2089\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1413 - val_loss: 0.0767 - val_mae: 0.2057\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.1430 - val_loss: 0.0784 - val_mae: 0.2108\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1363 - val_loss: 0.0797 - val_mae: 0.2088\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1416 - val_loss: 0.0853 - val_mae: 0.2114\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1405 - val_loss: 0.0802 - val_mae: 0.2136\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - mae: 0.1400 - val_loss: 0.0839 - val_mae: 0.2168\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1477 - val_loss: 0.0781 - val_mae: 0.2070\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1442 - val_loss: 0.0798 - val_mae: 0.2103\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1398 - val_loss: 0.0810 - val_mae: 0.2151\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1406 - val_loss: 0.0782 - val_mae: 0.2175\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1471 - val_loss: 0.0781 - val_mae: 0.2091\n",
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1378 - val_loss: 0.0800 - val_mae: 0.2082\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1426 - val_loss: 0.0773 - val_mae: 0.2119\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1402 - val_loss: 0.0775 - val_mae: 0.2165\n",
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1429 - val_loss: 0.0819 - val_mae: 0.2246\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1441 - val_loss: 0.0788 - val_mae: 0.2110\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1481 - val_loss: 0.0786 - val_mae: 0.2077\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1428 - val_loss: 0.0788 - val_mae: 0.2089\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1428 - val_loss: 0.0810 - val_mae: 0.2237\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0309 - mae: 0.1421 - val_loss: 0.0786 - val_mae: 0.2115\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0299 - mae: 0.1405 - val_loss: 0.0794 - val_mae: 0.2066\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0304 - mae: 0.1407 - val_loss: 0.0784 - val_mae: 0.2174\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0299 - mae: 0.1408 - val_loss: 0.0797 - val_mae: 0.2069\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1442 - val_loss: 0.0807 - val_mae: 0.2101\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1366 - val_loss: 0.0812 - val_mae: 0.2233\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1456 - val_loss: 0.0789 - val_mae: 0.2071\n",
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1434 - val_loss: 0.0811 - val_mae: 0.2082\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1356 - val_loss: 0.0786 - val_mae: 0.2081\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1416 - val_loss: 0.0796 - val_mae: 0.2063\n",
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - mae: 0.1452 - val_loss: 0.0793 - val_mae: 0.2165\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1401 - val_loss: 0.0818 - val_mae: 0.2277\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1395 - val_loss: 0.0840 - val_mae: 0.2147\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1408 - val_loss: 0.0818 - val_mae: 0.2094\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.1448 - val_loss: 0.0790 - val_mae: 0.2074\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1420 - val_loss: 0.0776 - val_mae: 0.2103\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1446 - val_loss: 0.0808 - val_mae: 0.2082\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1450 - val_loss: 0.0788 - val_mae: 0.2164\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1388 - val_loss: 0.0776 - val_mae: 0.2151\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1388 - val_loss: 0.0865 - val_mae: 0.2184\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0297 - mae: 0.1424 - val_loss: 0.0830 - val_mae: 0.2166\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1400 - val_loss: 0.0792 - val_mae: 0.2197\n",
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1422 - val_loss: 0.0825 - val_mae: 0.2098\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1356 - val_loss: 0.0786 - val_mae: 0.2177\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1449 - val_loss: 0.0807 - val_mae: 0.2106\n",
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1379 - val_loss: 0.0785 - val_mae: 0.2122\n",
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1390 - val_loss: 0.0828 - val_mae: 0.2088\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1448 - val_loss: 0.0829 - val_mae: 0.2181\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1383 - val_loss: 0.0810 - val_mae: 0.2083\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1461 - val_loss: 0.0789 - val_mae: 0.2190\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1391 - val_loss: 0.0788 - val_mae: 0.2155\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1411 - val_loss: 0.0776 - val_mae: 0.2123\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1396 - val_loss: 0.0777 - val_mae: 0.2110\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1443 - val_loss: 0.0787 - val_mae: 0.2063\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1414 - val_loss: 0.0810 - val_mae: 0.2133\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1403 - val_loss: 0.0866 - val_mae: 0.2266\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1391 - val_loss: 0.0779 - val_mae: 0.2055\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1414 - val_loss: 0.0822 - val_mae: 0.2211\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1430 - val_loss: 0.0775 - val_mae: 0.2097\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1412 - val_loss: 0.0876 - val_mae: 0.2259\n",
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0306 - mae: 0.1407 - val_loss: 0.0775 - val_mae: 0.2162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1445 - val_loss: 0.0784 - val_mae: 0.2131\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1419 - val_loss: 0.0782 - val_mae: 0.2115\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1379 - val_loss: 0.0804 - val_mae: 0.2114\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1405 - val_loss: 0.0784 - val_mae: 0.2121\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1395 - val_loss: 0.0788 - val_mae: 0.2081\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1470 - val_loss: 0.0779 - val_mae: 0.2105\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1423 - val_loss: 0.0775 - val_mae: 0.2128\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1400 - val_loss: 0.0867 - val_mae: 0.2241\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1465 - val_loss: 0.0788 - val_mae: 0.2061\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1410 - val_loss: 0.0790 - val_mae: 0.2087\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1428 - val_loss: 0.0767 - val_mae: 0.2116\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.1405 - val_loss: 0.0766 - val_mae: 0.2115\n",
      "Epoch 432/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1332 - val_loss: 0.0853 - val_mae: 0.2153\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1416 - val_loss: 0.0803 - val_mae: 0.2067\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1413 - val_loss: 0.0799 - val_mae: 0.2070\n",
      "Epoch 435/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1386 - val_loss: 0.0798 - val_mae: 0.2090\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1375 - val_loss: 0.0855 - val_mae: 0.2186\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1384 - val_loss: 0.0811 - val_mae: 0.2076\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1410 - val_loss: 0.0799 - val_mae: 0.2168\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - mae: 0.1451 - val_loss: 0.0829 - val_mae: 0.2147\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1418 - val_loss: 0.0784 - val_mae: 0.2131\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1389 - val_loss: 0.0784 - val_mae: 0.2159\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1367 - val_loss: 0.0807 - val_mae: 0.2095\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1432 - val_loss: 0.0795 - val_mae: 0.2087\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1372 - val_loss: 0.0822 - val_mae: 0.2144\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1409 - val_loss: 0.0802 - val_mae: 0.2139\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1387 - val_loss: 0.0822 - val_mae: 0.2147\n",
      "Epoch 447/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1420 - val_loss: 0.0803 - val_mae: 0.2186\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1375 - val_loss: 0.0843 - val_mae: 0.2137\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1375 - val_loss: 0.0786 - val_mae: 0.2121\n",
      "Epoch 450/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1361 - val_loss: 0.0834 - val_mae: 0.2142\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1423 - val_loss: 0.0839 - val_mae: 0.2167\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.1395 - val_loss: 0.0781 - val_mae: 0.2175\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0299 - mae: 0.1402 - val_loss: 0.0787 - val_mae: 0.2155\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1392 - val_loss: 0.0775 - val_mae: 0.2106\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1377 - val_loss: 0.0800 - val_mae: 0.2108\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1420 - val_loss: 0.0790 - val_mae: 0.2059\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1426 - val_loss: 0.0780 - val_mae: 0.2104\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1359 - val_loss: 0.0796 - val_mae: 0.2113\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1348 - val_loss: 0.0772 - val_mae: 0.2168\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1411 - val_loss: 0.0787 - val_mae: 0.2074\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1365 - val_loss: 0.0778 - val_mae: 0.2099\n",
      "Epoch 462/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1409 - val_loss: 0.0759 - val_mae: 0.2058\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1435 - val_loss: 0.0767 - val_mae: 0.2070\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1382 - val_loss: 0.0768 - val_mae: 0.2099\n",
      "Epoch 465/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0301 - mae: 0.1433 - val_loss: 0.0798 - val_mae: 0.2069\n",
      "Epoch 466/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.1427 - val_loss: 0.0814 - val_mae: 0.2097\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1450 - val_loss: 0.0809 - val_mae: 0.2120\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1393 - val_loss: 0.0781 - val_mae: 0.2106\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1388 - val_loss: 0.0804 - val_mae: 0.2151\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1386 - val_loss: 0.0890 - val_mae: 0.2236\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1448 - val_loss: 0.0784 - val_mae: 0.2156\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1435 - val_loss: 0.0858 - val_mae: 0.2218\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1419 - val_loss: 0.0778 - val_mae: 0.2050\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - mae: 0.1370 - val_loss: 0.0814 - val_mae: 0.2144\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1441 - val_loss: 0.0785 - val_mae: 0.2093\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1386 - val_loss: 0.0795 - val_mae: 0.2062\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1463 - val_loss: 0.0785 - val_mae: 0.2069\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1362 - val_loss: 0.0816 - val_mae: 0.2136\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1459 - val_loss: 0.0772 - val_mae: 0.2125\n",
      "Epoch 480/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1396 - val_loss: 0.0797 - val_mae: 0.2079\n",
      "Epoch 481/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - mae: 0.1437 - val_loss: 0.0791 - val_mae: 0.2083\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1357 - val_loss: 0.0788 - val_mae: 0.2185\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1412 - val_loss: 0.0833 - val_mae: 0.2190\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1394 - val_loss: 0.0835 - val_mae: 0.2091\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1406 - val_loss: 0.0799 - val_mae: 0.2084\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1384 - val_loss: 0.0783 - val_mae: 0.2165\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1395 - val_loss: 0.0801 - val_mae: 0.2102\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1409 - val_loss: 0.0835 - val_mae: 0.2125\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1419 - val_loss: 0.0789 - val_mae: 0.2136\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1377 - val_loss: 0.0819 - val_mae: 0.2155\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1378 - val_loss: 0.0807 - val_mae: 0.2148\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.1431 - val_loss: 0.0795 - val_mae: 0.2182\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0294 - mae: 0.1379 - val_loss: 0.0798 - val_mae: 0.2203\n",
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1416 - val_loss: 0.0796 - val_mae: 0.2085\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1437 - val_loss: 0.0811 - val_mae: 0.2131\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1438 - val_loss: 0.0785 - val_mae: 0.2158\n",
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1388 - val_loss: 0.0781 - val_mae: 0.2099\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1388 - val_loss: 0.0797 - val_mae: 0.2104\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1392 - val_loss: 0.0783 - val_mae: 0.2120\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1394 - val_loss: 0.0773 - val_mae: 0.2156\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1400 - val_loss: 0.0781 - val_mae: 0.2095\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1390 - val_loss: 0.0795 - val_mae: 0.2152\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1382 - val_loss: 0.0802 - val_mae: 0.2139\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1395 - val_loss: 0.0813 - val_mae: 0.2114\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1446 - val_loss: 0.0780 - val_mae: 0.2078\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1386 - val_loss: 0.0800 - val_mae: 0.2176\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1359 - val_loss: 0.0829 - val_mae: 0.2116\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1414 - val_loss: 0.0791 - val_mae: 0.2160\n",
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1362 - val_loss: 0.0780 - val_mae: 0.2068\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1399 - val_loss: 0.0809 - val_mae: 0.2089\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0298 - mae: 0.1380 - val_loss: 0.0786 - val_mae: 0.2066\n",
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1400 - val_loss: 0.0776 - val_mae: 0.2096\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1357 - val_loss: 0.0779 - val_mae: 0.2070\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1407 - val_loss: 0.0770 - val_mae: 0.2113\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1422 - val_loss: 0.0805 - val_mae: 0.2142\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1431 - val_loss: 0.0831 - val_mae: 0.2118\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1408 - val_loss: 0.0783 - val_mae: 0.2084\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0291 - mae: 0.1382 - val_loss: 0.0785 - val_mae: 0.2064\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1412 - val_loss: 0.0764 - val_mae: 0.2105\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1401 - val_loss: 0.0794 - val_mae: 0.2120\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1407 - val_loss: 0.0783 - val_mae: 0.2109\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1404 - val_loss: 0.0771 - val_mae: 0.2075\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1409 - val_loss: 0.0770 - val_mae: 0.2115\n",
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1389 - val_loss: 0.0798 - val_mae: 0.2213\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1420 - val_loss: 0.0759 - val_mae: 0.2095\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1429 - val_loss: 0.0802 - val_mae: 0.2074\n",
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1429 - val_loss: 0.0778 - val_mae: 0.2074\n",
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1424 - val_loss: 0.0791 - val_mae: 0.2147\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1400 - val_loss: 0.0860 - val_mae: 0.2154\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1389 - val_loss: 0.0805 - val_mae: 0.2077\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1348 - val_loss: 0.0769 - val_mae: 0.2110\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1435 - val_loss: 0.0780 - val_mae: 0.2072\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1387 - val_loss: 0.0795 - val_mae: 0.2177\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1364 - val_loss: 0.0792 - val_mae: 0.2101\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1362 - val_loss: 0.0785 - val_mae: 0.2125\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1332 - val_loss: 0.0958 - val_mae: 0.2354\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1339 - val_loss: 0.0798 - val_mae: 0.2110\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1398 - val_loss: 0.0783 - val_mae: 0.2113\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1361 - val_loss: 0.0855 - val_mae: 0.2208\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1412 - val_loss: 0.0775 - val_mae: 0.2117\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1396 - val_loss: 0.0769 - val_mae: 0.2111\n",
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1334 - val_loss: 0.0804 - val_mae: 0.2114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1396 - val_loss: 0.0825 - val_mae: 0.2113\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1380 - val_loss: 0.0782 - val_mae: 0.2114\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1408 - val_loss: 0.0778 - val_mae: 0.2132\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1420 - val_loss: 0.0799 - val_mae: 0.2086\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1363 - val_loss: 0.0784 - val_mae: 0.2135\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1379 - val_loss: 0.0845 - val_mae: 0.2249\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1428 - val_loss: 0.0789 - val_mae: 0.2122\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1406 - val_loss: 0.0798 - val_mae: 0.2136\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1408 - val_loss: 0.0771 - val_mae: 0.2116\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1389 - val_loss: 0.0816 - val_mae: 0.2134\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1398 - val_loss: 0.0768 - val_mae: 0.2116\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1403 - val_loss: 0.0779 - val_mae: 0.2137\n",
      "Epoch 555/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1402 - val_loss: 0.0798 - val_mae: 0.2142\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1375 - val_loss: 0.0794 - val_mae: 0.2101\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1370 - val_loss: 0.0813 - val_mae: 0.2100\n",
      "Epoch 558/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1365 - val_loss: 0.0787 - val_mae: 0.2165\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1360 - val_loss: 0.0807 - val_mae: 0.2191\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1364 - val_loss: 0.0845 - val_mae: 0.2200\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1350 - val_loss: 0.0788 - val_mae: 0.2127\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1346 - val_loss: 0.0818 - val_mae: 0.2109\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1368 - val_loss: 0.0807 - val_mae: 0.2104\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1363 - val_loss: 0.0794 - val_mae: 0.2080\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1405 - val_loss: 0.0780 - val_mae: 0.2141\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1396 - val_loss: 0.0780 - val_mae: 0.2166\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.1381 - val_loss: 0.0792 - val_mae: 0.2109\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1309 - val_loss: 0.0769 - val_mae: 0.2113\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0296 - mae: 0.1397 - val_loss: 0.0772 - val_mae: 0.2085\n",
      "Epoch 570/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1317 - val_loss: 0.0764 - val_mae: 0.2077\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1378 - val_loss: 0.0798 - val_mae: 0.2087\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - mae: 0.1343 - val_loss: 0.0786 - val_mae: 0.2167\n",
      "Epoch 573/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1384 - val_loss: 0.0777 - val_mae: 0.2169\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1369 - val_loss: 0.0779 - val_mae: 0.2116\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1385 - val_loss: 0.0787 - val_mae: 0.2112\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1326 - val_loss: 0.0865 - val_mae: 0.2167\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1400 - val_loss: 0.0797 - val_mae: 0.2165\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1334 - val_loss: 0.0856 - val_mae: 0.2196\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1421 - val_loss: 0.0796 - val_mae: 0.2176\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1381 - val_loss: 0.0774 - val_mae: 0.2096\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1328 - val_loss: 0.0782 - val_mae: 0.2061\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1405 - val_loss: 0.0811 - val_mae: 0.2078\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1375 - val_loss: 0.0793 - val_mae: 0.2070\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1428 - val_loss: 0.0767 - val_mae: 0.2092\n",
      "Epoch 585/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1375 - val_loss: 0.0776 - val_mae: 0.2078\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1297 - val_loss: 0.0842 - val_mae: 0.2228\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0311 - mae: 0.1412 - val_loss: 0.0791 - val_mae: 0.2135\n",
      "Epoch 588/600\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0281 - mae: 0.1384 - val_loss: 0.0792 - val_mae: 0.2102\n",
      "Epoch 589/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1352 - val_loss: 0.0818 - val_mae: 0.2145\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1443 - val_loss: 0.0818 - val_mae: 0.2119\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1330 - val_loss: 0.0805 - val_mae: 0.2103\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1371 - val_loss: 0.0799 - val_mae: 0.2110\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1338 - val_loss: 0.0780 - val_mae: 0.2110\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1379 - val_loss: 0.0794 - val_mae: 0.2113\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1406 - val_loss: 0.0785 - val_mae: 0.2095\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1417 - val_loss: 0.0781 - val_mae: 0.2102\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1340 - val_loss: 0.0791 - val_mae: 0.2109\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1365 - val_loss: 0.0805 - val_mae: 0.2160\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1335 - val_loss: 0.0797 - val_mae: 0.2137\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1367 - val_loss: 0.0803 - val_mae: 0.2112\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "10\n",
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 1.1102 - mae: 0.8834 - val_loss: 0.7061 - val_mae: 0.6177\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4367 - mae: 0.5271 - val_loss: 0.3684 - val_mae: 0.4510\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3023 - mae: 0.4453 - val_loss: 0.3199 - val_mae: 0.4419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2636 - mae: 0.4178 - val_loss: 0.2771 - val_mae: 0.4085\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2366 - mae: 0.3970 - val_loss: 0.2459 - val_mae: 0.3850\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2147 - mae: 0.3787 - val_loss: 0.2422 - val_mae: 0.3763\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1914 - mae: 0.3542 - val_loss: 0.2585 - val_mae: 0.3878\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1764 - mae: 0.3411 - val_loss: 0.2333 - val_mae: 0.3577\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1566 - mae: 0.3209 - val_loss: 0.2169 - val_mae: 0.3470\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1398 - mae: 0.3029 - val_loss: 0.1948 - val_mae: 0.3308\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1229 - mae: 0.2807 - val_loss: 0.2002 - val_mae: 0.3272\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1129 - mae: 0.2647 - val_loss: 0.1821 - val_mae: 0.3192\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0992 - mae: 0.2488 - val_loss: 0.1615 - val_mae: 0.2846\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0930 - mae: 0.2424 - val_loss: 0.1627 - val_mae: 0.2882\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0869 - mae: 0.2334 - val_loss: 0.1667 - val_mae: 0.3079\n",
      "Epoch 16/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0803 - mae: 0.2226 - val_loss: 0.1614 - val_mae: 0.3062\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0756 - mae: 0.2154 - val_loss: 0.1420 - val_mae: 0.2727\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0722 - mae: 0.2091 - val_loss: 0.1541 - val_mae: 0.2797\n",
      "Epoch 19/600\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0725 - mae: 0.2063 - val_loss: 0.1403 - val_mae: 0.2846\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0708 - mae: 0.2062 - val_loss: 0.1348 - val_mae: 0.2629\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0697 - mae: 0.2037 - val_loss: 0.1324 - val_mae: 0.2570\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0679 - mae: 0.1987 - val_loss: 0.1311 - val_mae: 0.2563\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0675 - mae: 0.2026 - val_loss: 0.1360 - val_mae: 0.2689\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - mae: 0.2026 - val_loss: 0.1288 - val_mae: 0.2566\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0650 - mae: 0.1999 - val_loss: 0.1274 - val_mae: 0.2529\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - mae: 0.2021 - val_loss: 0.1292 - val_mae: 0.2611\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0640 - mae: 0.1993 - val_loss: 0.1372 - val_mae: 0.2791\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - mae: 0.2024 - val_loss: 0.1268 - val_mae: 0.2549\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - mae: 0.1934 - val_loss: 0.1252 - val_mae: 0.2440\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0643 - mae: 0.2021 - val_loss: 0.1239 - val_mae: 0.2468\n",
      "Epoch 31/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - mae: 0.1998 - val_loss: 0.1223 - val_mae: 0.2495\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0605 - mae: 0.1981 - val_loss: 0.1279 - val_mae: 0.2598\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0621 - mae: 0.1929 - val_loss: 0.1204 - val_mae: 0.2440\n",
      "Epoch 34/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0623 - mae: 0.1969 - val_loss: 0.1179 - val_mae: 0.2420\n",
      "Epoch 35/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - mae: 0.1931 - val_loss: 0.1240 - val_mae: 0.2634\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - mae: 0.1939 - val_loss: 0.1230 - val_mae: 0.2601\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0598 - mae: 0.1950 - val_loss: 0.1209 - val_mae: 0.2512\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0605 - mae: 0.1988 - val_loss: 0.1260 - val_mae: 0.2589\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - mae: 0.1938 - val_loss: 0.1189 - val_mae: 0.2452\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - mae: 0.1920 - val_loss: 0.1188 - val_mae: 0.2389\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0574 - mae: 0.1961 - val_loss: 0.1253 - val_mae: 0.2671\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0574 - mae: 0.1927 - val_loss: 0.1209 - val_mae: 0.2502\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0585 - mae: 0.1921 - val_loss: 0.1150 - val_mae: 0.2443\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0579 - mae: 0.1899 - val_loss: 0.1115 - val_mae: 0.2345\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - mae: 0.1925 - val_loss: 0.1109 - val_mae: 0.2317\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0571 - mae: 0.1910 - val_loss: 0.1086 - val_mae: 0.2335\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - mae: 0.1876 - val_loss: 0.1103 - val_mae: 0.2378\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0544 - mae: 0.1862 - val_loss: 0.1099 - val_mae: 0.2442\n",
      "Epoch 49/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0559 - mae: 0.1881 - val_loss: 0.1075 - val_mae: 0.2320\n",
      "Epoch 50/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - mae: 0.1912 - val_loss: 0.1098 - val_mae: 0.2389\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0556 - mae: 0.1893 - val_loss: 0.1075 - val_mae: 0.2229\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0542 - mae: 0.1887 - val_loss: 0.1101 - val_mae: 0.2384\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0547 - mae: 0.1871 - val_loss: 0.1090 - val_mae: 0.2370\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0534 - mae: 0.1863 - val_loss: 0.1061 - val_mae: 0.2281\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - mae: 0.1761 - val_loss: 0.1055 - val_mae: 0.2154\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0523 - mae: 0.1854 - val_loss: 0.1100 - val_mae: 0.2393\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.1865 - val_loss: 0.1012 - val_mae: 0.2166\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0525 - mae: 0.1855 - val_loss: 0.1061 - val_mae: 0.2344\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0528 - mae: 0.1863 - val_loss: 0.1050 - val_mae: 0.2305\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - mae: 0.1831 - val_loss: 0.0998 - val_mae: 0.2186\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0519 - mae: 0.1830 - val_loss: 0.1016 - val_mae: 0.2344\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0513 - mae: 0.1836 - val_loss: 0.1004 - val_mae: 0.2181\n",
      "Epoch 63/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - mae: 0.1813 - val_loss: 0.0998 - val_mae: 0.2237\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1798 - val_loss: 0.0991 - val_mae: 0.2114\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - mae: 0.1774 - val_loss: 0.0999 - val_mae: 0.2368\n",
      "Epoch 66/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1847 - val_loss: 0.0958 - val_mae: 0.2214\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - mae: 0.1805 - val_loss: 0.0975 - val_mae: 0.2147\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0505 - mae: 0.1803 - val_loss: 0.0959 - val_mae: 0.2254\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0471 - mae: 0.1738 - val_loss: 0.0960 - val_mae: 0.2222\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1749 - val_loss: 0.0945 - val_mae: 0.2151\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0495 - mae: 0.1773 - val_loss: 0.0946 - val_mae: 0.2161\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1747 - val_loss: 0.0983 - val_mae: 0.2295\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0472 - mae: 0.1732 - val_loss: 0.0943 - val_mae: 0.2221\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1756 - val_loss: 0.0920 - val_mae: 0.2111\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.1687 - val_loss: 0.0948 - val_mae: 0.2160\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.1704 - val_loss: 0.0943 - val_mae: 0.2155\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - mae: 0.1743 - val_loss: 0.0919 - val_mae: 0.2119\n",
      "Epoch 78/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - mae: 0.1706 - val_loss: 0.0909 - val_mae: 0.2102\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0456 - mae: 0.1687 - val_loss: 0.0948 - val_mae: 0.2173\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0459 - mae: 0.1721 - val_loss: 0.0889 - val_mae: 0.2089\n",
      "Epoch 81/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 0.1653 - val_loss: 0.0927 - val_mae: 0.2213\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0452 - mae: 0.1695 - val_loss: 0.0913 - val_mae: 0.2078\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1617 - val_loss: 0.0935 - val_mae: 0.2140\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1698 - val_loss: 0.0871 - val_mae: 0.2088\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.1665 - val_loss: 0.0878 - val_mae: 0.2108\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.1623 - val_loss: 0.0884 - val_mae: 0.2129\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1615 - val_loss: 0.0880 - val_mae: 0.2185\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1595 - val_loss: 0.0855 - val_mae: 0.2100\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.1616 - val_loss: 0.0877 - val_mae: 0.2110\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0434 - mae: 0.1650 - val_loss: 0.0856 - val_mae: 0.2097\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - mae: 0.1591 - val_loss: 0.0865 - val_mae: 0.2059\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - mae: 0.1612 - val_loss: 0.0865 - val_mae: 0.2110\n",
      "Epoch 93/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1556 - val_loss: 0.0909 - val_mae: 0.2093\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 0.1591 - val_loss: 0.0849 - val_mae: 0.2079\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0397 - mae: 0.1581 - val_loss: 0.0851 - val_mae: 0.2097\n",
      "Epoch 96/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1571 - val_loss: 0.0909 - val_mae: 0.2137\n",
      "Epoch 97/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0403 - mae: 0.1591 - val_loss: 0.0833 - val_mae: 0.2052\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0386 - mae: 0.1552 - val_loss: 0.0851 - val_mae: 0.2126\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1563 - val_loss: 0.0837 - val_mae: 0.2099\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - mae: 0.1552 - val_loss: 0.0921 - val_mae: 0.2218\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1584 - val_loss: 0.0862 - val_mae: 0.2084\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.1522 - val_loss: 0.0818 - val_mae: 0.2122\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0365 - mae: 0.1520 - val_loss: 0.0840 - val_mae: 0.2122\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1485 - val_loss: 0.0879 - val_mae: 0.2107\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1476 - val_loss: 0.0815 - val_mae: 0.2053\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1523 - val_loss: 0.0872 - val_mae: 0.2106\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1522 - val_loss: 0.0814 - val_mae: 0.2034\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0371 - mae: 0.1515 - val_loss: 0.0832 - val_mae: 0.2080\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1503 - val_loss: 0.0822 - val_mae: 0.2081\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1464 - val_loss: 0.0827 - val_mae: 0.2077\n",
      "Epoch 111/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1457 - val_loss: 0.0873 - val_mae: 0.2112\n",
      "Epoch 112/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - mae: 0.1418 - val_loss: 0.0827 - val_mae: 0.2070\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0359 - mae: 0.1481 - val_loss: 0.0823 - val_mae: 0.2058\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1495 - val_loss: 0.0803 - val_mae: 0.2101\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.1449 - val_loss: 0.0874 - val_mae: 0.2147\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1442 - val_loss: 0.0852 - val_mae: 0.2099\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1514 - val_loss: 0.0847 - val_mae: 0.2082\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1483 - val_loss: 0.0837 - val_mae: 0.2078\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1448 - val_loss: 0.0811 - val_mae: 0.2085\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1493 - val_loss: 0.0793 - val_mae: 0.2040\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.1462 - val_loss: 0.0829 - val_mae: 0.2070\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1438 - val_loss: 0.0807 - val_mae: 0.2083\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1426 - val_loss: 0.0827 - val_mae: 0.2108\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1446 - val_loss: 0.0848 - val_mae: 0.2085\n",
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1470 - val_loss: 0.0820 - val_mae: 0.2101\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1465 - val_loss: 0.0834 - val_mae: 0.2104\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1474 - val_loss: 0.0818 - val_mae: 0.2079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1436 - val_loss: 0.0919 - val_mae: 0.2193\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1480 - val_loss: 0.0818 - val_mae: 0.2085\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1444 - val_loss: 0.0841 - val_mae: 0.2081\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1467 - val_loss: 0.0834 - val_mae: 0.2092\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1428 - val_loss: 0.0852 - val_mae: 0.2129\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1442 - val_loss: 0.0835 - val_mae: 0.2094\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1418 - val_loss: 0.0807 - val_mae: 0.2154\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1445 - val_loss: 0.0811 - val_mae: 0.2134\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1420 - val_loss: 0.0865 - val_mae: 0.2122\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1477 - val_loss: 0.0818 - val_mae: 0.2122\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1430 - val_loss: 0.0817 - val_mae: 0.2125\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1416 - val_loss: 0.0836 - val_mae: 0.2196\n",
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1402 - val_loss: 0.0828 - val_mae: 0.2129\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1449 - val_loss: 0.0822 - val_mae: 0.2133\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1383 - val_loss: 0.0861 - val_mae: 0.2154\n",
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1417 - val_loss: 0.0850 - val_mae: 0.2124\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1436 - val_loss: 0.0808 - val_mae: 0.2127\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1459 - val_loss: 0.0815 - val_mae: 0.2101\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1412 - val_loss: 0.0861 - val_mae: 0.2172\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1388 - val_loss: 0.0845 - val_mae: 0.2156\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1476 - val_loss: 0.0836 - val_mae: 0.2165\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1434 - val_loss: 0.0832 - val_mae: 0.2109\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1376 - val_loss: 0.0886 - val_mae: 0.2198\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1437 - val_loss: 0.0837 - val_mae: 0.2155\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1417 - val_loss: 0.0828 - val_mae: 0.2136\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1432 - val_loss: 0.0826 - val_mae: 0.2131\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1423 - val_loss: 0.0865 - val_mae: 0.2163\n",
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1447 - val_loss: 0.0839 - val_mae: 0.2150\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1406 - val_loss: 0.0831 - val_mae: 0.2144\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1391 - val_loss: 0.0829 - val_mae: 0.2133\n",
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1422 - val_loss: 0.0807 - val_mae: 0.2173\n",
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1411 - val_loss: 0.0855 - val_mae: 0.2172\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1363 - val_loss: 0.0927 - val_mae: 0.2180\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1476 - val_loss: 0.0841 - val_mae: 0.2153\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1391 - val_loss: 0.0814 - val_mae: 0.2171\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1374 - val_loss: 0.0882 - val_mae: 0.2259\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1463 - val_loss: 0.0859 - val_mae: 0.2149\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1424 - val_loss: 0.0866 - val_mae: 0.2221\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1432 - val_loss: 0.0848 - val_mae: 0.2228\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1409 - val_loss: 0.0842 - val_mae: 0.2180\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1447 - val_loss: 0.0830 - val_mae: 0.2219\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1442 - val_loss: 0.0814 - val_mae: 0.2143\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1475 - val_loss: 0.0830 - val_mae: 0.2129\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1415 - val_loss: 0.0825 - val_mae: 0.2165\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1428 - val_loss: 0.0828 - val_mae: 0.2152\n",
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1405 - val_loss: 0.0845 - val_mae: 0.2158\n",
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1389 - val_loss: 0.0847 - val_mae: 0.2196\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1434 - val_loss: 0.0898 - val_mae: 0.2234\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1441 - val_loss: 0.0844 - val_mae: 0.2186\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1382 - val_loss: 0.0867 - val_mae: 0.2253\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1380 - val_loss: 0.0906 - val_mae: 0.2219\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1421 - val_loss: 0.0848 - val_mae: 0.2211\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1382 - val_loss: 0.0810 - val_mae: 0.2186\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1381 - val_loss: 0.0853 - val_mae: 0.2152\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1388 - val_loss: 0.0896 - val_mae: 0.2219\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1399 - val_loss: 0.0830 - val_mae: 0.2133\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0295 - mae: 0.1370 - val_loss: 0.0853 - val_mae: 0.2170\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0309 - mae: 0.1421 - val_loss: 0.0857 - val_mae: 0.2173\n",
      "Epoch 186/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1431 - val_loss: 0.0854 - val_mae: 0.2205\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1397 - val_loss: 0.0854 - val_mae: 0.2230\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1391 - val_loss: 0.0850 - val_mae: 0.2166\n",
      "Epoch 189/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1391 - val_loss: 0.0841 - val_mae: 0.2218\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1408 - val_loss: 0.0836 - val_mae: 0.2199\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1393 - val_loss: 0.0855 - val_mae: 0.2197\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1391 - val_loss: 0.0917 - val_mae: 0.2263\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1376 - val_loss: 0.0906 - val_mae: 0.2224\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1351 - val_loss: 0.0842 - val_mae: 0.2269\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1402 - val_loss: 0.0834 - val_mae: 0.2255\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1398 - val_loss: 0.0838 - val_mae: 0.2186\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1374 - val_loss: 0.0860 - val_mae: 0.2207\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1376 - val_loss: 0.0874 - val_mae: 0.2212\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1413 - val_loss: 0.0849 - val_mae: 0.2232\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1388 - val_loss: 0.0907 - val_mae: 0.2202\n",
      "Epoch 201/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1350 - val_loss: 0.0880 - val_mae: 0.2234\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1421 - val_loss: 0.0893 - val_mae: 0.2231\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1339 - val_loss: 0.0868 - val_mae: 0.2304\n",
      "Epoch 204/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1393 - val_loss: 0.1015 - val_mae: 0.2393\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1438 - val_loss: 0.0885 - val_mae: 0.2195\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1365 - val_loss: 0.0853 - val_mae: 0.2223\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1347 - val_loss: 0.0847 - val_mae: 0.2200\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1384 - val_loss: 0.0860 - val_mae: 0.2181\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1416 - val_loss: 0.0841 - val_mae: 0.2225\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1392 - val_loss: 0.0842 - val_mae: 0.2221\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1365 - val_loss: 0.0822 - val_mae: 0.2231\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1388 - val_loss: 0.0828 - val_mae: 0.2235\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1390 - val_loss: 0.0903 - val_mae: 0.2220\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1393 - val_loss: 0.0836 - val_mae: 0.2200\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1384 - val_loss: 0.0853 - val_mae: 0.2220\n",
      "Epoch 216/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1358 - val_loss: 0.0849 - val_mae: 0.2214\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1356 - val_loss: 0.0875 - val_mae: 0.2175\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1372 - val_loss: 0.0853 - val_mae: 0.2221\n",
      "Epoch 219/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1372 - val_loss: 0.0863 - val_mae: 0.2205\n",
      "Epoch 220/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1346 - val_loss: 0.0886 - val_mae: 0.2309\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1411 - val_loss: 0.0893 - val_mae: 0.2185\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1381 - val_loss: 0.0915 - val_mae: 0.2199\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1407 - val_loss: 0.0854 - val_mae: 0.2226\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1365 - val_loss: 0.0874 - val_mae: 0.2268\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1362 - val_loss: 0.0894 - val_mae: 0.2190\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1374 - val_loss: 0.0879 - val_mae: 0.2214\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1333 - val_loss: 0.0861 - val_mae: 0.2199\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1365 - val_loss: 0.0866 - val_mae: 0.2293\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1414 - val_loss: 0.0877 - val_mae: 0.2211\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1357 - val_loss: 0.0903 - val_mae: 0.2261\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1363 - val_loss: 0.0870 - val_mae: 0.2198\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1340 - val_loss: 0.0873 - val_mae: 0.2209\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1361 - val_loss: 0.0881 - val_mae: 0.2182\n",
      "Epoch 234/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1356 - val_loss: 0.0856 - val_mae: 0.2218\n",
      "Epoch 235/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1385 - val_loss: 0.0889 - val_mae: 0.2266\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1361 - val_loss: 0.0913 - val_mae: 0.2223\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1367 - val_loss: 0.0873 - val_mae: 0.2227\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1314 - val_loss: 0.0945 - val_mae: 0.2296\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1382 - val_loss: 0.0911 - val_mae: 0.2197\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1342 - val_loss: 0.0898 - val_mae: 0.2225\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1377 - val_loss: 0.0885 - val_mae: 0.2324\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1386 - val_loss: 0.0925 - val_mae: 0.2292\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1386 - val_loss: 0.0887 - val_mae: 0.2211\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1311 - val_loss: 0.0874 - val_mae: 0.2221\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1362 - val_loss: 0.0892 - val_mae: 0.2242\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1341 - val_loss: 0.0905 - val_mae: 0.2202\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1408 - val_loss: 0.0873 - val_mae: 0.2191\n",
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1352 - val_loss: 0.0896 - val_mae: 0.2186\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1371 - val_loss: 0.0888 - val_mae: 0.2246\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1340 - val_loss: 0.0853 - val_mae: 0.2207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1355 - val_loss: 0.0907 - val_mae: 0.2176\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1317 - val_loss: 0.0870 - val_mae: 0.2305\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1357 - val_loss: 0.0862 - val_mae: 0.2289\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1373 - val_loss: 0.0904 - val_mae: 0.2192\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1328 - val_loss: 0.0866 - val_mae: 0.2251\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1370 - val_loss: 0.0869 - val_mae: 0.2221\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1366 - val_loss: 0.0870 - val_mae: 0.2186\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1362 - val_loss: 0.0872 - val_mae: 0.2252\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1361 - val_loss: 0.0896 - val_mae: 0.2196\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1328 - val_loss: 0.0917 - val_mae: 0.2196\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1333 - val_loss: 0.0893 - val_mae: 0.2207\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1355 - val_loss: 0.0933 - val_mae: 0.2323\n",
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1383 - val_loss: 0.0880 - val_mae: 0.2242\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1311 - val_loss: 0.0858 - val_mae: 0.2277\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1403 - val_loss: 0.0915 - val_mae: 0.2261\n",
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1382 - val_loss: 0.0904 - val_mae: 0.2237\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1381 - val_loss: 0.0878 - val_mae: 0.2302\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1312 - val_loss: 0.0844 - val_mae: 0.2260\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1382 - val_loss: 0.0921 - val_mae: 0.2260\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1378 - val_loss: 0.0899 - val_mae: 0.2226\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1355 - val_loss: 0.0909 - val_mae: 0.2308\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1309 - val_loss: 0.0904 - val_mae: 0.2304\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1336 - val_loss: 0.0885 - val_mae: 0.2231\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1320 - val_loss: 0.0867 - val_mae: 0.2250\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1334 - val_loss: 0.0855 - val_mae: 0.2223\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1319 - val_loss: 0.0935 - val_mae: 0.2192\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1289 - val_loss: 0.0915 - val_mae: 0.2305\n",
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1339 - val_loss: 0.0888 - val_mae: 0.2193\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1354 - val_loss: 0.0893 - val_mae: 0.2195\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1342 - val_loss: 0.1035 - val_mae: 0.2436\n",
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1412 - val_loss: 0.0905 - val_mae: 0.2220\n",
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1344 - val_loss: 0.0902 - val_mae: 0.2186\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1330 - val_loss: 0.0883 - val_mae: 0.2324\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1388 - val_loss: 0.0880 - val_mae: 0.2179\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1356 - val_loss: 0.0920 - val_mae: 0.2263\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1298 - val_loss: 0.0918 - val_mae: 0.2203\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1357 - val_loss: 0.0907 - val_mae: 0.2195\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1360 - val_loss: 0.0899 - val_mae: 0.2192\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1374 - val_loss: 0.0890 - val_mae: 0.2187\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1302 - val_loss: 0.0972 - val_mae: 0.2344\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1328 - val_loss: 0.0895 - val_mae: 0.2263\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1327 - val_loss: 0.0898 - val_mae: 0.2252\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1333 - val_loss: 0.0912 - val_mae: 0.2174\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1319 - val_loss: 0.0894 - val_mae: 0.2209\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1321 - val_loss: 0.0940 - val_mae: 0.2308\n",
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1321 - val_loss: 0.0901 - val_mae: 0.2264\n",
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1341 - val_loss: 0.0888 - val_mae: 0.2183\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1350 - val_loss: 0.0938 - val_mae: 0.2264\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1350 - val_loss: 0.0894 - val_mae: 0.2222\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1298 - val_loss: 0.0913 - val_mae: 0.2291\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1334 - val_loss: 0.0885 - val_mae: 0.2216\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1319 - val_loss: 0.0941 - val_mae: 0.2288\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1321 - val_loss: 0.0881 - val_mae: 0.2188\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1337 - val_loss: 0.0940 - val_mae: 0.2199\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1318 - val_loss: 0.0945 - val_mae: 0.2323\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1340 - val_loss: 0.0884 - val_mae: 0.2279\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1304 - val_loss: 0.0944 - val_mae: 0.2288\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1317 - val_loss: 0.0921 - val_mae: 0.2203\n",
      "Epoch 309/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1310 - val_loss: 0.0947 - val_mae: 0.2341\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1341 - val_loss: 0.0908 - val_mae: 0.2192\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1345 - val_loss: 0.0909 - val_mae: 0.2199\n",
      "Epoch 312/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1342 - val_loss: 0.0909 - val_mae: 0.2240\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1292 - val_loss: 0.0855 - val_mae: 0.2223\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1327 - val_loss: 0.0905 - val_mae: 0.2220\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1366 - val_loss: 0.0914 - val_mae: 0.2214\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1294 - val_loss: 0.0901 - val_mae: 0.2266\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1311 - val_loss: 0.0891 - val_mae: 0.2184\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1341 - val_loss: 0.0892 - val_mae: 0.2174\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1295 - val_loss: 0.0898 - val_mae: 0.2302\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1376 - val_loss: 0.0878 - val_mae: 0.2226\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1323 - val_loss: 0.0887 - val_mae: 0.2232\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1313 - val_loss: 0.0869 - val_mae: 0.2246\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1329 - val_loss: 0.0868 - val_mae: 0.2208\n",
      "Epoch 324/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1330 - val_loss: 0.0898 - val_mae: 0.2239\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1293 - val_loss: 0.0888 - val_mae: 0.2169\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1294 - val_loss: 0.0908 - val_mae: 0.2354\n",
      "Epoch 327/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1328 - val_loss: 0.0923 - val_mae: 0.2221\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1283 - val_loss: 0.0895 - val_mae: 0.2231\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1309 - val_loss: 0.0906 - val_mae: 0.2256\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1321 - val_loss: 0.0936 - val_mae: 0.2218\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1362 - val_loss: 0.0916 - val_mae: 0.2196\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1302 - val_loss: 0.0914 - val_mae: 0.2258\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1266 - val_loss: 0.0891 - val_mae: 0.2324\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1311 - val_loss: 0.0881 - val_mae: 0.2296\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1322 - val_loss: 0.0903 - val_mae: 0.2311\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1295 - val_loss: 0.0929 - val_mae: 0.2211\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1342 - val_loss: 0.0894 - val_mae: 0.2274\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1324 - val_loss: 0.0928 - val_mae: 0.2202\n",
      "Epoch 339/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1329 - val_loss: 0.0903 - val_mae: 0.2206\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1299 - val_loss: 0.0881 - val_mae: 0.2207\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1291 - val_loss: 0.0923 - val_mae: 0.2265\n",
      "Epoch 342/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1314 - val_loss: 0.0894 - val_mae: 0.2230\n",
      "Epoch 343/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1348 - val_loss: 0.0945 - val_mae: 0.2337\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1285 - val_loss: 0.0932 - val_mae: 0.2177\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1356 - val_loss: 0.0919 - val_mae: 0.2270\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1290 - val_loss: 0.0912 - val_mae: 0.2211\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1312 - val_loss: 0.0923 - val_mae: 0.2254\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1281 - val_loss: 0.0941 - val_mae: 0.2400\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1323 - val_loss: 0.0910 - val_mae: 0.2243\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1309 - val_loss: 0.0925 - val_mae: 0.2234\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0285 - mae: 0.1322 - val_loss: 0.0939 - val_mae: 0.2208\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0264 - mae: 0.1288 - val_loss: 0.0908 - val_mae: 0.2308\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1306 - val_loss: 0.0880 - val_mae: 0.2307\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1318 - val_loss: 0.0959 - val_mae: 0.2249\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1315 - val_loss: 0.0924 - val_mae: 0.2247\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1329 - val_loss: 0.0891 - val_mae: 0.2198\n",
      "Epoch 357/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1308 - val_loss: 0.0914 - val_mae: 0.2277\n",
      "Epoch 358/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1320 - val_loss: 0.0932 - val_mae: 0.2197\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1284 - val_loss: 0.0898 - val_mae: 0.2254\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1264 - val_loss: 0.0941 - val_mae: 0.2183\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1329 - val_loss: 0.0869 - val_mae: 0.2191\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1338 - val_loss: 0.0885 - val_mae: 0.2161\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1311 - val_loss: 0.0909 - val_mae: 0.2256\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1341 - val_loss: 0.0906 - val_mae: 0.2212\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1325 - val_loss: 0.0875 - val_mae: 0.2193\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1277 - val_loss: 0.0890 - val_mae: 0.2212\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1331 - val_loss: 0.0914 - val_mae: 0.2250\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1333 - val_loss: 0.0918 - val_mae: 0.2257\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1325 - val_loss: 0.0929 - val_mae: 0.2304\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.1271 - val_loss: 0.0940 - val_mae: 0.2274\n",
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1290 - val_loss: 0.0923 - val_mae: 0.2194\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1336 - val_loss: 0.0906 - val_mae: 0.2250\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1276 - val_loss: 0.0910 - val_mae: 0.2348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.1258 - val_loss: 0.0920 - val_mae: 0.2267\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1312 - val_loss: 0.0878 - val_mae: 0.2247\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1302 - val_loss: 0.0919 - val_mae: 0.2199\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1301 - val_loss: 0.0912 - val_mae: 0.2248\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1321 - val_loss: 0.0959 - val_mae: 0.2259\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1311 - val_loss: 0.0889 - val_mae: 0.2197\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1313 - val_loss: 0.0915 - val_mae: 0.2208\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1327 - val_loss: 0.0903 - val_mae: 0.2191\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1289 - val_loss: 0.0972 - val_mae: 0.2257\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1300 - val_loss: 0.0893 - val_mae: 0.2210\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.1250 - val_loss: 0.1023 - val_mae: 0.2286\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1311 - val_loss: 0.0975 - val_mae: 0.2318\n",
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1323 - val_loss: 0.0907 - val_mae: 0.2228\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1308 - val_loss: 0.0898 - val_mae: 0.2199\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1291 - val_loss: 0.0893 - val_mae: 0.2269\n",
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1290 - val_loss: 0.0918 - val_mae: 0.2206\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1338 - val_loss: 0.0880 - val_mae: 0.2208\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1318 - val_loss: 0.0888 - val_mae: 0.2247\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1328 - val_loss: 0.0928 - val_mae: 0.2263\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1329 - val_loss: 0.0914 - val_mae: 0.2224\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1302 - val_loss: 0.0923 - val_mae: 0.2230\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1299 - val_loss: 0.0933 - val_mae: 0.2233\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1279 - val_loss: 0.1011 - val_mae: 0.2385\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1335 - val_loss: 0.0911 - val_mae: 0.2228\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1301 - val_loss: 0.0905 - val_mae: 0.2189\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1275 - val_loss: 0.0927 - val_mae: 0.2270\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1250 - val_loss: 0.1017 - val_mae: 0.2326\n",
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1315 - val_loss: 0.0971 - val_mae: 0.2265\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1295 - val_loss: 0.0929 - val_mae: 0.2268\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1325 - val_loss: 0.0897 - val_mae: 0.2210\n",
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1289 - val_loss: 0.0921 - val_mae: 0.2201\n",
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1268 - val_loss: 0.0907 - val_mae: 0.2279\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1268 - val_loss: 0.0925 - val_mae: 0.2246\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1298 - val_loss: 0.0914 - val_mae: 0.2222\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1320 - val_loss: 0.0913 - val_mae: 0.2180\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0245 - mae: 0.1224 - val_loss: 0.0977 - val_mae: 0.2365\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1286 - val_loss: 0.0924 - val_mae: 0.2263\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1322 - val_loss: 0.0933 - val_mae: 0.2240\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1315 - val_loss: 0.0939 - val_mae: 0.2233\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1245 - val_loss: 0.0955 - val_mae: 0.2229\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1296 - val_loss: 0.0931 - val_mae: 0.2277\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1294 - val_loss: 0.0952 - val_mae: 0.2333\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1297 - val_loss: 0.0919 - val_mae: 0.2215\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1270 - val_loss: 0.0913 - val_mae: 0.2195\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1295 - val_loss: 0.0942 - val_mae: 0.2207\n",
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1279 - val_loss: 0.0947 - val_mae: 0.2230\n",
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1221 - val_loss: 0.0956 - val_mae: 0.2347\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1331 - val_loss: 0.0907 - val_mae: 0.2250\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.1250 - val_loss: 0.0980 - val_mae: 0.2381\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1302 - val_loss: 0.0909 - val_mae: 0.2235\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0273 - mae: 0.1286 - val_loss: 0.0930 - val_mae: 0.2286\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1279 - val_loss: 0.0951 - val_mae: 0.2314\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0258 - mae: 0.1258 - val_loss: 0.0965 - val_mae: 0.2357\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.1243 - val_loss: 0.0948 - val_mae: 0.2210\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1260 - val_loss: 0.0928 - val_mae: 0.2234\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0255 - mae: 0.1285 - val_loss: 0.0967 - val_mae: 0.2260\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1260 - val_loss: 0.0994 - val_mae: 0.2410\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1289 - val_loss: 0.0915 - val_mae: 0.2178\n",
      "Epoch 432/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1316 - val_loss: 0.0940 - val_mae: 0.2201\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1274 - val_loss: 0.0941 - val_mae: 0.2292\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1279 - val_loss: 0.0951 - val_mae: 0.2241\n",
      "Epoch 435/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1275 - val_loss: 0.0922 - val_mae: 0.2270\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1279 - val_loss: 0.0941 - val_mae: 0.2302\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1281 - val_loss: 0.0957 - val_mae: 0.2260\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1238 - val_loss: 0.0946 - val_mae: 0.2322\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0250 - mae: 0.1235 - val_loss: 0.0935 - val_mae: 0.2267\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0273 - mae: 0.1276 - val_loss: 0.0932 - val_mae: 0.2260\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1277 - val_loss: 0.0948 - val_mae: 0.2243\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1301 - val_loss: 0.0952 - val_mae: 0.2269\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1272 - val_loss: 0.0931 - val_mae: 0.2240\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1287 - val_loss: 0.0934 - val_mae: 0.2300\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1287 - val_loss: 0.0944 - val_mae: 0.2247\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1285 - val_loss: 0.0951 - val_mae: 0.2281\n",
      "Epoch 447/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1240 - val_loss: 0.0996 - val_mae: 0.2375\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1306 - val_loss: 0.0938 - val_mae: 0.2227\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1300 - val_loss: 0.0917 - val_mae: 0.2210\n",
      "Epoch 450/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1279 - val_loss: 0.0983 - val_mae: 0.2283\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.1266 - val_loss: 0.0961 - val_mae: 0.2347\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1296 - val_loss: 0.0945 - val_mae: 0.2254\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1278 - val_loss: 0.0939 - val_mae: 0.2303\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0252 - mae: 0.1237 - val_loss: 0.0961 - val_mae: 0.2264\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1258 - val_loss: 0.0932 - val_mae: 0.2220\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1272 - val_loss: 0.0958 - val_mae: 0.2316\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1286 - val_loss: 0.0971 - val_mae: 0.2262\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1278 - val_loss: 0.0936 - val_mae: 0.2295\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1291 - val_loss: 0.0925 - val_mae: 0.2280\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1299 - val_loss: 0.0909 - val_mae: 0.2240\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1288 - val_loss: 0.0886 - val_mae: 0.2224\n",
      "Epoch 462/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1316 - val_loss: 0.0923 - val_mae: 0.2276\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1307 - val_loss: 0.0938 - val_mae: 0.2254\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1262 - val_loss: 0.0973 - val_mae: 0.2225\n",
      "Epoch 465/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1299 - val_loss: 0.0931 - val_mae: 0.2271\n",
      "Epoch 466/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1273 - val_loss: 0.0987 - val_mae: 0.2297\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1297 - val_loss: 0.0943 - val_mae: 0.2237\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1271 - val_loss: 0.0923 - val_mae: 0.2259\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1293 - val_loss: 0.0923 - val_mae: 0.2259\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1236 - val_loss: 0.0935 - val_mae: 0.2251\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0248 - mae: 0.1263 - val_loss: 0.0979 - val_mae: 0.2376\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1335 - val_loss: 0.0947 - val_mae: 0.2261\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1287 - val_loss: 0.0965 - val_mae: 0.2287\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1259 - val_loss: 0.0943 - val_mae: 0.2324\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1296 - val_loss: 0.0904 - val_mae: 0.2234\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1291 - val_loss: 0.0927 - val_mae: 0.2257\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1259 - val_loss: 0.0923 - val_mae: 0.2232\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1266 - val_loss: 0.0924 - val_mae: 0.2249\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0239 - mae: 0.1213 - val_loss: 0.0990 - val_mae: 0.2426\n",
      "Epoch 480/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1318 - val_loss: 0.0944 - val_mae: 0.2215\n",
      "Epoch 481/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.1228 - val_loss: 0.0907 - val_mae: 0.2290\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1268 - val_loss: 0.0918 - val_mae: 0.2231\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1251 - val_loss: 0.0938 - val_mae: 0.2330\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1249 - val_loss: 0.0938 - val_mae: 0.2269\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1293 - val_loss: 0.0974 - val_mae: 0.2209\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1257 - val_loss: 0.0961 - val_mae: 0.2362\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1273 - val_loss: 0.0954 - val_mae: 0.2328\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1237 - val_loss: 0.0967 - val_mae: 0.2255\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.1260 - val_loss: 0.0925 - val_mae: 0.2270\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0271 - mae: 0.1301 - val_loss: 0.0937 - val_mae: 0.2272\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1291 - val_loss: 0.0937 - val_mae: 0.2292\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1254 - val_loss: 0.0933 - val_mae: 0.2300\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1276 - val_loss: 0.0963 - val_mae: 0.2209\n",
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1253 - val_loss: 0.0922 - val_mae: 0.2246\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0248 - mae: 0.1266 - val_loss: 0.0999 - val_mae: 0.2230\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1256 - val_loss: 0.0924 - val_mae: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1320 - val_loss: 0.0945 - val_mae: 0.2235\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1265 - val_loss: 0.0910 - val_mae: 0.2209\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1293 - val_loss: 0.0930 - val_mae: 0.2284\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1248 - val_loss: 0.0928 - val_mae: 0.2291\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1272 - val_loss: 0.0962 - val_mae: 0.2382\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1252 - val_loss: 0.0934 - val_mae: 0.2282\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1298 - val_loss: 0.0945 - val_mae: 0.2224\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0246 - mae: 0.1224 - val_loss: 0.1018 - val_mae: 0.2516\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1281 - val_loss: 0.0970 - val_mae: 0.2392\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1262 - val_loss: 0.0941 - val_mae: 0.2243\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1259 - val_loss: 0.0959 - val_mae: 0.2307\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1279 - val_loss: 0.0923 - val_mae: 0.2187\n",
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1226 - val_loss: 0.0942 - val_mae: 0.2201\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1250 - val_loss: 0.0929 - val_mae: 0.2192\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1258 - val_loss: 0.0974 - val_mae: 0.2217\n",
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.1259 - val_loss: 0.0943 - val_mae: 0.2237\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1314 - val_loss: 0.0958 - val_mae: 0.2254\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1281 - val_loss: 0.0930 - val_mae: 0.2227\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1265 - val_loss: 0.0934 - val_mae: 0.2319\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1251 - val_loss: 0.0975 - val_mae: 0.2244\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1281 - val_loss: 0.0923 - val_mae: 0.2236\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1238 - val_loss: 0.0920 - val_mae: 0.2195\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1247 - val_loss: 0.0946 - val_mae: 0.2339\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1289 - val_loss: 0.0951 - val_mae: 0.2228\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1277 - val_loss: 0.0935 - val_mae: 0.2251\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0247 - mae: 0.1254 - val_loss: 0.0925 - val_mae: 0.2187\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1281 - val_loss: 0.0936 - val_mae: 0.2256\n",
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0248 - mae: 0.1212 - val_loss: 0.0931 - val_mae: 0.2290\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1279 - val_loss: 0.0943 - val_mae: 0.2245\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1243 - val_loss: 0.0961 - val_mae: 0.2388\n",
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1293 - val_loss: 0.0964 - val_mae: 0.2298\n",
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1287 - val_loss: 0.0938 - val_mae: 0.2226\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0247 - mae: 0.1263 - val_loss: 0.0972 - val_mae: 0.2228\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1279 - val_loss: 0.0953 - val_mae: 0.2213\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.1239 - val_loss: 0.0954 - val_mae: 0.2271\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0951 - val_mae: 0.2249\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.1257 - val_loss: 0.0986 - val_mae: 0.2283\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1259 - val_loss: 0.0997 - val_mae: 0.2437\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1256 - val_loss: 0.0953 - val_mae: 0.2323\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1265 - val_loss: 0.0944 - val_mae: 0.2216\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0250 - mae: 0.1225 - val_loss: 0.0950 - val_mae: 0.2257\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1263 - val_loss: 0.0938 - val_mae: 0.2232\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1262 - val_loss: 0.0949 - val_mae: 0.2239\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1263 - val_loss: 0.0981 - val_mae: 0.2305\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1239 - val_loss: 0.0942 - val_mae: 0.2316\n",
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1305 - val_loss: 0.0957 - val_mae: 0.2312\n",
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1298 - val_loss: 0.0945 - val_mae: 0.2302\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0251 - mae: 0.1238 - val_loss: 0.0925 - val_mae: 0.2284\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.1264 - val_loss: 0.0970 - val_mae: 0.2317\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1308 - val_loss: 0.0957 - val_mae: 0.2320\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1232 - val_loss: 0.0953 - val_mae: 0.2356\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.1250 - val_loss: 0.0975 - val_mae: 0.2367\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.1275 - val_loss: 0.1017 - val_mae: 0.2224\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1274 - val_loss: 0.0924 - val_mae: 0.2264\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0250 - mae: 0.1222 - val_loss: 0.0930 - val_mae: 0.2252\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.1243 - val_loss: 0.0998 - val_mae: 0.2413\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1263 - val_loss: 0.0990 - val_mae: 0.2341\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1270 - val_loss: 0.0947 - val_mae: 0.2261\n",
      "Epoch 555/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1296 - val_loss: 0.0932 - val_mae: 0.2273\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1273 - val_loss: 0.0969 - val_mae: 0.2346\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0250 - mae: 0.1258 - val_loss: 0.0961 - val_mae: 0.2246\n",
      "Epoch 558/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.1213 - val_loss: 0.0981 - val_mae: 0.2260\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1228 - val_loss: 0.0960 - val_mae: 0.2239\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1275 - val_loss: 0.0942 - val_mae: 0.2207\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1244 - val_loss: 0.0953 - val_mae: 0.2299\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1265 - val_loss: 0.0951 - val_mae: 0.2311\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1276 - val_loss: 0.0930 - val_mae: 0.2252\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1255 - val_loss: 0.0980 - val_mae: 0.2406\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1251 - val_loss: 0.0975 - val_mae: 0.2254\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1248 - val_loss: 0.0948 - val_mae: 0.2321\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0246 - mae: 0.1235 - val_loss: 0.0931 - val_mae: 0.2260\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1260 - val_loss: 0.0974 - val_mae: 0.2371\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1314 - val_loss: 0.0958 - val_mae: 0.2259\n",
      "Epoch 570/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0246 - mae: 0.1215 - val_loss: 0.0970 - val_mae: 0.2358\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1259 - val_loss: 0.0960 - val_mae: 0.2237\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1268 - val_loss: 0.0945 - val_mae: 0.2298\n",
      "Epoch 573/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1251 - val_loss: 0.0972 - val_mae: 0.2221\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0247 - mae: 0.1190 - val_loss: 0.0978 - val_mae: 0.2236\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0248 - mae: 0.1221 - val_loss: 0.0938 - val_mae: 0.2239\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.1275 - val_loss: 0.0932 - val_mae: 0.2261\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1277 - val_loss: 0.0966 - val_mae: 0.2232\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1271 - val_loss: 0.0987 - val_mae: 0.2373\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1261 - val_loss: 0.0996 - val_mae: 0.2364\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1302 - val_loss: 0.0972 - val_mae: 0.2316\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1282 - val_loss: 0.0973 - val_mae: 0.2329\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1283 - val_loss: 0.0978 - val_mae: 0.2329\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0247 - mae: 0.1225 - val_loss: 0.0986 - val_mae: 0.2275\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1281 - val_loss: 0.0985 - val_mae: 0.2340\n",
      "Epoch 585/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1245 - val_loss: 0.1012 - val_mae: 0.2393\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1240 - val_loss: 0.0958 - val_mae: 0.2260\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1262 - val_loss: 0.0935 - val_mae: 0.2311\n",
      "Epoch 588/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1263 - val_loss: 0.0975 - val_mae: 0.2326\n",
      "Epoch 589/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.1233 - val_loss: 0.0995 - val_mae: 0.2300\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1290 - val_loss: 0.0962 - val_mae: 0.2240\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1249 - val_loss: 0.0999 - val_mae: 0.2251\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1259 - val_loss: 0.1052 - val_mae: 0.2386\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1282 - val_loss: 0.0955 - val_mae: 0.2306\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1253 - val_loss: 0.0975 - val_mae: 0.2421\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.1251 - val_loss: 0.0953 - val_mae: 0.2371\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1278 - val_loss: 0.0972 - val_mae: 0.2379\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0248 - mae: 0.1222 - val_loss: 0.0931 - val_mae: 0.2284\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1307 - val_loss: 0.0943 - val_mae: 0.2301\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.1250 - val_loss: 0.0938 - val_mae: 0.2235\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1250 - val_loss: 0.0935 - val_mae: 0.2282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "12\n",
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 0.5035 - mae: 0.5817 - val_loss: 0.3092 - val_mae: 0.4540\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2401 - mae: 0.4208 - val_loss: 0.2136 - val_mae: 0.4019\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1987 - mae: 0.3759 - val_loss: 0.1973 - val_mae: 0.3833\n",
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1590 - mae: 0.3376 - val_loss: 0.1999 - val_mae: 0.3806\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1357 - mae: 0.3113 - val_loss: 0.1556 - val_mae: 0.3137\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1201 - mae: 0.2822 - val_loss: 0.1643 - val_mae: 0.3237\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1040 - mae: 0.2581 - val_loss: 0.1492 - val_mae: 0.2964\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0938 - mae: 0.2392 - val_loss: 0.1389 - val_mae: 0.2861\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0837 - mae: 0.2280 - val_loss: 0.1498 - val_mae: 0.2825\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0794 - mae: 0.2196 - val_loss: 0.1352 - val_mae: 0.2683\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0780 - mae: 0.2167 - val_loss: 0.1316 - val_mae: 0.2665\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0733 - mae: 0.2124 - val_loss: 0.1404 - val_mae: 0.2704\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0733 - mae: 0.2116 - val_loss: 0.1368 - val_mae: 0.2642\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - mae: 0.2017 - val_loss: 0.1426 - val_mae: 0.2811\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - mae: 0.2039 - val_loss: 0.1294 - val_mae: 0.2639\n",
      "Epoch 16/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0696 - mae: 0.1981 - val_loss: 0.1294 - val_mae: 0.2552\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0686 - mae: 0.2015 - val_loss: 0.1292 - val_mae: 0.2543\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - mae: 0.2006 - val_loss: 0.1218 - val_mae: 0.2481\n",
      "Epoch 19/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0666 - mae: 0.1981 - val_loss: 0.1229 - val_mae: 0.2597\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - mae: 0.1957 - val_loss: 0.1185 - val_mae: 0.2447\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0608 - mae: 0.1931 - val_loss: 0.1534 - val_mae: 0.2858\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0665 - mae: 0.2035 - val_loss: 0.1223 - val_mae: 0.2484\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0633 - mae: 0.1955 - val_loss: 0.1195 - val_mae: 0.2559\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0602 - mae: 0.1890 - val_loss: 0.1128 - val_mae: 0.2415\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0610 - mae: 0.1910 - val_loss: 0.1084 - val_mae: 0.2331\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0609 - mae: 0.1944 - val_loss: 0.1136 - val_mae: 0.2525\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0605 - mae: 0.1928 - val_loss: 0.1064 - val_mae: 0.2269\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0620 - mae: 0.1978 - val_loss: 0.1100 - val_mae: 0.2369\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0575 - mae: 0.1892 - val_loss: 0.1126 - val_mae: 0.2394\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0569 - mae: 0.1802 - val_loss: 0.1272 - val_mae: 0.2724\n",
      "Epoch 31/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0596 - mae: 0.1894 - val_loss: 0.1062 - val_mae: 0.2296\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0550 - mae: 0.1838 - val_loss: 0.1075 - val_mae: 0.2330\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0580 - mae: 0.1876 - val_loss: 0.1019 - val_mae: 0.2210\n",
      "Epoch 34/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0545 - mae: 0.1842 - val_loss: 0.1043 - val_mae: 0.2303\n",
      "Epoch 35/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0531 - mae: 0.1832 - val_loss: 0.1210 - val_mae: 0.2526\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0544 - mae: 0.1861 - val_loss: 0.1155 - val_mae: 0.2477\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - mae: 0.1835 - val_loss: 0.1085 - val_mae: 0.2418\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.1804 - val_loss: 0.1004 - val_mae: 0.2287\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1773 - val_loss: 0.0982 - val_mae: 0.2196\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0519 - mae: 0.1817 - val_loss: 0.1070 - val_mae: 0.2392\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - mae: 0.1848 - val_loss: 0.0967 - val_mae: 0.2174\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0510 - mae: 0.1777 - val_loss: 0.0988 - val_mae: 0.2230\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - mae: 0.1794 - val_loss: 0.0979 - val_mae: 0.2212\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0519 - mae: 0.1823 - val_loss: 0.0967 - val_mae: 0.2207\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1715 - val_loss: 0.1028 - val_mae: 0.2454\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0501 - mae: 0.1721 - val_loss: 0.0970 - val_mae: 0.2294\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0489 - mae: 0.1732 - val_loss: 0.0969 - val_mae: 0.2210\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0493 - mae: 0.1724 - val_loss: 0.0934 - val_mae: 0.2139\n",
      "Epoch 49/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0498 - mae: 0.1760 - val_loss: 0.0998 - val_mae: 0.2281\n",
      "Epoch 50/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1682 - val_loss: 0.0952 - val_mae: 0.2306\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.1764 - val_loss: 0.0990 - val_mae: 0.2377\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0493 - mae: 0.1736 - val_loss: 0.0911 - val_mae: 0.2130\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - mae: 0.1707 - val_loss: 0.0983 - val_mae: 0.2382\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0478 - mae: 0.1732 - val_loss: 0.0901 - val_mae: 0.2122\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.1676 - val_loss: 0.0906 - val_mae: 0.2183\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.1706 - val_loss: 0.0892 - val_mae: 0.2115\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.1726 - val_loss: 0.0910 - val_mae: 0.2153\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1670 - val_loss: 0.0887 - val_mae: 0.2127\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.1701 - val_loss: 0.0898 - val_mae: 0.2150\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0459 - mae: 0.1682 - val_loss: 0.0886 - val_mae: 0.2121\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1689 - val_loss: 0.0886 - val_mae: 0.2137\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1689 - val_loss: 0.0887 - val_mae: 0.2133\n",
      "Epoch 63/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.1599 - val_loss: 0.0872 - val_mae: 0.2125\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0452 - mae: 0.1647 - val_loss: 0.0879 - val_mae: 0.2146\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1636 - val_loss: 0.0914 - val_mae: 0.2237\n",
      "Epoch 66/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1600 - val_loss: 0.0974 - val_mae: 0.2334\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.1615 - val_loss: 0.0864 - val_mae: 0.2110\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1609 - val_loss: 0.0858 - val_mae: 0.2112\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0417 - mae: 0.1583 - val_loss: 0.0851 - val_mae: 0.2112\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1604 - val_loss: 0.0847 - val_mae: 0.2108\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1626 - val_loss: 0.0862 - val_mae: 0.2137\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0407 - mae: 0.1566 - val_loss: 0.0882 - val_mae: 0.2155\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1628 - val_loss: 0.0860 - val_mae: 0.2140\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1610 - val_loss: 0.0852 - val_mae: 0.2157\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1610 - val_loss: 0.0826 - val_mae: 0.2076\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1595 - val_loss: 0.0821 - val_mae: 0.2070\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.1608 - val_loss: 0.0823 - val_mae: 0.2064\n",
      "Epoch 78/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0379 - mae: 0.1533 - val_loss: 0.0849 - val_mae: 0.2137\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - mae: 0.1558 - val_loss: 0.0805 - val_mae: 0.2058\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0386 - mae: 0.1544 - val_loss: 0.0840 - val_mae: 0.2123\n",
      "Epoch 81/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.1542 - val_loss: 0.0824 - val_mae: 0.2079\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1534 - val_loss: 0.0845 - val_mae: 0.2140\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1543 - val_loss: 0.0830 - val_mae: 0.2116\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1525 - val_loss: 0.0841 - val_mae: 0.2172\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0396 - mae: 0.1560 - val_loss: 0.0797 - val_mae: 0.2042\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0365 - mae: 0.1522 - val_loss: 0.0816 - val_mae: 0.2069\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.1552 - val_loss: 0.0845 - val_mae: 0.2111\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1556 - val_loss: 0.0800 - val_mae: 0.2075\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1477 - val_loss: 0.0813 - val_mae: 0.2095\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1535 - val_loss: 0.0784 - val_mae: 0.2068\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1492 - val_loss: 0.0773 - val_mae: 0.2054\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1492 - val_loss: 0.0782 - val_mae: 0.2067\n",
      "Epoch 93/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1501 - val_loss: 0.0869 - val_mae: 0.2165\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1522 - val_loss: 0.0855 - val_mae: 0.2141\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0365 - mae: 0.1517 - val_loss: 0.0784 - val_mae: 0.2061\n",
      "Epoch 96/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1476 - val_loss: 0.0795 - val_mae: 0.2072\n",
      "Epoch 97/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1470 - val_loss: 0.0805 - val_mae: 0.2083\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0354 - mae: 0.1496 - val_loss: 0.0801 - val_mae: 0.2081\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1491 - val_loss: 0.0757 - val_mae: 0.2050\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1471 - val_loss: 0.0814 - val_mae: 0.2100\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.1453 - val_loss: 0.0805 - val_mae: 0.2090\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0354 - mae: 0.1497 - val_loss: 0.0774 - val_mae: 0.2073\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1467 - val_loss: 0.0780 - val_mae: 0.2078\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - mae: 0.1518 - val_loss: 0.0776 - val_mae: 0.2060\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - mae: 0.1467 - val_loss: 0.0800 - val_mae: 0.2098\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1472 - val_loss: 0.0781 - val_mae: 0.2081\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.1482 - val_loss: 0.0796 - val_mae: 0.2073\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1512 - val_loss: 0.0815 - val_mae: 0.2112\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1494 - val_loss: 0.0776 - val_mae: 0.2079\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1460 - val_loss: 0.0784 - val_mae: 0.2088\n",
      "Epoch 111/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1479 - val_loss: 0.0800 - val_mae: 0.2084\n",
      "Epoch 112/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1475 - val_loss: 0.0782 - val_mae: 0.2079\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.1485 - val_loss: 0.0789 - val_mae: 0.2077\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1442 - val_loss: 0.0788 - val_mae: 0.2080\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1458 - val_loss: 0.0823 - val_mae: 0.2118\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1440 - val_loss: 0.0790 - val_mae: 0.2136\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1452 - val_loss: 0.0775 - val_mae: 0.2081\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1448 - val_loss: 0.0813 - val_mae: 0.2096\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0337 - mae: 0.1514 - val_loss: 0.0817 - val_mae: 0.2108\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0327 - mae: 0.1482 - val_loss: 0.0778 - val_mae: 0.2072\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0307 - mae: 0.1453 - val_loss: 0.0804 - val_mae: 0.2072\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1476 - val_loss: 0.0814 - val_mae: 0.2107\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1442 - val_loss: 0.0788 - val_mae: 0.2103\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1450 - val_loss: 0.0780 - val_mae: 0.2074\n",
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1484 - val_loss: 0.0804 - val_mae: 0.2074\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1476 - val_loss: 0.0776 - val_mae: 0.2077\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1431 - val_loss: 0.0801 - val_mae: 0.2100\n",
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1469 - val_loss: 0.0814 - val_mae: 0.2134\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1429 - val_loss: 0.0781 - val_mae: 0.2082\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1410 - val_loss: 0.0776 - val_mae: 0.2073\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1411 - val_loss: 0.0884 - val_mae: 0.2178\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1452 - val_loss: 0.0785 - val_mae: 0.2116\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1433 - val_loss: 0.0839 - val_mae: 0.2124\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1410 - val_loss: 0.0785 - val_mae: 0.2110\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1466 - val_loss: 0.0786 - val_mae: 0.2096\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1448 - val_loss: 0.0781 - val_mae: 0.2076\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1424 - val_loss: 0.0796 - val_mae: 0.2076\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1435 - val_loss: 0.0782 - val_mae: 0.2107\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1417 - val_loss: 0.0806 - val_mae: 0.2072\n",
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1457 - val_loss: 0.0836 - val_mae: 0.2144\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1497 - val_loss: 0.0840 - val_mae: 0.2107\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1397 - val_loss: 0.0839 - val_mae: 0.2249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1429 - val_loss: 0.0790 - val_mae: 0.2114\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1432 - val_loss: 0.0816 - val_mae: 0.2111\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1451 - val_loss: 0.0794 - val_mae: 0.2121\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1430 - val_loss: 0.0780 - val_mae: 0.2082\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1406 - val_loss: 0.0790 - val_mae: 0.2077\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1441 - val_loss: 0.0807 - val_mae: 0.2135\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1427 - val_loss: 0.0806 - val_mae: 0.2095\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1453 - val_loss: 0.0805 - val_mae: 0.2102\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1420 - val_loss: 0.0847 - val_mae: 0.2172\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1418 - val_loss: 0.0840 - val_mae: 0.2131\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1415 - val_loss: 0.0916 - val_mae: 0.2162\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1441 - val_loss: 0.0838 - val_mae: 0.2166\n",
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1423 - val_loss: 0.0822 - val_mae: 0.2104\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1407 - val_loss: 0.0835 - val_mae: 0.2185\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1448 - val_loss: 0.0823 - val_mae: 0.2154\n",
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1427 - val_loss: 0.0815 - val_mae: 0.2151\n",
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1432 - val_loss: 0.0811 - val_mae: 0.2103\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1392 - val_loss: 0.0864 - val_mae: 0.2165\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1466 - val_loss: 0.0785 - val_mae: 0.2118\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1405 - val_loss: 0.0826 - val_mae: 0.2088\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1424 - val_loss: 0.0858 - val_mae: 0.2145\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1418 - val_loss: 0.0819 - val_mae: 0.2090\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1400 - val_loss: 0.0853 - val_mae: 0.2117\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1432 - val_loss: 0.0793 - val_mae: 0.2122\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1427 - val_loss: 0.0803 - val_mae: 0.2117\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1403 - val_loss: 0.0815 - val_mae: 0.2108\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1447 - val_loss: 0.0841 - val_mae: 0.2116\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1393 - val_loss: 0.0834 - val_mae: 0.2116\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1413 - val_loss: 0.0830 - val_mae: 0.2101\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1409 - val_loss: 0.0826 - val_mae: 0.2126\n",
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1415 - val_loss: 0.0816 - val_mae: 0.2091\n",
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1400 - val_loss: 0.0817 - val_mae: 0.2188\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1421 - val_loss: 0.0838 - val_mae: 0.2136\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1424 - val_loss: 0.0829 - val_mae: 0.2103\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1390 - val_loss: 0.0826 - val_mae: 0.2085\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1382 - val_loss: 0.0823 - val_mae: 0.2125\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1427 - val_loss: 0.0823 - val_mae: 0.2073\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1376 - val_loss: 0.0835 - val_mae: 0.2173\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1450 - val_loss: 0.0837 - val_mae: 0.2094\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1446 - val_loss: 0.0821 - val_mae: 0.2097\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1405 - val_loss: 0.0805 - val_mae: 0.2092\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1429 - val_loss: 0.0819 - val_mae: 0.2115\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1389 - val_loss: 0.0881 - val_mae: 0.2212\n",
      "Epoch 186/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1381 - val_loss: 0.0856 - val_mae: 0.2126\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1442 - val_loss: 0.0842 - val_mae: 0.2110\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1416 - val_loss: 0.0845 - val_mae: 0.2117\n",
      "Epoch 189/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1411 - val_loss: 0.0826 - val_mae: 0.2112\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1399 - val_loss: 0.0835 - val_mae: 0.2142\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1409 - val_loss: 0.0876 - val_mae: 0.2130\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1359 - val_loss: 0.0841 - val_mae: 0.2067\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1402 - val_loss: 0.0862 - val_mae: 0.2154\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1409 - val_loss: 0.0820 - val_mae: 0.2121\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1406 - val_loss: 0.0820 - val_mae: 0.2090\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1362 - val_loss: 0.0872 - val_mae: 0.2151\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0297 - mae: 0.1401 - val_loss: 0.0810 - val_mae: 0.2100\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1356 - val_loss: 0.0798 - val_mae: 0.2135\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1448 - val_loss: 0.0817 - val_mae: 0.2087\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1416 - val_loss: 0.0822 - val_mae: 0.2087\n",
      "Epoch 201/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1425 - val_loss: 0.0816 - val_mae: 0.2166\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1392 - val_loss: 0.0810 - val_mae: 0.2149\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1374 - val_loss: 0.0836 - val_mae: 0.2052\n",
      "Epoch 204/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1418 - val_loss: 0.0857 - val_mae: 0.2115\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1412 - val_loss: 0.0820 - val_mae: 0.2121\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1398 - val_loss: 0.0847 - val_mae: 0.2118\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1422 - val_loss: 0.0823 - val_mae: 0.2112\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1390 - val_loss: 0.0847 - val_mae: 0.2088\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1387 - val_loss: 0.0814 - val_mae: 0.2122\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1366 - val_loss: 0.0829 - val_mae: 0.2156\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1426 - val_loss: 0.0871 - val_mae: 0.2118\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1447 - val_loss: 0.0822 - val_mae: 0.2057\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1407 - val_loss: 0.0807 - val_mae: 0.2131\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1425 - val_loss: 0.0827 - val_mae: 0.2087\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1435 - val_loss: 0.0872 - val_mae: 0.2120\n",
      "Epoch 216/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1394 - val_loss: 0.0883 - val_mae: 0.2100\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1383 - val_loss: 0.0853 - val_mae: 0.2142\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1394 - val_loss: 0.0837 - val_mae: 0.2075\n",
      "Epoch 219/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1417 - val_loss: 0.0841 - val_mae: 0.2081\n",
      "Epoch 220/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1390 - val_loss: 0.0849 - val_mae: 0.2141\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1411 - val_loss: 0.0825 - val_mae: 0.2133\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1396 - val_loss: 0.0836 - val_mae: 0.2089\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1391 - val_loss: 0.0826 - val_mae: 0.2107\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1392 - val_loss: 0.0862 - val_mae: 0.2117\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1397 - val_loss: 0.0818 - val_mae: 0.2114\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1393 - val_loss: 0.0851 - val_mae: 0.2061\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1389 - val_loss: 0.0824 - val_mae: 0.2070\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1405 - val_loss: 0.0820 - val_mae: 0.2148\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1424 - val_loss: 0.0824 - val_mae: 0.2127\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1369 - val_loss: 0.0826 - val_mae: 0.2104\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1363 - val_loss: 0.0821 - val_mae: 0.2099\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1397 - val_loss: 0.0839 - val_mae: 0.2085\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1340 - val_loss: 0.0826 - val_mae: 0.2133\n",
      "Epoch 234/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1377 - val_loss: 0.0828 - val_mae: 0.2093\n",
      "Epoch 235/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1350 - val_loss: 0.0852 - val_mae: 0.2044\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1412 - val_loss: 0.0883 - val_mae: 0.2087\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1400 - val_loss: 0.0840 - val_mae: 0.2066\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1383 - val_loss: 0.0846 - val_mae: 0.2097\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1350 - val_loss: 0.0861 - val_mae: 0.2069\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - mae: 0.1415 - val_loss: 0.0882 - val_mae: 0.2116\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1414 - val_loss: 0.0868 - val_mae: 0.2086\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1389 - val_loss: 0.0907 - val_mae: 0.2144\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1408 - val_loss: 0.0874 - val_mae: 0.2073\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1378 - val_loss: 0.0860 - val_mae: 0.2092\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1381 - val_loss: 0.0840 - val_mae: 0.2075\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1376 - val_loss: 0.0862 - val_mae: 0.2061\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1390 - val_loss: 0.0855 - val_mae: 0.2095\n",
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1359 - val_loss: 0.0831 - val_mae: 0.2067\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1360 - val_loss: 0.0824 - val_mae: 0.2127\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1345 - val_loss: 0.0863 - val_mae: 0.2100\n",
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1382 - val_loss: 0.0824 - val_mae: 0.2084\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1392 - val_loss: 0.0881 - val_mae: 0.2072\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1371 - val_loss: 0.0839 - val_mae: 0.2111\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1401 - val_loss: 0.0841 - val_mae: 0.2116\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1425 - val_loss: 0.0841 - val_mae: 0.2081\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1383 - val_loss: 0.0845 - val_mae: 0.2134\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1355 - val_loss: 0.0868 - val_mae: 0.2103\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1434 - val_loss: 0.0886 - val_mae: 0.2094\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1393 - val_loss: 0.0853 - val_mae: 0.2084\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.1345 - val_loss: 0.0844 - val_mae: 0.2125\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1382 - val_loss: 0.0853 - val_mae: 0.2048\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1376 - val_loss: 0.0853 - val_mae: 0.2115\n",
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1298 - val_loss: 0.0871 - val_mae: 0.2114\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0268 - mae: 0.1350 - val_loss: 0.0965 - val_mae: 0.2182\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1341 - val_loss: 0.0879 - val_mae: 0.2169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1370 - val_loss: 0.0880 - val_mae: 0.2164\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1378 - val_loss: 0.0850 - val_mae: 0.2150\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1358 - val_loss: 0.0951 - val_mae: 0.2131\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1363 - val_loss: 0.0851 - val_mae: 0.2071\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1362 - val_loss: 0.0829 - val_mae: 0.2135\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1383 - val_loss: 0.0837 - val_mae: 0.2121\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1400 - val_loss: 0.0851 - val_mae: 0.2158\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1342 - val_loss: 0.0868 - val_mae: 0.2108\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1372 - val_loss: 0.0848 - val_mae: 0.2135\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0296 - mae: 0.1379 - val_loss: 0.0843 - val_mae: 0.2083\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1368 - val_loss: 0.0860 - val_mae: 0.2089\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1362 - val_loss: 0.0873 - val_mae: 0.2089\n",
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1353 - val_loss: 0.0839 - val_mae: 0.2088\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1373 - val_loss: 0.0859 - val_mae: 0.2076\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1367 - val_loss: 0.0869 - val_mae: 0.2101\n",
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1387 - val_loss: 0.0843 - val_mae: 0.2117\n",
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1350 - val_loss: 0.0872 - val_mae: 0.2075\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1377 - val_loss: 0.0892 - val_mae: 0.2062\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1381 - val_loss: 0.0914 - val_mae: 0.2127\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1337 - val_loss: 0.0867 - val_mae: 0.2166\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1375 - val_loss: 0.0874 - val_mae: 0.2075\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1383 - val_loss: 0.0854 - val_mae: 0.2094\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1363 - val_loss: 0.0868 - val_mae: 0.2070\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1371 - val_loss: 0.0881 - val_mae: 0.2084\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1327 - val_loss: 0.0853 - val_mae: 0.2183\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1340 - val_loss: 0.0881 - val_mae: 0.2091\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1344 - val_loss: 0.0848 - val_mae: 0.2046\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1324 - val_loss: 0.0830 - val_mae: 0.2062\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1402 - val_loss: 0.0845 - val_mae: 0.2075\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1320 - val_loss: 0.0845 - val_mae: 0.2121\n",
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1348 - val_loss: 0.0839 - val_mae: 0.2076\n",
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1325 - val_loss: 0.0855 - val_mae: 0.2043\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1364 - val_loss: 0.0854 - val_mae: 0.2051\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1361 - val_loss: 0.0918 - val_mae: 0.2161\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1317 - val_loss: 0.0878 - val_mae: 0.2094\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1354 - val_loss: 0.0857 - val_mae: 0.2100\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1336 - val_loss: 0.0896 - val_mae: 0.2065\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1338 - val_loss: 0.0884 - val_mae: 0.2141\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1386 - val_loss: 0.0842 - val_mae: 0.2092\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1334 - val_loss: 0.0864 - val_mae: 0.2048\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1334 - val_loss: 0.0851 - val_mae: 0.2082\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1319 - val_loss: 0.0861 - val_mae: 0.2103\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1331 - val_loss: 0.0860 - val_mae: 0.2063\n",
      "Epoch 309/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1332 - val_loss: 0.0891 - val_mae: 0.2087\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1334 - val_loss: 0.0856 - val_mae: 0.2085\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1337 - val_loss: 0.0858 - val_mae: 0.2106\n",
      "Epoch 312/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1324 - val_loss: 0.0844 - val_mae: 0.2096\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1375 - val_loss: 0.0828 - val_mae: 0.2083\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1323 - val_loss: 0.0842 - val_mae: 0.2086\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1362 - val_loss: 0.0845 - val_mae: 0.2092\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1345 - val_loss: 0.0865 - val_mae: 0.2132\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1353 - val_loss: 0.0852 - val_mae: 0.2076\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1301 - val_loss: 0.0926 - val_mae: 0.2146\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1342 - val_loss: 0.0862 - val_mae: 0.2027\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1350 - val_loss: 0.0875 - val_mae: 0.2061\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1370 - val_loss: 0.0860 - val_mae: 0.2031\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1370 - val_loss: 0.0848 - val_mae: 0.2088\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1311 - val_loss: 0.0844 - val_mae: 0.2098\n",
      "Epoch 324/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - mae: 0.1348 - val_loss: 0.0870 - val_mae: 0.2134\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1363 - val_loss: 0.0911 - val_mae: 0.2080\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1333 - val_loss: 0.0874 - val_mae: 0.2037\n",
      "Epoch 327/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1342 - val_loss: 0.0849 - val_mae: 0.2065\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1383 - val_loss: 0.0882 - val_mae: 0.2081\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1304 - val_loss: 0.0851 - val_mae: 0.2070\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1353 - val_loss: 0.0856 - val_mae: 0.2070\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1325 - val_loss: 0.0842 - val_mae: 0.2061\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1329 - val_loss: 0.0845 - val_mae: 0.2030\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1320 - val_loss: 0.0830 - val_mae: 0.2072\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1349 - val_loss: 0.0868 - val_mae: 0.2074\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1336 - val_loss: 0.0869 - val_mae: 0.2041\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1340 - val_loss: 0.0889 - val_mae: 0.2046\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1355 - val_loss: 0.0903 - val_mae: 0.2065\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1349 - val_loss: 0.0873 - val_mae: 0.2093\n",
      "Epoch 339/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1358 - val_loss: 0.0919 - val_mae: 0.2172\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1329 - val_loss: 0.0855 - val_mae: 0.2088\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1349 - val_loss: 0.0899 - val_mae: 0.2106\n",
      "Epoch 342/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1356 - val_loss: 0.0876 - val_mae: 0.2080\n",
      "Epoch 343/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.1342 - val_loss: 0.0854 - val_mae: 0.2068\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1386 - val_loss: 0.0894 - val_mae: 0.2061\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1299 - val_loss: 0.0834 - val_mae: 0.2057\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1344 - val_loss: 0.0875 - val_mae: 0.2052\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1384 - val_loss: 0.0874 - val_mae: 0.2029\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1319 - val_loss: 0.0858 - val_mae: 0.2081\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1347 - val_loss: 0.0875 - val_mae: 0.2017\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1334 - val_loss: 0.0879 - val_mae: 0.2057\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1344 - val_loss: 0.0842 - val_mae: 0.2067\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1359 - val_loss: 0.0861 - val_mae: 0.2080\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1345 - val_loss: 0.0850 - val_mae: 0.2084\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1327 - val_loss: 0.0843 - val_mae: 0.2060\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1349 - val_loss: 0.0864 - val_mae: 0.2129\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1337 - val_loss: 0.0870 - val_mae: 0.2030\n",
      "Epoch 357/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1316 - val_loss: 0.0893 - val_mae: 0.2061\n",
      "Epoch 358/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1354 - val_loss: 0.0869 - val_mae: 0.2090\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1334 - val_loss: 0.0845 - val_mae: 0.2041\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1297 - val_loss: 0.0906 - val_mae: 0.2066\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1373 - val_loss: 0.0871 - val_mae: 0.2048\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1311 - val_loss: 0.0890 - val_mae: 0.2068\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1339 - val_loss: 0.0862 - val_mae: 0.2040\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1342 - val_loss: 0.0841 - val_mae: 0.2046\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1322 - val_loss: 0.0843 - val_mae: 0.2036\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1344 - val_loss: 0.0884 - val_mae: 0.2102\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1320 - val_loss: 0.0877 - val_mae: 0.2053\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1339 - val_loss: 0.0887 - val_mae: 0.2027\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1304 - val_loss: 0.0845 - val_mae: 0.2082\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1339 - val_loss: 0.0857 - val_mae: 0.2025\n",
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1315 - val_loss: 0.0869 - val_mae: 0.2084\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1339 - val_loss: 0.0933 - val_mae: 0.2131\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1364 - val_loss: 0.0921 - val_mae: 0.2079\n",
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1337 - val_loss: 0.0857 - val_mae: 0.2074\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1331 - val_loss: 0.0850 - val_mae: 0.2101\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1329 - val_loss: 0.0915 - val_mae: 0.2099\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1325 - val_loss: 0.0894 - val_mae: 0.2040\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1315 - val_loss: 0.0925 - val_mae: 0.2119\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1341 - val_loss: 0.0867 - val_mae: 0.2036\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1318 - val_loss: 0.0934 - val_mae: 0.2142\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1299 - val_loss: 0.0867 - val_mae: 0.2056\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1313 - val_loss: 0.0877 - val_mae: 0.2113\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1273 - val_loss: 0.0880 - val_mae: 0.2030\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1359 - val_loss: 0.0861 - val_mae: 0.2083\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1340 - val_loss: 0.0864 - val_mae: 0.2045\n",
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1305 - val_loss: 0.0861 - val_mae: 0.2078\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0273 - mae: 0.1344 - val_loss: 0.0865 - val_mae: 0.2132\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0277 - mae: 0.1336 - val_loss: 0.0874 - val_mae: 0.2095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1321 - val_loss: 0.0925 - val_mae: 0.2096\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1331 - val_loss: 0.0873 - val_mae: 0.2090\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1338 - val_loss: 0.0863 - val_mae: 0.2031\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1329 - val_loss: 0.0911 - val_mae: 0.2079\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1326 - val_loss: 0.0858 - val_mae: 0.2015\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.1383 - val_loss: 0.0879 - val_mae: 0.2019\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - mae: 0.1320 - val_loss: 0.0883 - val_mae: 0.2052\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1334 - val_loss: 0.0923 - val_mae: 0.2056\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1325 - val_loss: 0.0854 - val_mae: 0.2078\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1340 - val_loss: 0.0856 - val_mae: 0.2021\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1319 - val_loss: 0.0870 - val_mae: 0.2068\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1351 - val_loss: 0.0902 - val_mae: 0.2048\n",
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1363 - val_loss: 0.0893 - val_mae: 0.2017\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0877 - val_mae: 0.2072\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1317 - val_loss: 0.0882 - val_mae: 0.2081\n",
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1283 - val_loss: 0.0851 - val_mae: 0.2104\n",
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1334 - val_loss: 0.0890 - val_mae: 0.2036\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1307 - val_loss: 0.0888 - val_mae: 0.2034\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1326 - val_loss: 0.0869 - val_mae: 0.2015\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1345 - val_loss: 0.0898 - val_mae: 0.2029\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0269 - mae: 0.1310 - val_loss: 0.0883 - val_mae: 0.2044\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1359 - val_loss: 0.0853 - val_mae: 0.2047\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1283 - val_loss: 0.0897 - val_mae: 0.2082\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1384 - val_loss: 0.0874 - val_mae: 0.2018\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1312 - val_loss: 0.0928 - val_mae: 0.2056\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1337 - val_loss: 0.0873 - val_mae: 0.2035\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0261 - mae: 0.1284 - val_loss: 0.0927 - val_mae: 0.2180\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0278 - mae: 0.1323 - val_loss: 0.0863 - val_mae: 0.2045\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1336 - val_loss: 0.0879 - val_mae: 0.2035\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1305 - val_loss: 0.0863 - val_mae: 0.2117\n",
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1323 - val_loss: 0.0917 - val_mae: 0.2062\n",
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1353 - val_loss: 0.0898 - val_mae: 0.2089\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1346 - val_loss: 0.0860 - val_mae: 0.2067\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1302 - val_loss: 0.0902 - val_mae: 0.2055\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1305 - val_loss: 0.0881 - val_mae: 0.2036\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1375 - val_loss: 0.0902 - val_mae: 0.2033\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1303 - val_loss: 0.0873 - val_mae: 0.2098\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1356 - val_loss: 0.0889 - val_mae: 0.2022\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1329 - val_loss: 0.0855 - val_mae: 0.2049\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0279 - mae: 0.1323 - val_loss: 0.0865 - val_mae: 0.2050\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1338 - val_loss: 0.0882 - val_mae: 0.2057\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1334 - val_loss: 0.0867 - val_mae: 0.2099\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1348 - val_loss: 0.0888 - val_mae: 0.2128\n",
      "Epoch 432/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1279 - val_loss: 0.0913 - val_mae: 0.2092\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1298 - val_loss: 0.0908 - val_mae: 0.2155\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1301 - val_loss: 0.0864 - val_mae: 0.2151\n",
      "Epoch 435/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1329 - val_loss: 0.0883 - val_mae: 0.2041\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1349 - val_loss: 0.0897 - val_mae: 0.2063\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1275 - val_loss: 0.0924 - val_mae: 0.2085\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1337 - val_loss: 0.0907 - val_mae: 0.2044\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1381 - val_loss: 0.0952 - val_mae: 0.2102\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1304 - val_loss: 0.0889 - val_mae: 0.2082\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1346 - val_loss: 0.0890 - val_mae: 0.1993\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1342 - val_loss: 0.0911 - val_mae: 0.2096\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.1278 - val_loss: 0.0904 - val_mae: 0.2011\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1313 - val_loss: 0.0873 - val_mae: 0.2040\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1312 - val_loss: 0.0885 - val_mae: 0.2130\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1288 - val_loss: 0.0952 - val_mae: 0.2125\n",
      "Epoch 447/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1293 - val_loss: 0.0916 - val_mae: 0.2120\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1318 - val_loss: 0.0889 - val_mae: 0.2068\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1309 - val_loss: 0.0868 - val_mae: 0.2060\n",
      "Epoch 450/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1361 - val_loss: 0.0891 - val_mae: 0.2035\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1329 - val_loss: 0.0911 - val_mae: 0.2066\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1326 - val_loss: 0.0851 - val_mae: 0.2037\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1385 - val_loss: 0.0861 - val_mae: 0.2032\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1315 - val_loss: 0.0898 - val_mae: 0.2023\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1299 - val_loss: 0.0894 - val_mae: 0.2177\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0263 - mae: 0.1292 - val_loss: 0.0889 - val_mae: 0.2005\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1314 - val_loss: 0.0865 - val_mae: 0.2003\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1319 - val_loss: 0.0986 - val_mae: 0.2237\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1314 - val_loss: 0.0876 - val_mae: 0.2063\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1319 - val_loss: 0.0890 - val_mae: 0.2011\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1312 - val_loss: 0.0896 - val_mae: 0.2148\n",
      "Epoch 462/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1294 - val_loss: 0.0931 - val_mae: 0.2059\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0260 - mae: 0.1275 - val_loss: 0.0893 - val_mae: 0.2021\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0276 - mae: 0.1350 - val_loss: 0.0948 - val_mae: 0.2064\n",
      "Epoch 465/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1304 - val_loss: 0.0885 - val_mae: 0.2076\n",
      "Epoch 466/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1346 - val_loss: 0.0889 - val_mae: 0.2053\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1292 - val_loss: 0.0902 - val_mae: 0.2012\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1284 - val_loss: 0.0923 - val_mae: 0.2207\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1340 - val_loss: 0.0918 - val_mae: 0.2056\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1327 - val_loss: 0.0885 - val_mae: 0.2033\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1286 - val_loss: 0.0926 - val_mae: 0.2089\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0248 - mae: 0.1264 - val_loss: 0.0927 - val_mae: 0.2042\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1342 - val_loss: 0.0870 - val_mae: 0.2069\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1329 - val_loss: 0.0874 - val_mae: 0.2122\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1333 - val_loss: 0.0857 - val_mae: 0.2055\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1317 - val_loss: 0.0896 - val_mae: 0.2063\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1316 - val_loss: 0.0897 - val_mae: 0.2031\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1320 - val_loss: 0.0878 - val_mae: 0.2055\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1305 - val_loss: 0.0874 - val_mae: 0.2074\n",
      "Epoch 480/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1325 - val_loss: 0.0865 - val_mae: 0.2056\n",
      "Epoch 481/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1355 - val_loss: 0.0866 - val_mae: 0.2052\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1318 - val_loss: 0.0895 - val_mae: 0.2109\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1326 - val_loss: 0.0863 - val_mae: 0.2023\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1316 - val_loss: 0.0896 - val_mae: 0.2073\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1335 - val_loss: 0.0887 - val_mae: 0.2031\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1287 - val_loss: 0.0916 - val_mae: 0.2104\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1302 - val_loss: 0.0902 - val_mae: 0.2047\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1337 - val_loss: 0.0886 - val_mae: 0.2050\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1310 - val_loss: 0.0934 - val_mae: 0.2074\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1338 - val_loss: 0.0905 - val_mae: 0.2100\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1349 - val_loss: 0.0950 - val_mae: 0.2157\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.1293 - val_loss: 0.0965 - val_mae: 0.2092\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1273 - val_loss: 0.0918 - val_mae: 0.2130\n",
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1340 - val_loss: 0.0897 - val_mae: 0.2060\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1342 - val_loss: 0.0915 - val_mae: 0.2047\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1295 - val_loss: 0.0899 - val_mae: 0.2125\n",
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1321 - val_loss: 0.0876 - val_mae: 0.2051\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1308 - val_loss: 0.0877 - val_mae: 0.2068\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1342 - val_loss: 0.0870 - val_mae: 0.2090\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1276 - val_loss: 0.0904 - val_mae: 0.2010\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1325 - val_loss: 0.0890 - val_mae: 0.2057\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1307 - val_loss: 0.0914 - val_mae: 0.2077\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1325 - val_loss: 0.0908 - val_mae: 0.2063\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1319 - val_loss: 0.0908 - val_mae: 0.2033\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1306 - val_loss: 0.0898 - val_mae: 0.2048\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1311 - val_loss: 0.0912 - val_mae: 0.2080\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1312 - val_loss: 0.0898 - val_mae: 0.2068\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0269 - mae: 0.1309 - val_loss: 0.0959 - val_mae: 0.2138\n",
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1339 - val_loss: 0.0918 - val_mae: 0.2093\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1317 - val_loss: 0.0927 - val_mae: 0.2123\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1315 - val_loss: 0.0906 - val_mae: 0.2115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1286 - val_loss: 0.0979 - val_mae: 0.2155\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - mae: 0.1332 - val_loss: 0.0947 - val_mae: 0.2115\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1274 - val_loss: 0.0969 - val_mae: 0.2171\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1333 - val_loss: 0.0903 - val_mae: 0.2120\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1284 - val_loss: 0.0962 - val_mae: 0.2078\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1307 - val_loss: 0.0964 - val_mae: 0.2094\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1304 - val_loss: 0.0972 - val_mae: 0.2145\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1317 - val_loss: 0.0904 - val_mae: 0.2127\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1309 - val_loss: 0.0922 - val_mae: 0.2067\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1316 - val_loss: 0.0900 - val_mae: 0.2059\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1288 - val_loss: 0.0898 - val_mae: 0.2104\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1342 - val_loss: 0.0914 - val_mae: 0.2029\n",
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1304 - val_loss: 0.0916 - val_mae: 0.2072\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1279 - val_loss: 0.0896 - val_mae: 0.2065\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1342 - val_loss: 0.0920 - val_mae: 0.2015\n",
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1305 - val_loss: 0.0886 - val_mae: 0.2117\n",
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1306 - val_loss: 0.0920 - val_mae: 0.2044\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0276 - mae: 0.1323 - val_loss: 0.0899 - val_mae: 0.2069\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1298 - val_loss: 0.0899 - val_mae: 0.2125\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1304 - val_loss: 0.0925 - val_mae: 0.2041\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1362 - val_loss: 0.0923 - val_mae: 0.2039\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1327 - val_loss: 0.0910 - val_mae: 0.2033\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0274 - mae: 0.1298 - val_loss: 0.0918 - val_mae: 0.2072\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1319 - val_loss: 0.0898 - val_mae: 0.2052\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1338 - val_loss: 0.0892 - val_mae: 0.2033\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1285 - val_loss: 0.0887 - val_mae: 0.2099\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1337 - val_loss: 0.0951 - val_mae: 0.2137\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1292 - val_loss: 0.0903 - val_mae: 0.2048\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1331 - val_loss: 0.0912 - val_mae: 0.2060\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1291 - val_loss: 0.0887 - val_mae: 0.2124\n",
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1343 - val_loss: 0.0905 - val_mae: 0.2014\n",
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1321 - val_loss: 0.0912 - val_mae: 0.2039\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1292 - val_loss: 0.0906 - val_mae: 0.2157\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1348 - val_loss: 0.0889 - val_mae: 0.2060\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1297 - val_loss: 0.0891 - val_mae: 0.2039\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1277 - val_loss: 0.0880 - val_mae: 0.2090\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1303 - val_loss: 0.0920 - val_mae: 0.2039\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1321 - val_loss: 0.0950 - val_mae: 0.2141\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1309 - val_loss: 0.0908 - val_mae: 0.2125\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1296 - val_loss: 0.0950 - val_mae: 0.2072\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1315 - val_loss: 0.0938 - val_mae: 0.2142\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1327 - val_loss: 0.0903 - val_mae: 0.2056\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0254 - mae: 0.1277 - val_loss: 0.0945 - val_mae: 0.2126\n",
      "Epoch 555/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1289 - val_loss: 0.0924 - val_mae: 0.2019\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1305 - val_loss: 0.0914 - val_mae: 0.2055\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1287 - val_loss: 0.0941 - val_mae: 0.2161\n",
      "Epoch 558/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1317 - val_loss: 0.0924 - val_mae: 0.2085\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1311 - val_loss: 0.0918 - val_mae: 0.2018\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0264 - mae: 0.1318 - val_loss: 0.0916 - val_mae: 0.2066\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1341 - val_loss: 0.0989 - val_mae: 0.2181\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1348 - val_loss: 0.0913 - val_mae: 0.2071\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1292 - val_loss: 0.0917 - val_mae: 0.2070\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1289 - val_loss: 0.0944 - val_mae: 0.2038\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0270 - mae: 0.1302 - val_loss: 0.0915 - val_mae: 0.2035\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1327 - val_loss: 0.0998 - val_mae: 0.2188\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1301 - val_loss: 0.0915 - val_mae: 0.2061\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1314 - val_loss: 0.0934 - val_mae: 0.2094\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1285 - val_loss: 0.0913 - val_mae: 0.2099\n",
      "Epoch 570/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1315 - val_loss: 0.0895 - val_mae: 0.2093\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1349 - val_loss: 0.0936 - val_mae: 0.2056\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1321 - val_loss: 0.0895 - val_mae: 0.2122\n",
      "Epoch 573/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1328 - val_loss: 0.0915 - val_mae: 0.2026\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1312 - val_loss: 0.0912 - val_mae: 0.2061\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0261 - mae: 0.1269 - val_loss: 0.0934 - val_mae: 0.2106\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1274 - val_loss: 0.0898 - val_mae: 0.2081\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1335 - val_loss: 0.0912 - val_mae: 0.2031\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.1274 - val_loss: 0.0921 - val_mae: 0.2084\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1312 - val_loss: 0.0907 - val_mae: 0.2035\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1287 - val_loss: 0.0891 - val_mae: 0.2072\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1346 - val_loss: 0.0900 - val_mae: 0.2057\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1315 - val_loss: 0.0926 - val_mae: 0.2141\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1311 - val_loss: 0.0963 - val_mae: 0.2208\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1337 - val_loss: 0.0919 - val_mae: 0.2050\n",
      "Epoch 585/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1346 - val_loss: 0.0909 - val_mae: 0.2028\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0269 - mae: 0.1325 - val_loss: 0.0945 - val_mae: 0.2086\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1311 - val_loss: 0.0947 - val_mae: 0.2097\n",
      "Epoch 588/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1332 - val_loss: 0.0928 - val_mae: 0.2074\n",
      "Epoch 589/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1317 - val_loss: 0.0932 - val_mae: 0.2044\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1335 - val_loss: 0.0932 - val_mae: 0.2092\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1299 - val_loss: 0.0908 - val_mae: 0.2056\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1324 - val_loss: 0.0917 - val_mae: 0.2046\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1319 - val_loss: 0.0963 - val_mae: 0.2141\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1347 - val_loss: 0.0974 - val_mae: 0.2213\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1310 - val_loss: 0.0915 - val_mae: 0.2069\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0263 - mae: 0.1295 - val_loss: 0.0893 - val_mae: 0.2053\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1300 - val_loss: 0.0921 - val_mae: 0.2079\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1309 - val_loss: 0.0944 - val_mae: 0.2073\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1321 - val_loss: 0.0931 - val_mae: 0.2162\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1317 - val_loss: 0.1010 - val_mae: 0.2199\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "14\n",
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 11ms/step - loss: 1.6872 - mae: 0.9376 - val_loss: 1.4404 - val_mae: 0.8946\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8138 - mae: 0.6350 - val_loss: 0.7404 - val_mae: 0.6368\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4948 - mae: 0.5358 - val_loss: 0.4636 - val_mae: 0.4984\n",
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3713 - mae: 0.4806 - val_loss: 0.3254 - val_mae: 0.4352\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3279 - mae: 0.4511 - val_loss: 0.2893 - val_mae: 0.4180\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2927 - mae: 0.4238 - val_loss: 0.2767 - val_mae: 0.4046\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2622 - mae: 0.4077 - val_loss: 0.2601 - val_mae: 0.3793\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2320 - mae: 0.3776 - val_loss: 0.2319 - val_mae: 0.3611\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2043 - mae: 0.3536 - val_loss: 0.2441 - val_mae: 0.3669\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1848 - mae: 0.3384 - val_loss: 0.2032 - val_mae: 0.3264\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1587 - mae: 0.3122 - val_loss: 0.1770 - val_mae: 0.3074\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1422 - mae: 0.2877 - val_loss: 0.1784 - val_mae: 0.3050\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1210 - mae: 0.2701 - val_loss: 0.1675 - val_mae: 0.2974\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1053 - mae: 0.2518 - val_loss: 0.1441 - val_mae: 0.2764\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0923 - mae: 0.2374 - val_loss: 0.1350 - val_mae: 0.2616\n",
      "Epoch 16/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0823 - mae: 0.2216 - val_loss: 0.1464 - val_mae: 0.2775\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - mae: 0.2138 - val_loss: 0.1215 - val_mae: 0.2446\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - mae: 0.2146 - val_loss: 0.1350 - val_mae: 0.2662\n",
      "Epoch 19/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0698 - mae: 0.2029 - val_loss: 0.1202 - val_mae: 0.2450\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0684 - mae: 0.2048 - val_loss: 0.1306 - val_mae: 0.2598\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0690 - mae: 0.2057 - val_loss: 0.1278 - val_mae: 0.2621\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0685 - mae: 0.2054 - val_loss: 0.1257 - val_mae: 0.2536\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - mae: 0.1984 - val_loss: 0.1165 - val_mae: 0.2411\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0631 - mae: 0.1997 - val_loss: 0.1269 - val_mae: 0.2686\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0633 - mae: 0.1994 - val_loss: 0.1206 - val_mae: 0.2485\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - mae: 0.1995 - val_loss: 0.1121 - val_mae: 0.2348\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0611 - mae: 0.1937 - val_loss: 0.1105 - val_mae: 0.2350\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0602 - mae: 0.1946 - val_loss: 0.1051 - val_mae: 0.2202\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0602 - mae: 0.1949 - val_loss: 0.1132 - val_mae: 0.2458\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0601 - mae: 0.1942 - val_loss: 0.1099 - val_mae: 0.2385\n",
      "Epoch 31/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - mae: 0.1878 - val_loss: 0.1193 - val_mae: 0.2494\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - mae: 0.1901 - val_loss: 0.1086 - val_mae: 0.2340\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - mae: 0.1938 - val_loss: 0.1027 - val_mae: 0.2180\n",
      "Epoch 34/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - mae: 0.1890 - val_loss: 0.1000 - val_mae: 0.2136\n",
      "Epoch 35/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0553 - mae: 0.1867 - val_loss: 0.1017 - val_mae: 0.2190\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - mae: 0.1879 - val_loss: 0.1032 - val_mae: 0.2270\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - mae: 0.1865 - val_loss: 0.1005 - val_mae: 0.2172\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0534 - mae: 0.1804 - val_loss: 0.1069 - val_mae: 0.2408\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0536 - mae: 0.1874 - val_loss: 0.0966 - val_mae: 0.2143\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0542 - mae: 0.1845 - val_loss: 0.0979 - val_mae: 0.2130\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0534 - mae: 0.1827 - val_loss: 0.0975 - val_mae: 0.2231\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0509 - mae: 0.1814 - val_loss: 0.1073 - val_mae: 0.2426\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - mae: 0.1889 - val_loss: 0.0994 - val_mae: 0.2207\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - mae: 0.1808 - val_loss: 0.0951 - val_mae: 0.2127\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0495 - mae: 0.1795 - val_loss: 0.0943 - val_mae: 0.2153\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1830 - val_loss: 0.0934 - val_mae: 0.2051\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - mae: 0.1807 - val_loss: 0.0946 - val_mae: 0.2041\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0471 - mae: 0.1767 - val_loss: 0.0976 - val_mae: 0.2218\n",
      "Epoch 49/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0504 - mae: 0.1740 - val_loss: 0.0975 - val_mae: 0.2226\n",
      "Epoch 50/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - mae: 0.1725 - val_loss: 0.1016 - val_mae: 0.2301\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.1729 - val_loss: 0.0981 - val_mae: 0.2235\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - mae: 0.1753 - val_loss: 0.0962 - val_mae: 0.2210\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.1762 - val_loss: 0.0938 - val_mae: 0.2157\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.1798 - val_loss: 0.0909 - val_mae: 0.2076\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1697 - val_loss: 0.0934 - val_mae: 0.2172\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0476 - mae: 0.1759 - val_loss: 0.0888 - val_mae: 0.2039\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.1657 - val_loss: 0.0951 - val_mae: 0.2209\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - mae: 0.1738 - val_loss: 0.0895 - val_mae: 0.2070\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0456 - mae: 0.1724 - val_loss: 0.0902 - val_mae: 0.2063\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0447 - mae: 0.1700 - val_loss: 0.0903 - val_mae: 0.2115\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0434 - mae: 0.1694 - val_loss: 0.0876 - val_mae: 0.2006\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0442 - mae: 0.1690 - val_loss: 0.0913 - val_mae: 0.2136\n",
      "Epoch 63/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1711 - val_loss: 0.0880 - val_mae: 0.2014\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.1670 - val_loss: 0.0887 - val_mae: 0.2080\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1669 - val_loss: 0.0871 - val_mae: 0.2010\n",
      "Epoch 66/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.1664 - val_loss: 0.0904 - val_mae: 0.2042\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1636 - val_loss: 0.0898 - val_mae: 0.2085\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.1617 - val_loss: 0.0903 - val_mae: 0.2138\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0413 - mae: 0.1646 - val_loss: 0.0905 - val_mae: 0.2122\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0417 - mae: 0.1673 - val_loss: 0.0894 - val_mae: 0.2031\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.1619 - val_loss: 0.0876 - val_mae: 0.2071\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1582 - val_loss: 0.0869 - val_mae: 0.2070\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - mae: 0.1632 - val_loss: 0.0878 - val_mae: 0.2064\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1659 - val_loss: 0.0897 - val_mae: 0.2110\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1634 - val_loss: 0.0894 - val_mae: 0.2103\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0403 - mae: 0.1612 - val_loss: 0.0880 - val_mae: 0.2078\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0380 - mae: 0.1560 - val_loss: 0.0914 - val_mae: 0.2154\n",
      "Epoch 78/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1585 - val_loss: 0.0896 - val_mae: 0.2069\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.1597 - val_loss: 0.0865 - val_mae: 0.2065\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0402 - mae: 0.1617 - val_loss: 0.0856 - val_mae: 0.2025\n",
      "Epoch 81/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.1594 - val_loss: 0.0867 - val_mae: 0.2001\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0400 - mae: 0.1612 - val_loss: 0.0852 - val_mae: 0.1999\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.1605 - val_loss: 0.0859 - val_mae: 0.2035\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1586 - val_loss: 0.0855 - val_mae: 0.1988\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - mae: 0.1590 - val_loss: 0.0846 - val_mae: 0.1996\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0374 - mae: 0.1545 - val_loss: 0.0871 - val_mae: 0.2016\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1567 - val_loss: 0.0888 - val_mae: 0.2087\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.1527 - val_loss: 0.0902 - val_mae: 0.2107\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0389 - mae: 0.1566 - val_loss: 0.0853 - val_mae: 0.2011\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1568 - val_loss: 0.0852 - val_mae: 0.2010\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1549 - val_loss: 0.0825 - val_mae: 0.1969\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1552 - val_loss: 0.0868 - val_mae: 0.2082\n",
      "Epoch 93/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1538 - val_loss: 0.0867 - val_mae: 0.2092\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1595 - val_loss: 0.0849 - val_mae: 0.1977\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0368 - mae: 0.1528 - val_loss: 0.0861 - val_mae: 0.2011\n",
      "Epoch 96/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1508 - val_loss: 0.0862 - val_mae: 0.2035\n",
      "Epoch 97/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1524 - val_loss: 0.0869 - val_mae: 0.2061\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0367 - mae: 0.1538 - val_loss: 0.0833 - val_mae: 0.1985\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0368 - mae: 0.1556 - val_loss: 0.0843 - val_mae: 0.1998\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1520 - val_loss: 0.0884 - val_mae: 0.2115\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1518 - val_loss: 0.0849 - val_mae: 0.2025\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - mae: 0.1567 - val_loss: 0.0862 - val_mae: 0.2079\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0353 - mae: 0.1520 - val_loss: 0.0827 - val_mae: 0.1986\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0370 - mae: 0.1527 - val_loss: 0.0861 - val_mae: 0.2037\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1534 - val_loss: 0.0860 - val_mae: 0.2019\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1515 - val_loss: 0.0850 - val_mae: 0.2020\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1522 - val_loss: 0.0829 - val_mae: 0.1990\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - mae: 0.1528 - val_loss: 0.0832 - val_mae: 0.1988\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0348 - mae: 0.1508 - val_loss: 0.0873 - val_mae: 0.2078\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1450 - val_loss: 0.0818 - val_mae: 0.2013\n",
      "Epoch 111/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1548 - val_loss: 0.0872 - val_mae: 0.2120\n",
      "Epoch 112/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - mae: 0.1491 - val_loss: 0.0861 - val_mae: 0.2097\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0354 - mae: 0.1510 - val_loss: 0.0841 - val_mae: 0.2075\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1554 - val_loss: 0.0815 - val_mae: 0.1969\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0344 - mae: 0.1472 - val_loss: 0.0951 - val_mae: 0.2265\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1483 - val_loss: 0.0842 - val_mae: 0.2026\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1508 - val_loss: 0.0853 - val_mae: 0.2067\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1529 - val_loss: 0.0875 - val_mae: 0.2082\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1481 - val_loss: 0.0844 - val_mae: 0.2038\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0348 - mae: 0.1520 - val_loss: 0.0807 - val_mae: 0.1978\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0343 - mae: 0.1497 - val_loss: 0.0832 - val_mae: 0.2013\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1495 - val_loss: 0.0826 - val_mae: 0.2025\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.1469 - val_loss: 0.0808 - val_mae: 0.1996\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1485 - val_loss: 0.0812 - val_mae: 0.1992\n",
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1444 - val_loss: 0.0877 - val_mae: 0.2106\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0338 - mae: 0.1473 - val_loss: 0.0798 - val_mae: 0.1990\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.1459 - val_loss: 0.0873 - val_mae: 0.2092\n",
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0348 - mae: 0.1475 - val_loss: 0.0847 - val_mae: 0.2052\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0343 - mae: 0.1506 - val_loss: 0.0829 - val_mae: 0.2020\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1480 - val_loss: 0.0810 - val_mae: 0.2000\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1461 - val_loss: 0.0843 - val_mae: 0.2063\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.1486 - val_loss: 0.0831 - val_mae: 0.2012\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0331 - mae: 0.1461 - val_loss: 0.0838 - val_mae: 0.2085\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1515 - val_loss: 0.0821 - val_mae: 0.2019\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1452 - val_loss: 0.0826 - val_mae: 0.2054\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1494 - val_loss: 0.0806 - val_mae: 0.2030\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1461 - val_loss: 0.0818 - val_mae: 0.2029\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1442 - val_loss: 0.0841 - val_mae: 0.2051\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1420 - val_loss: 0.0852 - val_mae: 0.2072\n",
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0344 - mae: 0.1454 - val_loss: 0.0836 - val_mae: 0.2061\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1458 - val_loss: 0.0799 - val_mae: 0.2013\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1435 - val_loss: 0.0815 - val_mae: 0.2052\n",
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1455 - val_loss: 0.0804 - val_mae: 0.2009\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.1432 - val_loss: 0.0797 - val_mae: 0.2000\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0331 - mae: 0.1466 - val_loss: 0.0800 - val_mae: 0.1986\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - mae: 0.1482 - val_loss: 0.0823 - val_mae: 0.2048\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1466 - val_loss: 0.0817 - val_mae: 0.2038\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1461 - val_loss: 0.0795 - val_mae: 0.2015\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1436 - val_loss: 0.0871 - val_mae: 0.2186\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1489 - val_loss: 0.0796 - val_mae: 0.2013\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1439 - val_loss: 0.0793 - val_mae: 0.2035\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.1487 - val_loss: 0.0801 - val_mae: 0.2019\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1456 - val_loss: 0.0789 - val_mae: 0.2020\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1453 - val_loss: 0.0843 - val_mae: 0.2070\n",
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1419 - val_loss: 0.0799 - val_mae: 0.2038\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1406 - val_loss: 0.0891 - val_mae: 0.2137\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1397 - val_loss: 0.0822 - val_mae: 0.2068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1460 - val_loss: 0.0832 - val_mae: 0.2053\n",
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - mae: 0.1418 - val_loss: 0.0781 - val_mae: 0.2029\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0316 - mae: 0.1452 - val_loss: 0.0803 - val_mae: 0.2080\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1450 - val_loss: 0.0886 - val_mae: 0.2181\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1457 - val_loss: 0.0808 - val_mae: 0.2084\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1469 - val_loss: 0.0783 - val_mae: 0.2012\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.1475 - val_loss: 0.0814 - val_mae: 0.2040\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.1431 - val_loss: 0.0822 - val_mae: 0.2057\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1465 - val_loss: 0.0800 - val_mae: 0.2063\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1428 - val_loss: 0.0805 - val_mae: 0.2033\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1432 - val_loss: 0.0818 - val_mae: 0.2063\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1426 - val_loss: 0.0839 - val_mae: 0.2080\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - mae: 0.1458 - val_loss: 0.0837 - val_mae: 0.2103\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1436 - val_loss: 0.0808 - val_mae: 0.2081\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1397 - val_loss: 0.0815 - val_mae: 0.2136\n",
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1421 - val_loss: 0.0827 - val_mae: 0.2069\n",
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1353 - val_loss: 0.0792 - val_mae: 0.2088\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1450 - val_loss: 0.0823 - val_mae: 0.2149\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1425 - val_loss: 0.0778 - val_mae: 0.2060\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1401 - val_loss: 0.0819 - val_mae: 0.2052\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1423 - val_loss: 0.0823 - val_mae: 0.2100\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - mae: 0.1431 - val_loss: 0.0793 - val_mae: 0.2058\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0305 - mae: 0.1407 - val_loss: 0.0799 - val_mae: 0.2066\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1413 - val_loss: 0.0797 - val_mae: 0.2052\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1404 - val_loss: 0.0853 - val_mae: 0.2145\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1407 - val_loss: 0.0831 - val_mae: 0.2096\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1432 - val_loss: 0.0817 - val_mae: 0.2077\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1398 - val_loss: 0.0809 - val_mae: 0.2102\n",
      "Epoch 186/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1411 - val_loss: 0.0882 - val_mae: 0.2136\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1458 - val_loss: 0.0826 - val_mae: 0.2086\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0300 - mae: 0.1398 - val_loss: 0.0816 - val_mae: 0.2085\n",
      "Epoch 189/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1375 - val_loss: 0.0777 - val_mae: 0.2045\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1427 - val_loss: 0.0817 - val_mae: 0.2116\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1400 - val_loss: 0.0830 - val_mae: 0.2085\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1435 - val_loss: 0.0789 - val_mae: 0.2068\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1430 - val_loss: 0.0793 - val_mae: 0.2074\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1412 - val_loss: 0.0792 - val_mae: 0.2069\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1372 - val_loss: 0.0795 - val_mae: 0.2065\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - mae: 0.1406 - val_loss: 0.0806 - val_mae: 0.2087\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0297 - mae: 0.1399 - val_loss: 0.0815 - val_mae: 0.2111\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1436 - val_loss: 0.0813 - val_mae: 0.2071\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1377 - val_loss: 0.0789 - val_mae: 0.2045\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1411 - val_loss: 0.0804 - val_mae: 0.2109\n",
      "Epoch 201/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1426 - val_loss: 0.0803 - val_mae: 0.2080\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1401 - val_loss: 0.0817 - val_mae: 0.2104\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1398 - val_loss: 0.0813 - val_mae: 0.2080\n",
      "Epoch 204/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1404 - val_loss: 0.0781 - val_mae: 0.2075\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1418 - val_loss: 0.0783 - val_mae: 0.2073\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1443 - val_loss: 0.0812 - val_mae: 0.2111\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0301 - mae: 0.1414 - val_loss: 0.0801 - val_mae: 0.2087\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1435 - val_loss: 0.0789 - val_mae: 0.2089\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1394 - val_loss: 0.0793 - val_mae: 0.2086\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1381 - val_loss: 0.0832 - val_mae: 0.2110\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1399 - val_loss: 0.0815 - val_mae: 0.2121\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1411 - val_loss: 0.0804 - val_mae: 0.2110\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1362 - val_loss: 0.0835 - val_mae: 0.2168\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1421 - val_loss: 0.0802 - val_mae: 0.2103\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1402 - val_loss: 0.0808 - val_mae: 0.2136\n",
      "Epoch 216/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0290 - mae: 0.1382 - val_loss: 0.0775 - val_mae: 0.2103\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0298 - mae: 0.1429 - val_loss: 0.0772 - val_mae: 0.2072\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1404 - val_loss: 0.0815 - val_mae: 0.2130\n",
      "Epoch 219/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1380 - val_loss: 0.0785 - val_mae: 0.2127\n",
      "Epoch 220/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1419 - val_loss: 0.0775 - val_mae: 0.2098\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1367 - val_loss: 0.0775 - val_mae: 0.2128\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1442 - val_loss: 0.0798 - val_mae: 0.2072\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1393 - val_loss: 0.0806 - val_mae: 0.2118\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1408 - val_loss: 0.0844 - val_mae: 0.2188\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1416 - val_loss: 0.0822 - val_mae: 0.2118\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1374 - val_loss: 0.0803 - val_mae: 0.2113\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1427 - val_loss: 0.0794 - val_mae: 0.2135\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0299 - mae: 0.1413 - val_loss: 0.0814 - val_mae: 0.2157\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0298 - mae: 0.1409 - val_loss: 0.0811 - val_mae: 0.2127\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0272 - mae: 0.1373 - val_loss: 0.0883 - val_mae: 0.2176\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1405 - val_loss: 0.0804 - val_mae: 0.2132\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1417 - val_loss: 0.0806 - val_mae: 0.2119\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.1376 - val_loss: 0.0817 - val_mae: 0.2155\n",
      "Epoch 234/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1399 - val_loss: 0.0807 - val_mae: 0.2130\n",
      "Epoch 235/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1421 - val_loss: 0.0783 - val_mae: 0.2085\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1406 - val_loss: 0.0810 - val_mae: 0.2139\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1384 - val_loss: 0.0799 - val_mae: 0.2089\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1346 - val_loss: 0.0856 - val_mae: 0.2209\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1377 - val_loss: 0.0793 - val_mae: 0.2110\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.1370 - val_loss: 0.0799 - val_mae: 0.2113\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0290 - mae: 0.1383 - val_loss: 0.0831 - val_mae: 0.2157\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1395 - val_loss: 0.0813 - val_mae: 0.2127\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1395 - val_loss: 0.0799 - val_mae: 0.2114\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1367 - val_loss: 0.0801 - val_mae: 0.2090\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1393 - val_loss: 0.0798 - val_mae: 0.2120\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1385 - val_loss: 0.0789 - val_mae: 0.2100\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1411 - val_loss: 0.0806 - val_mae: 0.2129\n",
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1361 - val_loss: 0.0804 - val_mae: 0.2103\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1395 - val_loss: 0.0841 - val_mae: 0.2169\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1393 - val_loss: 0.0797 - val_mae: 0.2097\n",
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1407 - val_loss: 0.0822 - val_mae: 0.2104\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1370 - val_loss: 0.0804 - val_mae: 0.2106\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1374 - val_loss: 0.0805 - val_mae: 0.2115\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1355 - val_loss: 0.0800 - val_mae: 0.2102\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1410 - val_loss: 0.0788 - val_mae: 0.2092\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1357 - val_loss: 0.0815 - val_mae: 0.2124\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1394 - val_loss: 0.0809 - val_mae: 0.2108\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1411 - val_loss: 0.0808 - val_mae: 0.2149\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1357 - val_loss: 0.0803 - val_mae: 0.2088\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1414 - val_loss: 0.0823 - val_mae: 0.2143\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1378 - val_loss: 0.0820 - val_mae: 0.2161\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1359 - val_loss: 0.0829 - val_mae: 0.2150\n",
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1398 - val_loss: 0.0807 - val_mae: 0.2119\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1367 - val_loss: 0.0820 - val_mae: 0.2121\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1364 - val_loss: 0.0788 - val_mae: 0.2085\n",
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1377 - val_loss: 0.0773 - val_mae: 0.2121\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.1363 - val_loss: 0.0792 - val_mae: 0.2115\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1371 - val_loss: 0.0785 - val_mae: 0.2149\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1367 - val_loss: 0.0823 - val_mae: 0.2170\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1422 - val_loss: 0.0797 - val_mae: 0.2118\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1419 - val_loss: 0.0787 - val_mae: 0.2114\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1365 - val_loss: 0.0816 - val_mae: 0.2140\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1412 - val_loss: 0.0799 - val_mae: 0.2143\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1381 - val_loss: 0.0822 - val_mae: 0.2115\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1388 - val_loss: 0.0806 - val_mae: 0.2162\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1356 - val_loss: 0.0859 - val_mae: 0.2246\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1401 - val_loss: 0.0792 - val_mae: 0.2162\n",
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1363 - val_loss: 0.0789 - val_mae: 0.2125\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1373 - val_loss: 0.0810 - val_mae: 0.2173\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1414 - val_loss: 0.0791 - val_mae: 0.2098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1401 - val_loss: 0.0815 - val_mae: 0.2126\n",
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1370 - val_loss: 0.0811 - val_mae: 0.2127\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1401 - val_loss: 0.0830 - val_mae: 0.2171\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0275 - mae: 0.1371 - val_loss: 0.0785 - val_mae: 0.2160\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1378 - val_loss: 0.0767 - val_mae: 0.2090\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1387 - val_loss: 0.0793 - val_mae: 0.2124\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1356 - val_loss: 0.0805 - val_mae: 0.2109\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1367 - val_loss: 0.0821 - val_mae: 0.2117\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1393 - val_loss: 0.0792 - val_mae: 0.2118\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1346 - val_loss: 0.0799 - val_mae: 0.2105\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1390 - val_loss: 0.0793 - val_mae: 0.2107\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1379 - val_loss: 0.0775 - val_mae: 0.2122\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1340 - val_loss: 0.0813 - val_mae: 0.2198\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - mae: 0.1352 - val_loss: 0.0810 - val_mae: 0.2115\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.1406 - val_loss: 0.0816 - val_mae: 0.2123\n",
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0274 - mae: 0.1371 - val_loss: 0.0820 - val_mae: 0.2131\n",
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1347 - val_loss: 0.0847 - val_mae: 0.2171\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1337 - val_loss: 0.0821 - val_mae: 0.2146\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1320 - val_loss: 0.0837 - val_mae: 0.2191\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1393 - val_loss: 0.0780 - val_mae: 0.2091\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1340 - val_loss: 0.0792 - val_mae: 0.2187\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1417 - val_loss: 0.0779 - val_mae: 0.2140\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1344 - val_loss: 0.0833 - val_mae: 0.2161\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1373 - val_loss: 0.0803 - val_mae: 0.2137\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1380 - val_loss: 0.0805 - val_mae: 0.2158\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1383 - val_loss: 0.0815 - val_mae: 0.2196\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1370 - val_loss: 0.0814 - val_mae: 0.2119\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1367 - val_loss: 0.0813 - val_mae: 0.2116\n",
      "Epoch 309/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1378 - val_loss: 0.0805 - val_mae: 0.2208\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1363 - val_loss: 0.0804 - val_mae: 0.2110\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.1389 - val_loss: 0.0782 - val_mae: 0.2137\n",
      "Epoch 312/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1320 - val_loss: 0.0827 - val_mae: 0.2239\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1428 - val_loss: 0.0788 - val_mae: 0.2108\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1343 - val_loss: 0.0861 - val_mae: 0.2181\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1396 - val_loss: 0.0784 - val_mae: 0.2160\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1339 - val_loss: 0.0807 - val_mae: 0.2113\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1407 - val_loss: 0.0817 - val_mae: 0.2124\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1360 - val_loss: 0.0812 - val_mae: 0.2121\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1384 - val_loss: 0.0803 - val_mae: 0.2120\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1354 - val_loss: 0.0808 - val_mae: 0.2106\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - mae: 0.1345 - val_loss: 0.0828 - val_mae: 0.2148\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1365 - val_loss: 0.0839 - val_mae: 0.2163\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1307 - val_loss: 0.0802 - val_mae: 0.2204\n",
      "Epoch 324/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1383 - val_loss: 0.0796 - val_mae: 0.2120\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.1374 - val_loss: 0.0803 - val_mae: 0.2123\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0274 - mae: 0.1350 - val_loss: 0.0831 - val_mae: 0.2152\n",
      "Epoch 327/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0282 - mae: 0.1364 - val_loss: 0.0818 - val_mae: 0.2144\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1394 - val_loss: 0.0807 - val_mae: 0.2121\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.1348 - val_loss: 0.0820 - val_mae: 0.2129\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - mae: 0.1385 - val_loss: 0.0798 - val_mae: 0.2144\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0286 - mae: 0.1378 - val_loss: 0.0800 - val_mae: 0.2147\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0282 - mae: 0.1371 - val_loss: 0.0805 - val_mae: 0.2135\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.1398 - val_loss: 0.0808 - val_mae: 0.2111\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0274 - mae: 0.1372 - val_loss: 0.0796 - val_mae: 0.2163\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1355 - val_loss: 0.0789 - val_mae: 0.2139\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1332 - val_loss: 0.0812 - val_mae: 0.2145\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1372 - val_loss: 0.0799 - val_mae: 0.2125\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1395 - val_loss: 0.0791 - val_mae: 0.2124\n",
      "Epoch 339/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1344 - val_loss: 0.0794 - val_mae: 0.2144\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1373 - val_loss: 0.0795 - val_mae: 0.2168\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1351 - val_loss: 0.0795 - val_mae: 0.2151\n",
      "Epoch 342/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1361 - val_loss: 0.0856 - val_mae: 0.2181\n",
      "Epoch 343/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1362 - val_loss: 0.0801 - val_mae: 0.2199\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1361 - val_loss: 0.0821 - val_mae: 0.2126\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1345 - val_loss: 0.0813 - val_mae: 0.2198\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1357 - val_loss: 0.0802 - val_mae: 0.2157\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1349 - val_loss: 0.0800 - val_mae: 0.2125\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1386 - val_loss: 0.0791 - val_mae: 0.2101\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0268 - mae: 0.1358 - val_loss: 0.0825 - val_mae: 0.2136\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1311 - val_loss: 0.0799 - val_mae: 0.2166\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1374 - val_loss: 0.0807 - val_mae: 0.2129\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1311 - val_loss: 0.0859 - val_mae: 0.2222\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1364 - val_loss: 0.0822 - val_mae: 0.2158\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1330 - val_loss: 0.0801 - val_mae: 0.2151\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1379 - val_loss: 0.0792 - val_mae: 0.2117\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1326 - val_loss: 0.0828 - val_mae: 0.2148\n",
      "Epoch 357/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1334 - val_loss: 0.0799 - val_mae: 0.2188\n",
      "Epoch 358/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1376 - val_loss: 0.0782 - val_mae: 0.2105\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1369 - val_loss: 0.0789 - val_mae: 0.2110\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1365 - val_loss: 0.0806 - val_mae: 0.2108\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1338 - val_loss: 0.0808 - val_mae: 0.2124\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1344 - val_loss: 0.0813 - val_mae: 0.2198\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1362 - val_loss: 0.0779 - val_mae: 0.2105\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1355 - val_loss: 0.0816 - val_mae: 0.2160\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1378 - val_loss: 0.0788 - val_mae: 0.2119\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1373 - val_loss: 0.0787 - val_mae: 0.2177\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1345 - val_loss: 0.0775 - val_mae: 0.2129\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1365 - val_loss: 0.0794 - val_mae: 0.2101\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1354 - val_loss: 0.0822 - val_mae: 0.2159\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1334 - val_loss: 0.0784 - val_mae: 0.2144\n",
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1380 - val_loss: 0.0833 - val_mae: 0.2161\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1318 - val_loss: 0.0834 - val_mae: 0.2163\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1396 - val_loss: 0.0805 - val_mae: 0.2116\n",
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1377 - val_loss: 0.0796 - val_mae: 0.2102\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1363 - val_loss: 0.0795 - val_mae: 0.2143\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1348 - val_loss: 0.0786 - val_mae: 0.2131\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1365 - val_loss: 0.0786 - val_mae: 0.2100\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1344 - val_loss: 0.0785 - val_mae: 0.2117\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1332 - val_loss: 0.0774 - val_mae: 0.2123\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0252 - mae: 0.1289 - val_loss: 0.0842 - val_mae: 0.2217\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1323 - val_loss: 0.0838 - val_mae: 0.2223\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1358 - val_loss: 0.0821 - val_mae: 0.2165\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1352 - val_loss: 0.0780 - val_mae: 0.2098\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1344 - val_loss: 0.0795 - val_mae: 0.2113\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1368 - val_loss: 0.0783 - val_mae: 0.2106\n",
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1312 - val_loss: 0.0787 - val_mae: 0.2128\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1316 - val_loss: 0.0806 - val_mae: 0.2127\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1361 - val_loss: 0.0807 - val_mae: 0.2122\n",
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1301 - val_loss: 0.0788 - val_mae: 0.2167\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1328 - val_loss: 0.0813 - val_mae: 0.2164\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1320 - val_loss: 0.0775 - val_mae: 0.2189\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1366 - val_loss: 0.0776 - val_mae: 0.2102\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1362 - val_loss: 0.0785 - val_mae: 0.2159\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1353 - val_loss: 0.0812 - val_mae: 0.2132\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1327 - val_loss: 0.0775 - val_mae: 0.2117\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0266 - mae: 0.1355 - val_loss: 0.0789 - val_mae: 0.2116\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1331 - val_loss: 0.0802 - val_mae: 0.2121\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1326 - val_loss: 0.0769 - val_mae: 0.2073\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1359 - val_loss: 0.0766 - val_mae: 0.2083\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1317 - val_loss: 0.0779 - val_mae: 0.2088\n",
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1347 - val_loss: 0.0836 - val_mae: 0.2198\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1360 - val_loss: 0.0799 - val_mae: 0.2110\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1339 - val_loss: 0.0803 - val_mae: 0.2137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1343 - val_loss: 0.0831 - val_mae: 0.2154\n",
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1338 - val_loss: 0.0794 - val_mae: 0.2103\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1347 - val_loss: 0.0796 - val_mae: 0.2179\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1342 - val_loss: 0.0805 - val_mae: 0.2153\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1374 - val_loss: 0.0799 - val_mae: 0.2109\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1342 - val_loss: 0.0812 - val_mae: 0.2115\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1355 - val_loss: 0.0801 - val_mae: 0.2125\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1311 - val_loss: 0.0860 - val_mae: 0.2217\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1370 - val_loss: 0.0792 - val_mae: 0.2105\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1336 - val_loss: 0.0779 - val_mae: 0.2104\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1310 - val_loss: 0.0804 - val_mae: 0.2171\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1285 - val_loss: 0.0836 - val_mae: 0.2226\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1391 - val_loss: 0.0784 - val_mae: 0.2145\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1362 - val_loss: 0.0820 - val_mae: 0.2147\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1340 - val_loss: 0.0788 - val_mae: 0.2148\n",
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0270 - mae: 0.1340 - val_loss: 0.0807 - val_mae: 0.2136\n",
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1377 - val_loss: 0.0795 - val_mae: 0.2150\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1324 - val_loss: 0.0816 - val_mae: 0.2151\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1326 - val_loss: 0.0777 - val_mae: 0.2110\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0275 - mae: 0.1345 - val_loss: 0.0799 - val_mae: 0.2116\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1313 - val_loss: 0.0784 - val_mae: 0.2126\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1358 - val_loss: 0.0792 - val_mae: 0.2160\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1373 - val_loss: 0.0799 - val_mae: 0.2108\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1341 - val_loss: 0.0781 - val_mae: 0.2096\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1326 - val_loss: 0.0811 - val_mae: 0.2128\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1344 - val_loss: 0.0766 - val_mae: 0.2092\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1335 - val_loss: 0.0803 - val_mae: 0.2122\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1320 - val_loss: 0.0797 - val_mae: 0.2180\n",
      "Epoch 432/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1343 - val_loss: 0.0790 - val_mae: 0.2151\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0268 - mae: 0.1333 - val_loss: 0.0804 - val_mae: 0.2115\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1377 - val_loss: 0.0825 - val_mae: 0.2139\n",
      "Epoch 435/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1355 - val_loss: 0.0773 - val_mae: 0.2071\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1301 - val_loss: 0.0824 - val_mae: 0.2147\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1338 - val_loss: 0.0787 - val_mae: 0.2111\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1331 - val_loss: 0.0803 - val_mae: 0.2136\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1311 - val_loss: 0.0770 - val_mae: 0.2082\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0262 - mae: 0.1310 - val_loss: 0.0805 - val_mae: 0.2161\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1354 - val_loss: 0.0804 - val_mae: 0.2112\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1319 - val_loss: 0.0791 - val_mae: 0.2082\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1333 - val_loss: 0.0763 - val_mae: 0.2098\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1327 - val_loss: 0.0772 - val_mae: 0.2098\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1319 - val_loss: 0.0789 - val_mae: 0.2125\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1315 - val_loss: 0.0812 - val_mae: 0.2157\n",
      "Epoch 447/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0267 - mae: 0.1329 - val_loss: 0.0781 - val_mae: 0.2098\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1330 - val_loss: 0.0759 - val_mae: 0.2072\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1320 - val_loss: 0.0833 - val_mae: 0.2148\n",
      "Epoch 450/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1336 - val_loss: 0.0786 - val_mae: 0.2116\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1308 - val_loss: 0.0844 - val_mae: 0.2181\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1327 - val_loss: 0.0791 - val_mae: 0.2133\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0267 - mae: 0.1336 - val_loss: 0.0767 - val_mae: 0.2091\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0274 - mae: 0.1362 - val_loss: 0.0792 - val_mae: 0.2102\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1340 - val_loss: 0.0815 - val_mae: 0.2141\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1324 - val_loss: 0.0802 - val_mae: 0.2106\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1309 - val_loss: 0.0797 - val_mae: 0.2112\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1347 - val_loss: 0.0767 - val_mae: 0.2063\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1311 - val_loss: 0.0769 - val_mae: 0.2113\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0264 - mae: 0.1323 - val_loss: 0.0783 - val_mae: 0.2084\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1349 - val_loss: 0.0820 - val_mae: 0.2143\n",
      "Epoch 462/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1318 - val_loss: 0.0752 - val_mae: 0.2085\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1323 - val_loss: 0.0764 - val_mae: 0.2082\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1331 - val_loss: 0.0774 - val_mae: 0.2080\n",
      "Epoch 465/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1326 - val_loss: 0.0768 - val_mae: 0.2090\n",
      "Epoch 466/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0261 - mae: 0.1309 - val_loss: 0.0771 - val_mae: 0.2173\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1334 - val_loss: 0.0780 - val_mae: 0.2148\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1330 - val_loss: 0.0823 - val_mae: 0.2192\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1357 - val_loss: 0.0780 - val_mae: 0.2085\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1300 - val_loss: 0.0791 - val_mae: 0.2112\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1334 - val_loss: 0.0823 - val_mae: 0.2137\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1320 - val_loss: 0.0766 - val_mae: 0.2090\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0262 - mae: 0.1318 - val_loss: 0.0779 - val_mae: 0.2168\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.1294 - val_loss: 0.0877 - val_mae: 0.2186\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1324 - val_loss: 0.0818 - val_mae: 0.2135\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1347 - val_loss: 0.0799 - val_mae: 0.2163\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.1297 - val_loss: 0.0801 - val_mae: 0.2193\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1349 - val_loss: 0.0782 - val_mae: 0.2112\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1307 - val_loss: 0.0780 - val_mae: 0.2088\n",
      "Epoch 480/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0265 - mae: 0.1309 - val_loss: 0.0791 - val_mae: 0.2076\n",
      "Epoch 481/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0270 - mae: 0.1354 - val_loss: 0.0789 - val_mae: 0.2081\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1310 - val_loss: 0.0784 - val_mae: 0.2154\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1347 - val_loss: 0.0766 - val_mae: 0.2089\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1357 - val_loss: 0.0764 - val_mae: 0.2099\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1332 - val_loss: 0.0805 - val_mae: 0.2156\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1353 - val_loss: 0.0801 - val_mae: 0.2087\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1342 - val_loss: 0.0787 - val_mae: 0.2118\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0266 - mae: 0.1313 - val_loss: 0.0812 - val_mae: 0.2145\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1362 - val_loss: 0.0808 - val_mae: 0.2172\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1301 - val_loss: 0.0873 - val_mae: 0.2219\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1310 - val_loss: 0.0782 - val_mae: 0.2149\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1322 - val_loss: 0.0808 - val_mae: 0.2137\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1347 - val_loss: 0.0790 - val_mae: 0.2105\n",
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0265 - mae: 0.1318 - val_loss: 0.0790 - val_mae: 0.2097\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0266 - mae: 0.1306 - val_loss: 0.0780 - val_mae: 0.2100\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1339 - val_loss: 0.0788 - val_mae: 0.2124\n",
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1345 - val_loss: 0.0825 - val_mae: 0.2155\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1283 - val_loss: 0.0786 - val_mae: 0.2116\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1360 - val_loss: 0.0783 - val_mae: 0.2123\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1355 - val_loss: 0.0796 - val_mae: 0.2097\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1296 - val_loss: 0.0804 - val_mae: 0.2099\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0261 - mae: 0.1325 - val_loss: 0.0795 - val_mae: 0.2105\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1331 - val_loss: 0.0818 - val_mae: 0.2152\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1318 - val_loss: 0.0794 - val_mae: 0.2107\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1320 - val_loss: 0.0825 - val_mae: 0.2184\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1319 - val_loss: 0.0792 - val_mae: 0.2116\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1325 - val_loss: 0.0767 - val_mae: 0.2122\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1332 - val_loss: 0.0782 - val_mae: 0.2139\n",
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1334 - val_loss: 0.0837 - val_mae: 0.2181\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1323 - val_loss: 0.0789 - val_mae: 0.2148\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1305 - val_loss: 0.0825 - val_mae: 0.2155\n",
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.1295 - val_loss: 0.0792 - val_mae: 0.2120\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1354 - val_loss: 0.0787 - val_mae: 0.2104\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1311 - val_loss: 0.0813 - val_mae: 0.2111\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0251 - mae: 0.1273 - val_loss: 0.0765 - val_mae: 0.2087\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1330 - val_loss: 0.0768 - val_mae: 0.2133\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1323 - val_loss: 0.0776 - val_mae: 0.2101\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1333 - val_loss: 0.0782 - val_mae: 0.2103\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1318 - val_loss: 0.0780 - val_mae: 0.2125\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0263 - mae: 0.1320 - val_loss: 0.0782 - val_mae: 0.2098\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1310 - val_loss: 0.0742 - val_mae: 0.2072\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1319 - val_loss: 0.0775 - val_mae: 0.2101\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1303 - val_loss: 0.0807 - val_mae: 0.2182\n",
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1355 - val_loss: 0.0802 - val_mae: 0.2102\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1282 - val_loss: 0.0812 - val_mae: 0.2132\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0252 - mae: 0.1271 - val_loss: 0.0819 - val_mae: 0.2163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1285 - val_loss: 0.0782 - val_mae: 0.2088\n",
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1295 - val_loss: 0.0777 - val_mae: 0.2120\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1357 - val_loss: 0.0795 - val_mae: 0.2102\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1329 - val_loss: 0.0809 - val_mae: 0.2118\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1329 - val_loss: 0.0788 - val_mae: 0.2115\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0265 - mae: 0.1305 - val_loss: 0.0793 - val_mae: 0.2083\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0262 - mae: 0.1299 - val_loss: 0.0779 - val_mae: 0.2099\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1301 - val_loss: 0.0776 - val_mae: 0.2096\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1325 - val_loss: 0.0751 - val_mae: 0.2112\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1329 - val_loss: 0.0761 - val_mae: 0.2111\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1355 - val_loss: 0.0779 - val_mae: 0.2098\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1294 - val_loss: 0.0776 - val_mae: 0.2144\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1337 - val_loss: 0.0785 - val_mae: 0.2118\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1325 - val_loss: 0.0767 - val_mae: 0.2086\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1323 - val_loss: 0.0771 - val_mae: 0.2074\n",
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1283 - val_loss: 0.0804 - val_mae: 0.2103\n",
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1328 - val_loss: 0.0800 - val_mae: 0.2112\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1318 - val_loss: 0.0761 - val_mae: 0.2095\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1315 - val_loss: 0.0763 - val_mae: 0.2082\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1311 - val_loss: 0.0779 - val_mae: 0.2188\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0258 - mae: 0.1313 - val_loss: 0.0793 - val_mae: 0.2128\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1316 - val_loss: 0.0795 - val_mae: 0.2107\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1343 - val_loss: 0.0775 - val_mae: 0.2098\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1296 - val_loss: 0.0775 - val_mae: 0.2182\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1325 - val_loss: 0.0795 - val_mae: 0.2088\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1355 - val_loss: 0.0785 - val_mae: 0.2087\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1324 - val_loss: 0.0789 - val_mae: 0.2103\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0247 - mae: 0.1284 - val_loss: 0.0770 - val_mae: 0.2116\n",
      "Epoch 555/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1331 - val_loss: 0.0823 - val_mae: 0.2238\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1325 - val_loss: 0.0788 - val_mae: 0.2077\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1296 - val_loss: 0.0787 - val_mae: 0.2124\n",
      "Epoch 558/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1331 - val_loss: 0.0786 - val_mae: 0.2071\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1313 - val_loss: 0.0804 - val_mae: 0.2107\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0253 - mae: 0.1290 - val_loss: 0.0777 - val_mae: 0.2147\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1347 - val_loss: 0.0778 - val_mae: 0.2135\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1334 - val_loss: 0.0793 - val_mae: 0.2094\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1332 - val_loss: 0.0785 - val_mae: 0.2115\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1321 - val_loss: 0.0791 - val_mae: 0.2087\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1320 - val_loss: 0.0801 - val_mae: 0.2109\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0255 - mae: 0.1304 - val_loss: 0.0796 - val_mae: 0.2180\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1349 - val_loss: 0.0785 - val_mae: 0.2129\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1314 - val_loss: 0.0772 - val_mae: 0.2088\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1295 - val_loss: 0.0878 - val_mae: 0.2222\n",
      "Epoch 570/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1312 - val_loss: 0.0803 - val_mae: 0.2121\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0267 - mae: 0.1333 - val_loss: 0.0783 - val_mae: 0.2089\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1329 - val_loss: 0.0778 - val_mae: 0.2102\n",
      "Epoch 573/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1285 - val_loss: 0.0776 - val_mae: 0.2098\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1349 - val_loss: 0.0791 - val_mae: 0.2109\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.1268 - val_loss: 0.0826 - val_mae: 0.2127\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1303 - val_loss: 0.0787 - val_mae: 0.2170\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1318 - val_loss: 0.0792 - val_mae: 0.2084\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1352 - val_loss: 0.0787 - val_mae: 0.2176\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1278 - val_loss: 0.0773 - val_mae: 0.2126\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0267 - mae: 0.1303 - val_loss: 0.0755 - val_mae: 0.2111\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0252 - mae: 0.1284 - val_loss: 0.0805 - val_mae: 0.2095\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1302 - val_loss: 0.0821 - val_mae: 0.2178\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1286 - val_loss: 0.0814 - val_mae: 0.2141\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1295 - val_loss: 0.0781 - val_mae: 0.2086\n",
      "Epoch 585/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1319 - val_loss: 0.0766 - val_mae: 0.2081\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1299 - val_loss: 0.0774 - val_mae: 0.2090\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0266 - mae: 0.1343 - val_loss: 0.0821 - val_mae: 0.2135\n",
      "Epoch 588/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1309 - val_loss: 0.0781 - val_mae: 0.2117\n",
      "Epoch 589/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1284 - val_loss: 0.0813 - val_mae: 0.2112\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.1275 - val_loss: 0.0812 - val_mae: 0.2117\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1364 - val_loss: 0.0788 - val_mae: 0.2113\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1346 - val_loss: 0.0779 - val_mae: 0.2077\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0268 - mae: 0.1341 - val_loss: 0.0790 - val_mae: 0.2086\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0254 - mae: 0.1285 - val_loss: 0.0809 - val_mae: 0.2131\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1295 - val_loss: 0.0841 - val_mae: 0.2166\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1305 - val_loss: 0.0843 - val_mae: 0.2196\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1342 - val_loss: 0.0781 - val_mae: 0.2080\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.1309 - val_loss: 0.0798 - val_mae: 0.2119\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1306 - val_loss: 0.0830 - val_mae: 0.2148\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0257 - mae: 0.1281 - val_loss: 0.0822 - val_mae: 0.2120\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "16\n",
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 11ms/step - loss: 0.3803 - mae: 0.5094 - val_loss: 0.3314 - val_mae: 0.4941\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2786 - mae: 0.4442 - val_loss: 0.2413 - val_mae: 0.4150\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2302 - mae: 0.4012 - val_loss: 0.1972 - val_mae: 0.3825\n",
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1984 - mae: 0.3681 - val_loss: 0.1992 - val_mae: 0.3602\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1716 - mae: 0.3487 - val_loss: 0.1758 - val_mae: 0.3329\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1473 - mae: 0.3189 - val_loss: 0.1832 - val_mae: 0.3525\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1261 - mae: 0.2879 - val_loss: 0.1301 - val_mae: 0.2825\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1133 - mae: 0.2674 - val_loss: 0.1405 - val_mae: 0.2989\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - mae: 0.2586 - val_loss: 0.1283 - val_mae: 0.2749\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0871 - mae: 0.2394 - val_loss: 0.1173 - val_mae: 0.2539\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - mae: 0.2203 - val_loss: 0.1388 - val_mae: 0.2864\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - mae: 0.2146 - val_loss: 0.1141 - val_mae: 0.2472\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - mae: 0.2081 - val_loss: 0.1249 - val_mae: 0.2621\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - mae: 0.2084 - val_loss: 0.1179 - val_mae: 0.2508\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - mae: 0.2046 - val_loss: 0.1136 - val_mae: 0.2438\n",
      "Epoch 16/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - mae: 0.2041 - val_loss: 0.1299 - val_mae: 0.2674\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - mae: 0.2063 - val_loss: 0.1119 - val_mae: 0.2409\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0652 - mae: 0.2042 - val_loss: 0.1215 - val_mae: 0.2655\n",
      "Epoch 19/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0621 - mae: 0.1970 - val_loss: 0.1202 - val_mae: 0.2537\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0644 - mae: 0.1975 - val_loss: 0.1142 - val_mae: 0.2452\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0616 - mae: 0.1958 - val_loss: 0.1185 - val_mae: 0.2476\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0628 - mae: 0.1990 - val_loss: 0.1134 - val_mae: 0.2446\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0619 - mae: 0.1957 - val_loss: 0.1154 - val_mae: 0.2506\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0615 - mae: 0.1962 - val_loss: 0.1122 - val_mae: 0.2417\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0599 - mae: 0.1926 - val_loss: 0.1122 - val_mae: 0.2521\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0582 - mae: 0.1924 - val_loss: 0.1239 - val_mae: 0.2538\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0606 - mae: 0.1923 - val_loss: 0.1109 - val_mae: 0.2407\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - mae: 0.1890 - val_loss: 0.1104 - val_mae: 0.2369\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0580 - mae: 0.1918 - val_loss: 0.1063 - val_mae: 0.2328\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - mae: 0.1873 - val_loss: 0.1067 - val_mae: 0.2326\n",
      "Epoch 31/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - mae: 0.1828 - val_loss: 0.1167 - val_mae: 0.2503\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - mae: 0.1829 - val_loss: 0.1092 - val_mae: 0.2464\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0564 - mae: 0.1890 - val_loss: 0.1021 - val_mae: 0.2231\n",
      "Epoch 34/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0527 - mae: 0.1825 - val_loss: 0.1046 - val_mae: 0.2275\n",
      "Epoch 35/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - mae: 0.1877 - val_loss: 0.1013 - val_mae: 0.2230\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - mae: 0.1861 - val_loss: 0.1070 - val_mae: 0.2360\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - mae: 0.1870 - val_loss: 0.1053 - val_mae: 0.2412\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0544 - mae: 0.1835 - val_loss: 0.1034 - val_mae: 0.2288\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0521 - mae: 0.1826 - val_loss: 0.1107 - val_mae: 0.2540\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0541 - mae: 0.1858 - val_loss: 0.1000 - val_mae: 0.2259\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0528 - mae: 0.1799 - val_loss: 0.1019 - val_mae: 0.2334\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0540 - mae: 0.1835 - val_loss: 0.1019 - val_mae: 0.2317\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0540 - mae: 0.1887 - val_loss: 0.0992 - val_mae: 0.2225\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0513 - mae: 0.1770 - val_loss: 0.1054 - val_mae: 0.2361\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0520 - mae: 0.1772 - val_loss: 0.1113 - val_mae: 0.2497\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0529 - mae: 0.1837 - val_loss: 0.0966 - val_mae: 0.2156\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0516 - mae: 0.1794 - val_loss: 0.0943 - val_mae: 0.2130\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0483 - mae: 0.1749 - val_loss: 0.1063 - val_mae: 0.2380\n",
      "Epoch 49/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0524 - mae: 0.1809 - val_loss: 0.0982 - val_mae: 0.2306\n",
      "Epoch 50/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1851 - val_loss: 0.0964 - val_mae: 0.2137\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0512 - mae: 0.1802 - val_loss: 0.0961 - val_mae: 0.2170\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1773 - val_loss: 0.0934 - val_mae: 0.2150\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0495 - mae: 0.1780 - val_loss: 0.0970 - val_mae: 0.2226\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0481 - mae: 0.1765 - val_loss: 0.0959 - val_mae: 0.2126\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1717 - val_loss: 0.0931 - val_mae: 0.2128\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - mae: 0.1814 - val_loss: 0.0931 - val_mae: 0.2110\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.1742 - val_loss: 0.0935 - val_mae: 0.2179\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0486 - mae: 0.1801 - val_loss: 0.0933 - val_mae: 0.2130\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - mae: 0.1798 - val_loss: 0.0928 - val_mae: 0.2082\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - mae: 0.1760 - val_loss: 0.0900 - val_mae: 0.2070\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0490 - mae: 0.1769 - val_loss: 0.0907 - val_mae: 0.2089\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1694 - val_loss: 0.0955 - val_mae: 0.2237\n",
      "Epoch 63/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0464 - mae: 0.1711 - val_loss: 0.0930 - val_mae: 0.2199\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.1743 - val_loss: 0.0897 - val_mae: 0.2075\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - mae: 0.1717 - val_loss: 0.0931 - val_mae: 0.2250\n",
      "Epoch 66/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1708 - val_loss: 0.0971 - val_mae: 0.2295\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0461 - mae: 0.1746 - val_loss: 0.0907 - val_mae: 0.2124\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0442 - mae: 0.1694 - val_loss: 0.0883 - val_mae: 0.2138\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - mae: 0.1717 - val_loss: 0.0896 - val_mae: 0.2130\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1639 - val_loss: 0.0928 - val_mae: 0.2216\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.1648 - val_loss: 0.0923 - val_mae: 0.2066\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0442 - mae: 0.1697 - val_loss: 0.0862 - val_mae: 0.2062\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0446 - mae: 0.1700 - val_loss: 0.0849 - val_mae: 0.2014\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.1651 - val_loss: 0.0890 - val_mae: 0.2119\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1636 - val_loss: 0.0842 - val_mae: 0.1977\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.1639 - val_loss: 0.0838 - val_mae: 0.2007\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0434 - mae: 0.1702 - val_loss: 0.0850 - val_mae: 0.2071\n",
      "Epoch 78/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.1667 - val_loss: 0.0854 - val_mae: 0.2040\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1674 - val_loss: 0.0833 - val_mae: 0.2028\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1620 - val_loss: 0.0901 - val_mae: 0.2191\n",
      "Epoch 81/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0410 - mae: 0.1640 - val_loss: 0.0828 - val_mae: 0.1982\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.1649 - val_loss: 0.0844 - val_mae: 0.2066\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.1657 - val_loss: 0.0816 - val_mae: 0.1978\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0401 - mae: 0.1635 - val_loss: 0.0821 - val_mae: 0.2071\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1588 - val_loss: 0.0845 - val_mae: 0.2150\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0401 - mae: 0.1616 - val_loss: 0.0816 - val_mae: 0.1991\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1636 - val_loss: 0.0811 - val_mae: 0.2012\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1637 - val_loss: 0.0805 - val_mae: 0.1927\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - mae: 0.1591 - val_loss: 0.0779 - val_mae: 0.1918\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1603 - val_loss: 0.0798 - val_mae: 0.1977\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1581 - val_loss: 0.0783 - val_mae: 0.1881\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1568 - val_loss: 0.0774 - val_mae: 0.1913\n",
      "Epoch 93/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1590 - val_loss: 0.0776 - val_mae: 0.1899\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1585 - val_loss: 0.0768 - val_mae: 0.1947\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.1589 - val_loss: 0.0782 - val_mae: 0.1911\n",
      "Epoch 96/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0390 - mae: 0.1569 - val_loss: 0.0776 - val_mae: 0.1993\n",
      "Epoch 97/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1572 - val_loss: 0.0773 - val_mae: 0.1904\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1533 - val_loss: 0.0825 - val_mae: 0.2012\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0388 - mae: 0.1568 - val_loss: 0.0765 - val_mae: 0.1888\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0383 - mae: 0.1558 - val_loss: 0.0782 - val_mae: 0.1995\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0367 - mae: 0.1556 - val_loss: 0.0782 - val_mae: 0.1980\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.1576 - val_loss: 0.0782 - val_mae: 0.1924\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0371 - mae: 0.1554 - val_loss: 0.0810 - val_mae: 0.1977\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1570 - val_loss: 0.0778 - val_mae: 0.2007\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0382 - mae: 0.1610 - val_loss: 0.0742 - val_mae: 0.1901\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1535 - val_loss: 0.0786 - val_mae: 0.2055\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0367 - mae: 0.1529 - val_loss: 0.0767 - val_mae: 0.1973\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0379 - mae: 0.1548 - val_loss: 0.0759 - val_mae: 0.1893\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1521 - val_loss: 0.0762 - val_mae: 0.1928\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.1481 - val_loss: 0.0840 - val_mae: 0.2016\n",
      "Epoch 111/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1513 - val_loss: 0.0809 - val_mae: 0.2009\n",
      "Epoch 112/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1550 - val_loss: 0.0761 - val_mae: 0.1891\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0368 - mae: 0.1531 - val_loss: 0.0731 - val_mae: 0.1870\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1505 - val_loss: 0.0760 - val_mae: 0.1959\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - mae: 0.1484 - val_loss: 0.0729 - val_mae: 0.1885\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.1530 - val_loss: 0.0712 - val_mae: 0.1880\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0344 - mae: 0.1464 - val_loss: 0.0721 - val_mae: 0.1855\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1543 - val_loss: 0.0722 - val_mae: 0.1843\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1492 - val_loss: 0.0723 - val_mae: 0.1944\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1507 - val_loss: 0.0718 - val_mae: 0.1854\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0343 - mae: 0.1464 - val_loss: 0.0715 - val_mae: 0.1845\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.1456 - val_loss: 0.0744 - val_mae: 0.1937\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0339 - mae: 0.1477 - val_loss: 0.0762 - val_mae: 0.1922\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.1516 - val_loss: 0.0718 - val_mae: 0.1893\n",
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1441 - val_loss: 0.0728 - val_mae: 0.1867\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1491 - val_loss: 0.0717 - val_mae: 0.1860\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1433 - val_loss: 0.0724 - val_mae: 0.1955\n",
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0346 - mae: 0.1466 - val_loss: 0.0713 - val_mae: 0.1863\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1496 - val_loss: 0.0730 - val_mae: 0.1873\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1433 - val_loss: 0.0702 - val_mae: 0.1852\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1446 - val_loss: 0.0771 - val_mae: 0.1952\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - mae: 0.1516 - val_loss: 0.0713 - val_mae: 0.1871\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1422 - val_loss: 0.0770 - val_mae: 0.1927\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0338 - mae: 0.1463 - val_loss: 0.0736 - val_mae: 0.1912\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1477 - val_loss: 0.0746 - val_mae: 0.1914\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.1469 - val_loss: 0.0703 - val_mae: 0.1843\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.1451 - val_loss: 0.0710 - val_mae: 0.1884\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1466 - val_loss: 0.0739 - val_mae: 0.1935\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0328 - mae: 0.1461 - val_loss: 0.0700 - val_mae: 0.1866\n",
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1393 - val_loss: 0.0757 - val_mae: 0.2080\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1506 - val_loss: 0.0713 - val_mae: 0.1872\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1419 - val_loss: 0.0695 - val_mae: 0.1913\n",
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1429 - val_loss: 0.0715 - val_mae: 0.1961\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1390 - val_loss: 0.0742 - val_mae: 0.1913\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - mae: 0.1383 - val_loss: 0.0766 - val_mae: 0.2102\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1449 - val_loss: 0.0725 - val_mae: 0.1893\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1400 - val_loss: 0.0776 - val_mae: 0.2030\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1441 - val_loss: 0.0691 - val_mae: 0.1881\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.1450 - val_loss: 0.0702 - val_mae: 0.1906\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - mae: 0.1431 - val_loss: 0.0727 - val_mae: 0.1914\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1443 - val_loss: 0.0708 - val_mae: 0.1895\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1448 - val_loss: 0.0697 - val_mae: 0.1939\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1457 - val_loss: 0.0695 - val_mae: 0.1850\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1443 - val_loss: 0.0685 - val_mae: 0.1875\n",
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0322 - mae: 0.1426 - val_loss: 0.0689 - val_mae: 0.1859\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1426 - val_loss: 0.0701 - val_mae: 0.1874\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1472 - val_loss: 0.0713 - val_mae: 0.1894\n",
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1417 - val_loss: 0.0699 - val_mae: 0.1886\n",
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1467 - val_loss: 0.0711 - val_mae: 0.1890\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1401 - val_loss: 0.0770 - val_mae: 0.1960\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1437 - val_loss: 0.0712 - val_mae: 0.2013\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1456 - val_loss: 0.0697 - val_mae: 0.1884\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1416 - val_loss: 0.0717 - val_mae: 0.1933\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1437 - val_loss: 0.0706 - val_mae: 0.1959\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1420 - val_loss: 0.0713 - val_mae: 0.1933\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1435 - val_loss: 0.0717 - val_mae: 0.1931\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - mae: 0.1413 - val_loss: 0.0692 - val_mae: 0.1960\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1445 - val_loss: 0.0701 - val_mae: 0.1909\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1446 - val_loss: 0.0765 - val_mae: 0.1969\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.1438 - val_loss: 0.0699 - val_mae: 0.1903\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0318 - mae: 0.1395 - val_loss: 0.0706 - val_mae: 0.1886\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1402 - val_loss: 0.0707 - val_mae: 0.1914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1402 - val_loss: 0.0711 - val_mae: 0.1899\n",
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1451 - val_loss: 0.0722 - val_mae: 0.1994\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1422 - val_loss: 0.0727 - val_mae: 0.1932\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1417 - val_loss: 0.0702 - val_mae: 0.1904\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1421 - val_loss: 0.0708 - val_mae: 0.1982\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1437 - val_loss: 0.0758 - val_mae: 0.1950\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1432 - val_loss: 0.0724 - val_mae: 0.1912\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1369 - val_loss: 0.0717 - val_mae: 0.1912\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1457 - val_loss: 0.0724 - val_mae: 0.2033\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0333 - mae: 0.1505 - val_loss: 0.0711 - val_mae: 0.1909\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1395 - val_loss: 0.0765 - val_mae: 0.1985\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1404 - val_loss: 0.0703 - val_mae: 0.1932\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1440 - val_loss: 0.0709 - val_mae: 0.1921\n",
      "Epoch 186/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1384 - val_loss: 0.0746 - val_mae: 0.1950\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.1435 - val_loss: 0.0708 - val_mae: 0.1971\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0313 - mae: 0.1395 - val_loss: 0.0708 - val_mae: 0.1925\n",
      "Epoch 189/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1397 - val_loss: 0.0753 - val_mae: 0.1948\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1428 - val_loss: 0.0709 - val_mae: 0.1960\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1390 - val_loss: 0.0728 - val_mae: 0.1962\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1423 - val_loss: 0.0703 - val_mae: 0.1971\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1417 - val_loss: 0.0700 - val_mae: 0.1921\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1368 - val_loss: 0.0721 - val_mae: 0.1938\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1387 - val_loss: 0.0765 - val_mae: 0.1987\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1371 - val_loss: 0.0728 - val_mae: 0.1937\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1368 - val_loss: 0.0722 - val_mae: 0.1939\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1446 - val_loss: 0.0711 - val_mae: 0.1953\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1393 - val_loss: 0.0737 - val_mae: 0.1984\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1406 - val_loss: 0.0719 - val_mae: 0.1908\n",
      "Epoch 201/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1444 - val_loss: 0.0703 - val_mae: 0.1894\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1332 - val_loss: 0.0716 - val_mae: 0.1968\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1431 - val_loss: 0.0715 - val_mae: 0.1960\n",
      "Epoch 204/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1408 - val_loss: 0.0760 - val_mae: 0.2107\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1385 - val_loss: 0.0720 - val_mae: 0.1975\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1398 - val_loss: 0.0763 - val_mae: 0.1967\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.1414 - val_loss: 0.0718 - val_mae: 0.1969\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1425 - val_loss: 0.0698 - val_mae: 0.1949\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1391 - val_loss: 0.0703 - val_mae: 0.1991\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1433 - val_loss: 0.0697 - val_mae: 0.1924\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1401 - val_loss: 0.0733 - val_mae: 0.2013\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1421 - val_loss: 0.0751 - val_mae: 0.1943\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0308 - mae: 0.1434 - val_loss: 0.0730 - val_mae: 0.2038\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0313 - mae: 0.1432 - val_loss: 0.0714 - val_mae: 0.1969\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0304 - mae: 0.1423 - val_loss: 0.0705 - val_mae: 0.1958\n",
      "Epoch 216/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1356 - val_loss: 0.0751 - val_mae: 0.2082\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1438 - val_loss: 0.0739 - val_mae: 0.1971\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0314 - mae: 0.1433 - val_loss: 0.0743 - val_mae: 0.1967\n",
      "Epoch 219/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - mae: 0.1432 - val_loss: 0.0735 - val_mae: 0.1957\n",
      "Epoch 220/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1375 - val_loss: 0.0790 - val_mae: 0.2041\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.1401 - val_loss: 0.0762 - val_mae: 0.1981\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1450 - val_loss: 0.0716 - val_mae: 0.1962\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1386 - val_loss: 0.0781 - val_mae: 0.2025\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1426 - val_loss: 0.0717 - val_mae: 0.2002\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1389 - val_loss: 0.0751 - val_mae: 0.1986\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1368 - val_loss: 0.0774 - val_mae: 0.1983\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1396 - val_loss: 0.0740 - val_mae: 0.2047\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1394 - val_loss: 0.0739 - val_mae: 0.1999\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1425 - val_loss: 0.0712 - val_mae: 0.1982\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1380 - val_loss: 0.0818 - val_mae: 0.2046\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0320 - mae: 0.1443 - val_loss: 0.0731 - val_mae: 0.1997\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1390 - val_loss: 0.0708 - val_mae: 0.2001\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1339 - val_loss: 0.0747 - val_mae: 0.1984\n",
      "Epoch 234/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1373 - val_loss: 0.0728 - val_mae: 0.1979\n",
      "Epoch 235/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1369 - val_loss: 0.0846 - val_mae: 0.2171\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1421 - val_loss: 0.0750 - val_mae: 0.2041\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1389 - val_loss: 0.0711 - val_mae: 0.1942\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1428 - val_loss: 0.0704 - val_mae: 0.1963\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1366 - val_loss: 0.0717 - val_mae: 0.1990\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1382 - val_loss: 0.0733 - val_mae: 0.2027\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1342 - val_loss: 0.0720 - val_mae: 0.2055\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1384 - val_loss: 0.0717 - val_mae: 0.1960\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1428 - val_loss: 0.0722 - val_mae: 0.1980\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1427 - val_loss: 0.0774 - val_mae: 0.1982\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1409 - val_loss: 0.0756 - val_mae: 0.2005\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1373 - val_loss: 0.0749 - val_mae: 0.2061\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1449 - val_loss: 0.0735 - val_mae: 0.2036\n",
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1412 - val_loss: 0.0756 - val_mae: 0.1979\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1427 - val_loss: 0.0712 - val_mae: 0.2014\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1372 - val_loss: 0.0782 - val_mae: 0.1984\n",
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1394 - val_loss: 0.0714 - val_mae: 0.2026\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1388 - val_loss: 0.0756 - val_mae: 0.1993\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1406 - val_loss: 0.0750 - val_mae: 0.2038\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0297 - mae: 0.1372 - val_loss: 0.0739 - val_mae: 0.1953\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0284 - mae: 0.1351 - val_loss: 0.0751 - val_mae: 0.1983\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0304 - mae: 0.1413 - val_loss: 0.0734 - val_mae: 0.2016\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0305 - mae: 0.1398 - val_loss: 0.0782 - val_mae: 0.2011\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1392 - val_loss: 0.0741 - val_mae: 0.2047\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0308 - mae: 0.1398 - val_loss: 0.0717 - val_mae: 0.2015\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1393 - val_loss: 0.0719 - val_mae: 0.2006\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - mae: 0.1375 - val_loss: 0.0717 - val_mae: 0.2015\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1402 - val_loss: 0.0715 - val_mae: 0.1970\n",
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0297 - mae: 0.1387 - val_loss: 0.0725 - val_mae: 0.1966\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1396 - val_loss: 0.0787 - val_mae: 0.1984\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1383 - val_loss: 0.0785 - val_mae: 0.1986\n",
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1398 - val_loss: 0.0742 - val_mae: 0.2009\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1368 - val_loss: 0.0756 - val_mae: 0.2039\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1435 - val_loss: 0.0743 - val_mae: 0.2062\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.1460 - val_loss: 0.0735 - val_mae: 0.2003\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1403 - val_loss: 0.0740 - val_mae: 0.1990\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1374 - val_loss: 0.0742 - val_mae: 0.2036\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1398 - val_loss: 0.0737 - val_mae: 0.1997\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1362 - val_loss: 0.0763 - val_mae: 0.2081\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1381 - val_loss: 0.0757 - val_mae: 0.2000\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1393 - val_loss: 0.0723 - val_mae: 0.2019\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1401 - val_loss: 0.0726 - val_mae: 0.2002\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1373 - val_loss: 0.0728 - val_mae: 0.2067\n",
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1444 - val_loss: 0.0747 - val_mae: 0.2028\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1321 - val_loss: 0.0717 - val_mae: 0.1989\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1393 - val_loss: 0.0734 - val_mae: 0.1992\n",
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1374 - val_loss: 0.0763 - val_mae: 0.1981\n",
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1377 - val_loss: 0.0738 - val_mae: 0.2004\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1421 - val_loss: 0.0756 - val_mae: 0.2088\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1346 - val_loss: 0.0746 - val_mae: 0.2051\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0299 - mae: 0.1365 - val_loss: 0.0751 - val_mae: 0.2026\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1436 - val_loss: 0.0732 - val_mae: 0.2082\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1413 - val_loss: 0.0771 - val_mae: 0.2042\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1378 - val_loss: 0.0758 - val_mae: 0.2079\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1401 - val_loss: 0.0763 - val_mae: 0.2003\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1350 - val_loss: 0.0716 - val_mae: 0.2049\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1397 - val_loss: 0.0717 - val_mae: 0.2027\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1421 - val_loss: 0.0736 - val_mae: 0.2073\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1366 - val_loss: 0.0747 - val_mae: 0.2035\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1387 - val_loss: 0.0807 - val_mae: 0.2067\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1425 - val_loss: 0.0742 - val_mae: 0.2045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0310 - mae: 0.1427 - val_loss: 0.0738 - val_mae: 0.2052\n",
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1341 - val_loss: 0.0760 - val_mae: 0.2057\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1366 - val_loss: 0.0784 - val_mae: 0.2012\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1355 - val_loss: 0.0741 - val_mae: 0.2047\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1399 - val_loss: 0.0770 - val_mae: 0.2057\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1441 - val_loss: 0.0785 - val_mae: 0.2003\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1381 - val_loss: 0.0780 - val_mae: 0.2096\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1388 - val_loss: 0.0750 - val_mae: 0.2012\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1349 - val_loss: 0.0761 - val_mae: 0.2126\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1369 - val_loss: 0.0815 - val_mae: 0.2050\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1402 - val_loss: 0.0744 - val_mae: 0.2076\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1406 - val_loss: 0.0739 - val_mae: 0.2081\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1357 - val_loss: 0.0759 - val_mae: 0.1969\n",
      "Epoch 309/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1453 - val_loss: 0.0753 - val_mae: 0.2044\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1398 - val_loss: 0.0737 - val_mae: 0.2059\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1358 - val_loss: 0.0728 - val_mae: 0.2050\n",
      "Epoch 312/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1411 - val_loss: 0.0750 - val_mae: 0.2062\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1380 - val_loss: 0.0797 - val_mae: 0.2093\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1395 - val_loss: 0.0754 - val_mae: 0.2084\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1358 - val_loss: 0.0808 - val_mae: 0.2102\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1407 - val_loss: 0.0775 - val_mae: 0.2124\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1414 - val_loss: 0.0745 - val_mae: 0.2094\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1382 - val_loss: 0.0761 - val_mae: 0.2137\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1437 - val_loss: 0.0736 - val_mae: 0.2074\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1361 - val_loss: 0.0773 - val_mae: 0.2069\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1382 - val_loss: 0.0759 - val_mae: 0.2055\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1362 - val_loss: 0.0750 - val_mae: 0.2093\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1385 - val_loss: 0.0766 - val_mae: 0.2064\n",
      "Epoch 324/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1380 - val_loss: 0.0749 - val_mae: 0.2076\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1353 - val_loss: 0.0751 - val_mae: 0.2028\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1404 - val_loss: 0.0738 - val_mae: 0.2035\n",
      "Epoch 327/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1378 - val_loss: 0.0801 - val_mae: 0.2177\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1371 - val_loss: 0.0803 - val_mae: 0.2131\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1321 - val_loss: 0.0821 - val_mae: 0.2069\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1332 - val_loss: 0.0741 - val_mae: 0.2080\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1378 - val_loss: 0.0760 - val_mae: 0.2097\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1375 - val_loss: 0.0766 - val_mae: 0.2104\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1403 - val_loss: 0.0771 - val_mae: 0.2070\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1358 - val_loss: 0.0795 - val_mae: 0.2031\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1378 - val_loss: 0.0732 - val_mae: 0.2012\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1378 - val_loss: 0.0746 - val_mae: 0.2016\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1396 - val_loss: 0.0745 - val_mae: 0.2029\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1390 - val_loss: 0.0747 - val_mae: 0.2035\n",
      "Epoch 339/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1381 - val_loss: 0.0760 - val_mae: 0.2051\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1413 - val_loss: 0.0759 - val_mae: 0.2111\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.1428 - val_loss: 0.0761 - val_mae: 0.2067\n",
      "Epoch 342/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1383 - val_loss: 0.0762 - val_mae: 0.2084\n",
      "Epoch 343/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1387 - val_loss: 0.0753 - val_mae: 0.2027\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1384 - val_loss: 0.0765 - val_mae: 0.1986\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1372 - val_loss: 0.0754 - val_mae: 0.2028\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1358 - val_loss: 0.0751 - val_mae: 0.2045\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1383 - val_loss: 0.0758 - val_mae: 0.2030\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1386 - val_loss: 0.0764 - val_mae: 0.2064\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1355 - val_loss: 0.0742 - val_mae: 0.2061\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1334 - val_loss: 0.0763 - val_mae: 0.2025\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1346 - val_loss: 0.0774 - val_mae: 0.2098\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1306 - val_loss: 0.0739 - val_mae: 0.1982\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1386 - val_loss: 0.0749 - val_mae: 0.2006\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1407 - val_loss: 0.0762 - val_mae: 0.2049\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1374 - val_loss: 0.0775 - val_mae: 0.2059\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1398 - val_loss: 0.0750 - val_mae: 0.2021\n",
      "Epoch 357/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1379 - val_loss: 0.0745 - val_mae: 0.2032\n",
      "Epoch 358/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1367 - val_loss: 0.0796 - val_mae: 0.2085\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1411 - val_loss: 0.0769 - val_mae: 0.2053\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1365 - val_loss: 0.0763 - val_mae: 0.2108\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1380 - val_loss: 0.0796 - val_mae: 0.2057\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1332 - val_loss: 0.0885 - val_mae: 0.2203\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1389 - val_loss: 0.0799 - val_mae: 0.2072\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1388 - val_loss: 0.0756 - val_mae: 0.2075\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1381 - val_loss: 0.0751 - val_mae: 0.2084\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1358 - val_loss: 0.0769 - val_mae: 0.2039\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1347 - val_loss: 0.0757 - val_mae: 0.2115\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1402 - val_loss: 0.0751 - val_mae: 0.2064\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1387 - val_loss: 0.0785 - val_mae: 0.2020\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1386 - val_loss: 0.0776 - val_mae: 0.2038\n",
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1305 - val_loss: 0.0765 - val_mae: 0.2101\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1405 - val_loss: 0.0766 - val_mae: 0.2016\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1405 - val_loss: 0.0775 - val_mae: 0.2146\n",
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1364 - val_loss: 0.0768 - val_mae: 0.2141\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1407 - val_loss: 0.0755 - val_mae: 0.2064\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1355 - val_loss: 0.0822 - val_mae: 0.2057\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1427 - val_loss: 0.0806 - val_mae: 0.2075\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1337 - val_loss: 0.0775 - val_mae: 0.2106\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1391 - val_loss: 0.0778 - val_mae: 0.2105\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1410 - val_loss: 0.0781 - val_mae: 0.2083\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1379 - val_loss: 0.0811 - val_mae: 0.2077\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1358 - val_loss: 0.0762 - val_mae: 0.2114\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1360 - val_loss: 0.0755 - val_mae: 0.2089\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1367 - val_loss: 0.0763 - val_mae: 0.2078\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1352 - val_loss: 0.0758 - val_mae: 0.2076\n",
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1343 - val_loss: 0.0757 - val_mae: 0.2066\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.1438 - val_loss: 0.0769 - val_mae: 0.2053\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0279 - mae: 0.1353 - val_loss: 0.0746 - val_mae: 0.2077\n",
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1359 - val_loss: 0.0764 - val_mae: 0.2078\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1397 - val_loss: 0.0801 - val_mae: 0.2076\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1295 - val_loss: 0.0792 - val_mae: 0.2048\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1336 - val_loss: 0.0773 - val_mae: 0.2022\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1360 - val_loss: 0.0769 - val_mae: 0.2050\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1323 - val_loss: 0.0764 - val_mae: 0.2045\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1337 - val_loss: 0.0762 - val_mae: 0.2062\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1340 - val_loss: 0.0751 - val_mae: 0.2015\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1349 - val_loss: 0.0786 - val_mae: 0.2028\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1334 - val_loss: 0.0769 - val_mae: 0.2127\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1411 - val_loss: 0.0774 - val_mae: 0.2093\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1317 - val_loss: 0.0796 - val_mae: 0.2025\n",
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1385 - val_loss: 0.0770 - val_mae: 0.2022\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1387 - val_loss: 0.0778 - val_mae: 0.2069\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1350 - val_loss: 0.0768 - val_mae: 0.2106\n",
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1390 - val_loss: 0.0769 - val_mae: 0.2093\n",
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1375 - val_loss: 0.0799 - val_mae: 0.2149\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1383 - val_loss: 0.0803 - val_mae: 0.2086\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1366 - val_loss: 0.0782 - val_mae: 0.2088\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1317 - val_loss: 0.0764 - val_mae: 0.2096\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1368 - val_loss: 0.0767 - val_mae: 0.2114\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1366 - val_loss: 0.0779 - val_mae: 0.2065\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1358 - val_loss: 0.0801 - val_mae: 0.2115\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1364 - val_loss: 0.0777 - val_mae: 0.2064\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1380 - val_loss: 0.0805 - val_mae: 0.2114\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1334 - val_loss: 0.0800 - val_mae: 0.2068\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1368 - val_loss: 0.0780 - val_mae: 0.2076\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1394 - val_loss: 0.0792 - val_mae: 0.2132\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1337 - val_loss: 0.0790 - val_mae: 0.2113\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1382 - val_loss: 0.0800 - val_mae: 0.2101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1366 - val_loss: 0.0773 - val_mae: 0.2075\n",
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1334 - val_loss: 0.0798 - val_mae: 0.2110\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1377 - val_loss: 0.0785 - val_mae: 0.2106\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1354 - val_loss: 0.0780 - val_mae: 0.2087\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1355 - val_loss: 0.0805 - val_mae: 0.2083\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1353 - val_loss: 0.0789 - val_mae: 0.2164\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1354 - val_loss: 0.0788 - val_mae: 0.2063\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1347 - val_loss: 0.0829 - val_mae: 0.2132\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1352 - val_loss: 0.0792 - val_mae: 0.2119\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1353 - val_loss: 0.0801 - val_mae: 0.2151\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1390 - val_loss: 0.0793 - val_mae: 0.2067\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1343 - val_loss: 0.0788 - val_mae: 0.2055\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1341 - val_loss: 0.0796 - val_mae: 0.2133\n",
      "Epoch 432/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1387 - val_loss: 0.0795 - val_mae: 0.2061\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1355 - val_loss: 0.0815 - val_mae: 0.2075\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1358 - val_loss: 0.0818 - val_mae: 0.2118\n",
      "Epoch 435/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1298 - val_loss: 0.0789 - val_mae: 0.2073\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0293 - mae: 0.1398 - val_loss: 0.0810 - val_mae: 0.2107\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1350 - val_loss: 0.0802 - val_mae: 0.2120\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1349 - val_loss: 0.0788 - val_mae: 0.2089\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1347 - val_loss: 0.0804 - val_mae: 0.2104\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1348 - val_loss: 0.0796 - val_mae: 0.2109\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1310 - val_loss: 0.0784 - val_mae: 0.2143\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1393 - val_loss: 0.0804 - val_mae: 0.2137\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1330 - val_loss: 0.0767 - val_mae: 0.2092\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1361 - val_loss: 0.0780 - val_mae: 0.2085\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1384 - val_loss: 0.0800 - val_mae: 0.2153\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1376 - val_loss: 0.0795 - val_mae: 0.2078\n",
      "Epoch 447/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1338 - val_loss: 0.0804 - val_mae: 0.2107\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1365 - val_loss: 0.0801 - val_mae: 0.2141\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1329 - val_loss: 0.0850 - val_mae: 0.2234\n",
      "Epoch 450/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1335 - val_loss: 0.0825 - val_mae: 0.2094\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1354 - val_loss: 0.0813 - val_mae: 0.2142\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1337 - val_loss: 0.0788 - val_mae: 0.2146\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1368 - val_loss: 0.0779 - val_mae: 0.2082\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1391 - val_loss: 0.0797 - val_mae: 0.2096\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1345 - val_loss: 0.0815 - val_mae: 0.2132\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1332 - val_loss: 0.0786 - val_mae: 0.2095\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1366 - val_loss: 0.0813 - val_mae: 0.2068\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1329 - val_loss: 0.0800 - val_mae: 0.2159\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1286 - val_loss: 0.0791 - val_mae: 0.2111\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1338 - val_loss: 0.0795 - val_mae: 0.2141\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1334 - val_loss: 0.0827 - val_mae: 0.2075\n",
      "Epoch 462/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1351 - val_loss: 0.0803 - val_mae: 0.2147\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1343 - val_loss: 0.0839 - val_mae: 0.2119\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1326 - val_loss: 0.0801 - val_mae: 0.2148\n",
      "Epoch 465/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1390 - val_loss: 0.0849 - val_mae: 0.2098\n",
      "Epoch 466/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1315 - val_loss: 0.0820 - val_mae: 0.2196\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1263 - val_loss: 0.0820 - val_mae: 0.2198\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1350 - val_loss: 0.0826 - val_mae: 0.2171\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1345 - val_loss: 0.0900 - val_mae: 0.2233\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1324 - val_loss: 0.0836 - val_mae: 0.2169\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.1385 - val_loss: 0.0832 - val_mae: 0.2160\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1348 - val_loss: 0.0830 - val_mae: 0.2113\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1364 - val_loss: 0.0796 - val_mae: 0.2112\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1337 - val_loss: 0.0816 - val_mae: 0.2147\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1338 - val_loss: 0.0825 - val_mae: 0.2170\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1364 - val_loss: 0.0811 - val_mae: 0.2146\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1356 - val_loss: 0.0817 - val_mae: 0.2154\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1298 - val_loss: 0.0860 - val_mae: 0.2100\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1375 - val_loss: 0.0820 - val_mae: 0.2084\n",
      "Epoch 480/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1337 - val_loss: 0.0812 - val_mae: 0.2121\n",
      "Epoch 481/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1313 - val_loss: 0.0822 - val_mae: 0.2129\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1297 - val_loss: 0.0839 - val_mae: 0.2225\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0280 - mae: 0.1331 - val_loss: 0.0799 - val_mae: 0.2143\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1329 - val_loss: 0.0826 - val_mae: 0.2172\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1311 - val_loss: 0.0808 - val_mae: 0.2158\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1384 - val_loss: 0.0851 - val_mae: 0.2216\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1374 - val_loss: 0.0831 - val_mae: 0.2182\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1349 - val_loss: 0.0826 - val_mae: 0.2159\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1350 - val_loss: 0.0848 - val_mae: 0.2133\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1313 - val_loss: 0.0879 - val_mae: 0.2130\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.1357 - val_loss: 0.0833 - val_mae: 0.2141\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1328 - val_loss: 0.0866 - val_mae: 0.2234\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.1377 - val_loss: 0.0844 - val_mae: 0.2149\n",
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1348 - val_loss: 0.0806 - val_mae: 0.2143\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1365 - val_loss: 0.0814 - val_mae: 0.2125\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1341 - val_loss: 0.0799 - val_mae: 0.2125\n",
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1358 - val_loss: 0.0797 - val_mae: 0.2154\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1327 - val_loss: 0.0844 - val_mae: 0.2112\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1291 - val_loss: 0.0828 - val_mae: 0.2172\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1319 - val_loss: 0.0868 - val_mae: 0.2183\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1340 - val_loss: 0.0833 - val_mae: 0.2158\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1342 - val_loss: 0.0868 - val_mae: 0.2142\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1311 - val_loss: 0.0807 - val_mae: 0.2145\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1363 - val_loss: 0.0839 - val_mae: 0.2153\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1290 - val_loss: 0.0833 - val_mae: 0.2178\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1301 - val_loss: 0.0845 - val_mae: 0.2195\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1333 - val_loss: 0.0830 - val_mae: 0.2191\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.1350 - val_loss: 0.0842 - val_mae: 0.2103\n",
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1328 - val_loss: 0.0828 - val_mae: 0.2136\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.1355 - val_loss: 0.0844 - val_mae: 0.2143\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1312 - val_loss: 0.0842 - val_mae: 0.2160\n",
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1268 - val_loss: 0.0853 - val_mae: 0.2243\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1325 - val_loss: 0.0818 - val_mae: 0.2162\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1328 - val_loss: 0.0817 - val_mae: 0.2152\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1322 - val_loss: 0.0865 - val_mae: 0.2243\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1320 - val_loss: 0.0828 - val_mae: 0.2118\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1340 - val_loss: 0.0844 - val_mae: 0.2238\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1317 - val_loss: 0.0830 - val_mae: 0.2222\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1357 - val_loss: 0.0833 - val_mae: 0.2178\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1337 - val_loss: 0.0829 - val_mae: 0.2204\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1316 - val_loss: 0.0833 - val_mae: 0.2193\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1352 - val_loss: 0.0819 - val_mae: 0.2149\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1306 - val_loss: 0.0838 - val_mae: 0.2179\n",
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1309 - val_loss: 0.0851 - val_mae: 0.2217\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1321 - val_loss: 0.0849 - val_mae: 0.2193\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1313 - val_loss: 0.0857 - val_mae: 0.2131\n",
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1336 - val_loss: 0.0863 - val_mae: 0.2118\n",
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1291 - val_loss: 0.0852 - val_mae: 0.2242\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1315 - val_loss: 0.0852 - val_mae: 0.2114\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1284 - val_loss: 0.0842 - val_mae: 0.2206\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1324 - val_loss: 0.0837 - val_mae: 0.2140\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1345 - val_loss: 0.0858 - val_mae: 0.2130\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1269 - val_loss: 0.0826 - val_mae: 0.2139\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1272 - val_loss: 0.0843 - val_mae: 0.2186\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1326 - val_loss: 0.0859 - val_mae: 0.2098\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1293 - val_loss: 0.0814 - val_mae: 0.2149\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1315 - val_loss: 0.0832 - val_mae: 0.2170\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1314 - val_loss: 0.0831 - val_mae: 0.2154\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1313 - val_loss: 0.0847 - val_mae: 0.2174\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1329 - val_loss: 0.0825 - val_mae: 0.2159\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1317 - val_loss: 0.0831 - val_mae: 0.2178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1294 - val_loss: 0.0878 - val_mae: 0.2119\n",
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1303 - val_loss: 0.0856 - val_mae: 0.2204\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1335 - val_loss: 0.0840 - val_mae: 0.2153\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1319 - val_loss: 0.0854 - val_mae: 0.2239\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1309 - val_loss: 0.0904 - val_mae: 0.2239\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.1250 - val_loss: 0.0892 - val_mae: 0.2148\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0274 - mae: 0.1336 - val_loss: 0.0829 - val_mae: 0.2204\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1326 - val_loss: 0.0837 - val_mae: 0.2159\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1303 - val_loss: 0.0876 - val_mae: 0.2290\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1299 - val_loss: 0.0833 - val_mae: 0.2209\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1336 - val_loss: 0.0837 - val_mae: 0.2165\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1296 - val_loss: 0.0818 - val_mae: 0.2167\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1340 - val_loss: 0.0823 - val_mae: 0.2185\n",
      "Epoch 555/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1281 - val_loss: 0.0840 - val_mae: 0.2168\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1313 - val_loss: 0.0889 - val_mae: 0.2280\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1317 - val_loss: 0.0868 - val_mae: 0.2246\n",
      "Epoch 558/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1297 - val_loss: 0.0854 - val_mae: 0.2209\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1341 - val_loss: 0.0874 - val_mae: 0.2163\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1310 - val_loss: 0.0859 - val_mae: 0.2171\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1299 - val_loss: 0.0874 - val_mae: 0.2213\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1276 - val_loss: 0.0859 - val_mae: 0.2165\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1269 - val_loss: 0.0883 - val_mae: 0.2310\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0278 - mae: 0.1345 - val_loss: 0.0840 - val_mae: 0.2202\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1275 - val_loss: 0.0839 - val_mae: 0.2164\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1295 - val_loss: 0.0843 - val_mae: 0.2173\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1326 - val_loss: 0.0857 - val_mae: 0.2184\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.1297 - val_loss: 0.0877 - val_mae: 0.2295\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1335 - val_loss: 0.0858 - val_mae: 0.2205\n",
      "Epoch 570/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1262 - val_loss: 0.0850 - val_mae: 0.2172\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1341 - val_loss: 0.0884 - val_mae: 0.2204\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1293 - val_loss: 0.0912 - val_mae: 0.2326\n",
      "Epoch 573/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.1313 - val_loss: 0.0871 - val_mae: 0.2267\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1324 - val_loss: 0.0857 - val_mae: 0.2204\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1276 - val_loss: 0.0862 - val_mae: 0.2253\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0266 - mae: 0.1268 - val_loss: 0.0874 - val_mae: 0.2153\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1305 - val_loss: 0.0864 - val_mae: 0.2240\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1296 - val_loss: 0.0851 - val_mae: 0.2202\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1315 - val_loss: 0.0868 - val_mae: 0.2135\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1249 - val_loss: 0.0855 - val_mae: 0.2217\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1344 - val_loss: 0.0870 - val_mae: 0.2182\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.1280 - val_loss: 0.0857 - val_mae: 0.2216\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1296 - val_loss: 0.0836 - val_mae: 0.2211\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0248 - mae: 0.1270 - val_loss: 0.0887 - val_mae: 0.2342\n",
      "Epoch 585/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.1314 - val_loss: 0.0862 - val_mae: 0.2250\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1317 - val_loss: 0.0873 - val_mae: 0.2258\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1316 - val_loss: 0.0863 - val_mae: 0.2213\n",
      "Epoch 588/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1279 - val_loss: 0.0877 - val_mae: 0.2268\n",
      "Epoch 589/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1295 - val_loss: 0.0864 - val_mae: 0.2225\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1321 - val_loss: 0.0863 - val_mae: 0.2222\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.1322 - val_loss: 0.0885 - val_mae: 0.2262\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1292 - val_loss: 0.0865 - val_mae: 0.2224\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.1323 - val_loss: 0.0860 - val_mae: 0.2190\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1264 - val_loss: 0.0875 - val_mae: 0.2297\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1280 - val_loss: 0.0891 - val_mae: 0.2290\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.1317 - val_loss: 0.0844 - val_mae: 0.2171\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.1291 - val_loss: 0.0888 - val_mae: 0.2194\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.1302 - val_loss: 0.0894 - val_mae: 0.2309\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.1319 - val_loss: 0.0876 - val_mae: 0.2236\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1311 - val_loss: 0.0874 - val_mae: 0.2201\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "#Choosing the number on neurons in the hidden layer\n",
    "scores = {}\n",
    "results0 = {}\n",
    "results1 = {}\n",
    "batch_size = 4\n",
    "max_epochs = 600\n",
    "parameters = [2,3,4,6,8,10,12,14,16]\n",
    "output_size = 2\n",
    "\n",
    "for parameter in parameters:\n",
    "    print(parameter)\n",
    "    model = make_regression_model()\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=max_epochs,\n",
    "                        validation_data=(x_validate, y_validate), verbose = 1) \n",
    "    scores[parameter] = history.history\n",
    "    y_hat_train = model.predict(x_train)\n",
    "    y_hat_test = model.predict(x_test)\n",
    "    r2_train0 = np.round(r2_score(np.exp(y_train[:,0]), np.exp(y_hat_train[:,0])), 5)\n",
    "    r2_test0 = np.round(r2_score(np.exp(y_test[:,0]), np.exp(y_hat_test[:,0])), 5)\n",
    "    mean_abs_error0 = np.round(mean_absolute_error(np.exp(y_test[:,0]), np.exp(y_hat_test[:,0])), 0)\n",
    "    mean_sq_error0 = np.round(np.sqrt(mean_squared_error(np.exp(y_test[:,0]), np.exp(y_hat_test[:,0]))),0)\n",
    "    mean_abs_percent_error0 = np.round(mean_absolute_percentage_error(np.exp(y_test[:,0]), np.exp(y_hat_test[:,0])),3)*100\n",
    "    r2_train1 = np.round(r2_score(np.exp(y_train[:,1]), np.exp(y_hat_train[:,1])), 5)\n",
    "    r2_test1 = np.round(r2_score(np.exp(y_test[:,1]), np.exp(y_hat_test[:,1])), 5)\n",
    "    mean_abs_error1 = np.round(mean_absolute_error(np.exp(y_test[:,1]), np.exp(y_hat_test[:,1])), 0)\n",
    "    mean_sq_error1 = np.round(np.sqrt(mean_squared_error(np.exp(y_test[:,1]), np.exp(y_hat_test[:,1]))),0)\n",
    "    mean_abs_percent_error1 = np.round(mean_absolute_percentage_error(np.exp(y_test[:,1]), np.exp(y_hat_test[:,1])),3)*100\n",
    "    results0[parameter] = [r2_train0, r2_test0, mean_abs_error0, mean_sq_error0, mean_abs_percent_error0]\n",
    "    results1[parameter] = [r2_train1, r2_test1, mean_abs_error1, mean_sq_error1, mean_abs_percent_error1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d40d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the results\n",
    "plt.figure(figsize = [16, 6])\n",
    "for parameter, hist in scores.items():\n",
    "    plt.plot(hist['val_mae'], label=parameters)\n",
    "\n",
    "plt.legend(parameters)\n",
    "#plt.xlim(400,600)\n",
    "#plt.ylim(0.2,0.3)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94f9f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.89554</td>\n",
       "      <td>0.91869</td>\n",
       "      <td>0.91966</td>\n",
       "      <td>0.88106</td>\n",
       "      <td>0.92023</td>\n",
       "      <td>0.92054</td>\n",
       "      <td>0.90853</td>\n",
       "      <td>0.88149</td>\n",
       "      <td>0.90732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test</th>\n",
       "      <td>0.79993</td>\n",
       "      <td>0.75336</td>\n",
       "      <td>0.58446</td>\n",
       "      <td>0.79244</td>\n",
       "      <td>0.62701</td>\n",
       "      <td>0.53852</td>\n",
       "      <td>0.67302</td>\n",
       "      <td>0.50598</td>\n",
       "      <td>0.60563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_abs_error</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_sq_error</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_abs_percent_error</th>\n",
       "      <td>20.40000</td>\n",
       "      <td>22.60000</td>\n",
       "      <td>27.10000</td>\n",
       "      <td>19.80000</td>\n",
       "      <td>26.10000</td>\n",
       "      <td>29.40000</td>\n",
       "      <td>23.60000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>26.20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              2         3         4         6         8   \\\n",
       "r2_train                 0.89554   0.91869   0.91966   0.88106   0.92023   \n",
       "r2_test                  0.79993   0.75336   0.58446   0.79244   0.62701   \n",
       "mean_abs_error           1.00000   2.00000   2.00000   1.00000   2.00000   \n",
       "mean_sq_error            2.00000   2.00000   3.00000   2.00000   3.00000   \n",
       "mean_abs_percent_error  20.40000  22.60000  27.10000  19.80000  26.10000   \n",
       "\n",
       "                              10        12        14        16  \n",
       "r2_train                 0.92054   0.90853   0.88149   0.90732  \n",
       "r2_test                  0.53852   0.67302   0.50598   0.60563  \n",
       "mean_abs_error           2.00000   2.00000   2.00000   2.00000  \n",
       "mean_sq_error            3.00000   2.00000   3.00000   3.00000  \n",
       "mean_abs_percent_error  29.40000  23.60000  37.00000  26.20000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results0, index=['r2_train', 'r2_test', 'mean_abs_error', 'mean_sq_error', 'mean_abs_percent_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48f08788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.69089</td>\n",
       "      <td>0.72294</td>\n",
       "      <td>0.64512</td>\n",
       "      <td>0.68704</td>\n",
       "      <td>0.61522</td>\n",
       "      <td>0.70718</td>\n",
       "      <td>0.67346</td>\n",
       "      <td>0.65519</td>\n",
       "      <td>0.70340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test</th>\n",
       "      <td>0.66431</td>\n",
       "      <td>0.71235</td>\n",
       "      <td>0.71268</td>\n",
       "      <td>0.70427</td>\n",
       "      <td>0.72851</td>\n",
       "      <td>0.68696</td>\n",
       "      <td>0.59610</td>\n",
       "      <td>0.71772</td>\n",
       "      <td>0.71701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_abs_error</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_sq_error</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_abs_percent_error</th>\n",
       "      <td>13.10000</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>14.30000</td>\n",
       "      <td>13.10000</td>\n",
       "      <td>14.80000</td>\n",
       "      <td>14.50000</td>\n",
       "      <td>17.90000</td>\n",
       "      <td>13.10000</td>\n",
       "      <td>13.70000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              2         3         4         6         8   \\\n",
       "r2_train                 0.69089   0.72294   0.64512   0.68704   0.61522   \n",
       "r2_test                  0.66431   0.71235   0.71268   0.70427   0.72851   \n",
       "mean_abs_error           0.00000   0.00000   0.00000   0.00000   0.00000   \n",
       "mean_sq_error            0.00000   0.00000   0.00000   0.00000   0.00000   \n",
       "mean_abs_percent_error  13.10000  12.60000  14.30000  13.10000  14.80000   \n",
       "\n",
       "                              10        12        14        16  \n",
       "r2_train                 0.70718   0.67346   0.65519   0.70340  \n",
       "r2_test                  0.68696   0.59610   0.71772   0.71701  \n",
       "mean_abs_error           0.00000   0.00000   0.00000   0.00000  \n",
       "mean_sq_error            0.00000   0.00000   0.00000   0.00000  \n",
       "mean_abs_percent_error  14.50000  17.90000  13.10000  13.70000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results1, index=['r2_train', 'r2_test', 'mean_abs_error', 'mean_sq_error', 'mean_abs_percent_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1695d0",
   "metadata": {},
   "source": [
    "Using the same method, the following parameter combinations were run:\n",
    "\n",
    "- Activation function 1: [Linear, Relu, Elu, Swish, Tanh, Sigmoid, Hard Sigmoid]\n",
    "- Activation function 2: [Linear, Relu, Elu, Swish, Tanh, Sigmoid, Hard Sigmoid]\n",
    "- Kernel initializer: [glorot normal, glorot uniform, he normal, he uniform]\n",
    "- Batch size: [3, 4, 5, 6, 7, 8]\n",
    "- Maximum epochs: [100, 200, 300, 400, 500, 600, 700]\n",
    "- Learning rate: [0.1, 0.01, 0.005, 0.001]\n",
    "- Optimizer: [Adam, RMSprop]\n",
    "- Dropout rate: [0, 0.01, 0.03, 0.05, 0.1, 0.2]\n",
    "\n",
    "After running all the above combinations, the final parameters will be as following:\n",
    "\n",
    "- hidden layers neurons: 3\n",
    "- Activation function 1: Tanh\n",
    "- Activation function 2: Relu\n",
    "- Kernel initializer: he normal\n",
    "- Batch size: 4\n",
    "- Maximum epochs: 600\n",
    "- Learning rate: 0.005\n",
    "- Optimizer: RMSprop\n",
    "- Dropout rate: 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365038e5",
   "metadata": {},
   "source": [
    "3 neurons\n",
    "tanh/sigmoid\n",
    "relu/elu\n",
    "he_normal\n",
    "0.03\n",
    "600\n",
    "3/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57423f1",
   "metadata": {},
   "source": [
    "## Running the Final Model and Comparing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254c2e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.8284 - mae: 0.7373 - val_loss: 0.7972 - val_mae: 0.6763\n",
      "Epoch 2/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - mae: 0.6548 - val_loss: 0.5971 - val_mae: 0.5869\n",
      "Epoch 3/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5084 - mae: 0.5930 - val_loss: 0.4329 - val_mae: 0.5018\n",
      "Epoch 4/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3929 - mae: 0.5273 - val_loss: 0.3020 - val_mae: 0.4327\n",
      "Epoch 5/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3289 - mae: 0.4812 - val_loss: 0.2244 - val_mae: 0.3846\n",
      "Epoch 6/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2803 - mae: 0.4474 - val_loss: 0.1754 - val_mae: 0.3455\n",
      "Epoch 7/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2641 - mae: 0.4235 - val_loss: 0.1520 - val_mae: 0.3185\n",
      "Epoch 8/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2286 - mae: 0.3897 - val_loss: 0.1361 - val_mae: 0.2946\n",
      "Epoch 9/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1946 - mae: 0.3602 - val_loss: 0.1407 - val_mae: 0.3007\n",
      "Epoch 10/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1777 - mae: 0.3386 - val_loss: 0.1350 - val_mae: 0.2906\n",
      "Epoch 11/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1602 - mae: 0.3126 - val_loss: 0.1338 - val_mae: 0.2846\n",
      "Epoch 12/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1609 - mae: 0.3173 - val_loss: 0.1348 - val_mae: 0.2871\n",
      "Epoch 13/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1506 - mae: 0.3104 - val_loss: 0.1376 - val_mae: 0.2892\n",
      "Epoch 14/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1920 - mae: 0.3349 - val_loss: 0.1353 - val_mae: 0.2811\n",
      "Epoch 15/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1516 - mae: 0.3081 - val_loss: 0.1351 - val_mae: 0.2796\n",
      "Epoch 16/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1498 - mae: 0.3039 - val_loss: 0.1361 - val_mae: 0.2792\n",
      "Epoch 17/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1357 - mae: 0.2864 - val_loss: 0.1385 - val_mae: 0.2850\n",
      "Epoch 18/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1577 - mae: 0.3034 - val_loss: 0.1372 - val_mae: 0.2824\n",
      "Epoch 19/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1393 - mae: 0.2868 - val_loss: 0.1376 - val_mae: 0.2840\n",
      "Epoch 20/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1518 - mae: 0.3030 - val_loss: 0.1364 - val_mae: 0.2813\n",
      "Epoch 21/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1661 - mae: 0.3019 - val_loss: 0.1353 - val_mae: 0.2786\n",
      "Epoch 22/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1459 - mae: 0.2941 - val_loss: 0.1361 - val_mae: 0.2801\n",
      "Epoch 23/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1545 - mae: 0.3059 - val_loss: 0.1339 - val_mae: 0.2769\n",
      "Epoch 24/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1489 - mae: 0.3029 - val_loss: 0.1344 - val_mae: 0.2726\n",
      "Epoch 25/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1339 - mae: 0.2840 - val_loss: 0.1315 - val_mae: 0.2691\n",
      "Epoch 26/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1257 - mae: 0.2785 - val_loss: 0.1291 - val_mae: 0.2678\n",
      "Epoch 27/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1416 - mae: 0.2910 - val_loss: 0.1252 - val_mae: 0.2601\n",
      "Epoch 28/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1301 - mae: 0.2814 - val_loss: 0.1238 - val_mae: 0.2605\n",
      "Epoch 29/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1247 - mae: 0.2746 - val_loss: 0.1175 - val_mae: 0.2548\n",
      "Epoch 30/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1129 - mae: 0.2636 - val_loss: 0.1126 - val_mae: 0.2508\n",
      "Epoch 31/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1272 - mae: 0.2775 - val_loss: 0.1052 - val_mae: 0.2497\n",
      "Epoch 32/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1119 - mae: 0.2699 - val_loss: 0.1056 - val_mae: 0.2556\n",
      "Epoch 33/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1058 - mae: 0.2608 - val_loss: 0.1024 - val_mae: 0.2549\n",
      "Epoch 34/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0956 - mae: 0.2443 - val_loss: 0.1005 - val_mae: 0.2500\n",
      "Epoch 35/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1210 - mae: 0.2695 - val_loss: 0.1019 - val_mae: 0.2522\n",
      "Epoch 36/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1186 - mae: 0.2813 - val_loss: 0.0997 - val_mae: 0.2455\n",
      "Epoch 37/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0938 - mae: 0.2467 - val_loss: 0.0983 - val_mae: 0.2411\n",
      "Epoch 38/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0920 - mae: 0.2368 - val_loss: 0.1023 - val_mae: 0.2463\n",
      "Epoch 39/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0916 - mae: 0.2381 - val_loss: 0.1004 - val_mae: 0.2453\n",
      "Epoch 40/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1105 - mae: 0.2601 - val_loss: 0.0983 - val_mae: 0.2444\n",
      "Epoch 41/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1031 - mae: 0.2476 - val_loss: 0.0959 - val_mae: 0.2346\n",
      "Epoch 42/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0980 - mae: 0.2393 - val_loss: 0.0992 - val_mae: 0.2407\n",
      "Epoch 43/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0906 - mae: 0.2348 - val_loss: 0.0971 - val_mae: 0.2331\n",
      "Epoch 44/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0870 - mae: 0.2332 - val_loss: 0.0938 - val_mae: 0.2277\n",
      "Epoch 45/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0951 - mae: 0.2366 - val_loss: 0.0953 - val_mae: 0.2250\n",
      "Epoch 46/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1101 - mae: 0.2632 - val_loss: 0.0952 - val_mae: 0.2244\n",
      "Epoch 47/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0912 - mae: 0.2304 - val_loss: 0.0952 - val_mae: 0.2316\n",
      "Epoch 48/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0946 - mae: 0.2408 - val_loss: 0.0953 - val_mae: 0.2302\n",
      "Epoch 49/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0859 - mae: 0.2294 - val_loss: 0.0955 - val_mae: 0.2333\n",
      "Epoch 50/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0780 - mae: 0.2216 - val_loss: 0.0950 - val_mae: 0.2304\n",
      "Epoch 51/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0762 - mae: 0.2076 - val_loss: 0.0936 - val_mae: 0.2236\n",
      "Epoch 52/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0701 - mae: 0.2037 - val_loss: 0.0951 - val_mae: 0.2239\n",
      "Epoch 53/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0679 - mae: 0.1994 - val_loss: 0.0947 - val_mae: 0.2153\n",
      "Epoch 54/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0674 - mae: 0.2000 - val_loss: 0.0966 - val_mae: 0.2212\n",
      "Epoch 55/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0649 - mae: 0.1953 - val_loss: 0.0974 - val_mae: 0.2206\n",
      "Epoch 56/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0879 - mae: 0.2192 - val_loss: 0.0963 - val_mae: 0.2179\n",
      "Epoch 57/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0680 - mae: 0.2025 - val_loss: 0.0962 - val_mae: 0.2173\n",
      "Epoch 58/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0850 - mae: 0.2069 - val_loss: 0.0962 - val_mae: 0.2143\n",
      "Epoch 59/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0582 - mae: 0.1826 - val_loss: 0.0949 - val_mae: 0.2137\n",
      "Epoch 60/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0622 - mae: 0.1904 - val_loss: 0.0941 - val_mae: 0.2129\n",
      "Epoch 61/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0580 - mae: 0.1860 - val_loss: 0.0957 - val_mae: 0.2164\n",
      "Epoch 62/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0639 - mae: 0.1973 - val_loss: 0.0956 - val_mae: 0.2151\n",
      "Epoch 63/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0651 - mae: 0.1911 - val_loss: 0.0977 - val_mae: 0.2174\n",
      "Epoch 64/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.1675 - val_loss: 0.0950 - val_mae: 0.2142\n",
      "Epoch 65/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0738 - mae: 0.2021 - val_loss: 0.0945 - val_mae: 0.2144\n",
      "Epoch 66/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0638 - mae: 0.1922 - val_loss: 0.0946 - val_mae: 0.2134\n",
      "Epoch 67/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0657 - mae: 0.1869 - val_loss: 0.0953 - val_mae: 0.2146\n",
      "Epoch 68/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - mae: 0.1770 - val_loss: 0.0938 - val_mae: 0.2137\n",
      "Epoch 69/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0628 - mae: 0.1900 - val_loss: 0.0948 - val_mae: 0.2148\n",
      "Epoch 70/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - mae: 0.1795 - val_loss: 0.0963 - val_mae: 0.2157\n",
      "Epoch 71/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0646 - mae: 0.1889 - val_loss: 0.0947 - val_mae: 0.2144\n",
      "Epoch 72/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - mae: 0.1871 - val_loss: 0.0973 - val_mae: 0.2183\n",
      "Epoch 73/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0480 - mae: 0.1766 - val_loss: 0.0988 - val_mae: 0.2210\n",
      "Epoch 74/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - mae: 0.1771 - val_loss: 0.0986 - val_mae: 0.2212\n",
      "Epoch 75/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0494 - mae: 0.1771 - val_loss: 0.0956 - val_mae: 0.2170\n",
      "Epoch 76/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0708 - mae: 0.1916 - val_loss: 0.0981 - val_mae: 0.2221\n",
      "Epoch 77/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0653 - mae: 0.1878 - val_loss: 0.0969 - val_mae: 0.2196\n",
      "Epoch 78/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - mae: 0.1776 - val_loss: 0.0972 - val_mae: 0.2207\n",
      "Epoch 79/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0495 - mae: 0.1748 - val_loss: 0.0965 - val_mae: 0.2192\n",
      "Epoch 80/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.1709 - val_loss: 0.0946 - val_mae: 0.2169\n",
      "Epoch 81/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.1662 - val_loss: 0.0959 - val_mae: 0.2181\n",
      "Epoch 82/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0505 - mae: 0.1772 - val_loss: 0.0943 - val_mae: 0.2162\n",
      "Epoch 83/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0478 - mae: 0.1720 - val_loss: 0.0957 - val_mae: 0.2180\n",
      "Epoch 84/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1721 - val_loss: 0.0972 - val_mae: 0.2201\n",
      "Epoch 85/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - mae: 0.1765 - val_loss: 0.0960 - val_mae: 0.2195\n",
      "Epoch 86/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0577 - mae: 0.1822 - val_loss: 0.0937 - val_mae: 0.2151\n",
      "Epoch 87/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1781 - val_loss: 0.0973 - val_mae: 0.2198\n",
      "Epoch 88/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.1603 - val_loss: 0.0954 - val_mae: 0.2173\n",
      "Epoch 89/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0504 - mae: 0.1709 - val_loss: 0.0931 - val_mae: 0.2150\n",
      "Epoch 90/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0594 - mae: 0.1844 - val_loss: 0.0966 - val_mae: 0.2189\n",
      "Epoch 91/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.1777 - val_loss: 0.0962 - val_mae: 0.2182\n",
      "Epoch 92/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - mae: 0.1726 - val_loss: 0.0963 - val_mae: 0.2185\n",
      "Epoch 93/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0527 - mae: 0.1744 - val_loss: 0.0954 - val_mae: 0.2184\n",
      "Epoch 94/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0468 - mae: 0.1675 - val_loss: 0.0961 - val_mae: 0.2199\n",
      "Epoch 95/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0582 - mae: 0.1847 - val_loss: 0.0929 - val_mae: 0.2158\n",
      "Epoch 96/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0490 - mae: 0.1733 - val_loss: 0.0944 - val_mae: 0.2181\n",
      "Epoch 97/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0569 - mae: 0.1824 - val_loss: 0.0946 - val_mae: 0.2175\n",
      "Epoch 98/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1670 - val_loss: 0.0963 - val_mae: 0.2193\n",
      "Epoch 99/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0472 - mae: 0.1661 - val_loss: 0.0954 - val_mae: 0.2178\n",
      "Epoch 100/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0468 - mae: 0.1677 - val_loss: 0.0935 - val_mae: 0.2157\n",
      "Epoch 101/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0509 - mae: 0.1702 - val_loss: 0.0932 - val_mae: 0.2153\n",
      "Epoch 102/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0442 - mae: 0.1624 - val_loss: 0.0953 - val_mae: 0.2198\n",
      "Epoch 103/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - mae: 0.1733 - val_loss: 0.0954 - val_mae: 0.2198\n",
      "Epoch 104/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0481 - mae: 0.1657 - val_loss: 0.0937 - val_mae: 0.2168\n",
      "Epoch 105/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0595 - mae: 0.1824 - val_loss: 0.0939 - val_mae: 0.2154\n",
      "Epoch 106/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0495 - mae: 0.1670 - val_loss: 0.0952 - val_mae: 0.2208\n",
      "Epoch 107/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0517 - mae: 0.1711 - val_loss: 0.0941 - val_mae: 0.2180\n",
      "Epoch 108/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0632 - mae: 0.1875 - val_loss: 0.0938 - val_mae: 0.2164\n",
      "Epoch 109/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1632 - val_loss: 0.0953 - val_mae: 0.2195\n",
      "Epoch 110/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0472 - mae: 0.1630 - val_loss: 0.0953 - val_mae: 0.2187\n",
      "Epoch 111/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0395 - mae: 0.1548 - val_loss: 0.0928 - val_mae: 0.2150\n",
      "Epoch 112/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - mae: 0.1673 - val_loss: 0.0950 - val_mae: 0.2197\n",
      "Epoch 113/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1487 - val_loss: 0.0941 - val_mae: 0.2185\n",
      "Epoch 114/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0476 - mae: 0.1659 - val_loss: 0.0949 - val_mae: 0.2209\n",
      "Epoch 115/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0575 - mae: 0.1756 - val_loss: 0.0934 - val_mae: 0.2171\n",
      "Epoch 116/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1625 - val_loss: 0.0923 - val_mae: 0.2162\n",
      "Epoch 117/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - mae: 0.1812 - val_loss: 0.0929 - val_mae: 0.2155\n",
      "Epoch 118/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0499 - mae: 0.1701 - val_loss: 0.0929 - val_mae: 0.2165\n",
      "Epoch 119/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0518 - mae: 0.1708 - val_loss: 0.0966 - val_mae: 0.2215\n",
      "Epoch 120/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - mae: 0.1640 - val_loss: 0.0954 - val_mae: 0.2189\n",
      "Epoch 121/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - mae: 0.1730 - val_loss: 0.0948 - val_mae: 0.2190\n",
      "Epoch 122/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1564 - val_loss: 0.0939 - val_mae: 0.2182\n",
      "Epoch 123/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0522 - mae: 0.1756 - val_loss: 0.0957 - val_mae: 0.2202\n",
      "Epoch 124/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - mae: 0.1762 - val_loss: 0.0981 - val_mae: 0.2232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1537 - val_loss: 0.0944 - val_mae: 0.2195\n",
      "Epoch 126/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0480 - mae: 0.1611 - val_loss: 0.0954 - val_mae: 0.2202\n",
      "Epoch 127/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0563 - mae: 0.1745 - val_loss: 0.0941 - val_mae: 0.2181\n",
      "Epoch 128/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1622 - val_loss: 0.0950 - val_mae: 0.2193\n",
      "Epoch 129/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.1656 - val_loss: 0.0950 - val_mae: 0.2195\n",
      "Epoch 130/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1738 - val_loss: 0.0935 - val_mae: 0.2167\n",
      "Epoch 131/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0553 - mae: 0.1726 - val_loss: 0.0934 - val_mae: 0.2173\n",
      "Epoch 132/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0503 - mae: 0.1643 - val_loss: 0.0945 - val_mae: 0.2166\n",
      "Epoch 133/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - mae: 0.1771 - val_loss: 0.0945 - val_mae: 0.2195\n",
      "Epoch 134/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1661 - val_loss: 0.0924 - val_mae: 0.2144\n",
      "Epoch 135/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1667 - val_loss: 0.0952 - val_mae: 0.2199\n",
      "Epoch 136/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0478 - mae: 0.1676 - val_loss: 0.0939 - val_mae: 0.2175\n",
      "Epoch 137/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1678 - val_loss: 0.0922 - val_mae: 0.2151\n",
      "Epoch 138/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.1700 - val_loss: 0.0937 - val_mae: 0.2175\n",
      "Epoch 139/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.1630 - val_loss: 0.0923 - val_mae: 0.2158\n",
      "Epoch 140/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - mae: 0.1732 - val_loss: 0.0922 - val_mae: 0.2161\n",
      "Epoch 141/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0494 - mae: 0.1686 - val_loss: 0.0936 - val_mae: 0.2182\n",
      "Epoch 142/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1569 - val_loss: 0.0944 - val_mae: 0.2198\n",
      "Epoch 143/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - mae: 0.1676 - val_loss: 0.0943 - val_mae: 0.2200\n",
      "Epoch 144/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0446 - mae: 0.1646 - val_loss: 0.0933 - val_mae: 0.2185\n",
      "Epoch 145/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1672 - val_loss: 0.0927 - val_mae: 0.2176\n",
      "Epoch 146/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0591 - mae: 0.1789 - val_loss: 0.0933 - val_mae: 0.2178\n",
      "Epoch 147/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0546 - mae: 0.1761 - val_loss: 0.0925 - val_mae: 0.2156\n",
      "Epoch 148/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1509 - val_loss: 0.0924 - val_mae: 0.2177\n",
      "Epoch 149/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0455 - mae: 0.1636 - val_loss: 0.0908 - val_mae: 0.2150\n",
      "Epoch 150/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0371 - mae: 0.1504 - val_loss: 0.0938 - val_mae: 0.2214\n",
      "Epoch 151/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0459 - mae: 0.1665 - val_loss: 0.0927 - val_mae: 0.2179\n",
      "Epoch 152/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1541 - val_loss: 0.0927 - val_mae: 0.2177\n",
      "Epoch 153/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0558 - mae: 0.1745 - val_loss: 0.0928 - val_mae: 0.2161\n",
      "Epoch 154/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1548 - val_loss: 0.0949 - val_mae: 0.2237\n",
      "Epoch 155/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0433 - mae: 0.1632 - val_loss: 0.0934 - val_mae: 0.2196\n",
      "Epoch 156/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0517 - mae: 0.1706 - val_loss: 0.0919 - val_mae: 0.2165\n",
      "Epoch 157/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.1538 - val_loss: 0.0913 - val_mae: 0.2150\n",
      "Epoch 158/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0637 - mae: 0.1788 - val_loss: 0.0909 - val_mae: 0.2146\n",
      "Epoch 159/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0562 - mae: 0.1708 - val_loss: 0.0894 - val_mae: 0.2114\n",
      "Epoch 160/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1520 - val_loss: 0.0918 - val_mae: 0.2151\n",
      "Epoch 161/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0557 - mae: 0.1743 - val_loss: 0.0931 - val_mae: 0.2191\n",
      "Epoch 162/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.1605 - val_loss: 0.0924 - val_mae: 0.2167\n",
      "Epoch 163/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0511 - mae: 0.1665 - val_loss: 0.0924 - val_mae: 0.2171\n",
      "Epoch 164/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1699 - val_loss: 0.0916 - val_mae: 0.2164\n",
      "Epoch 165/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.1601 - val_loss: 0.0931 - val_mae: 0.2227\n",
      "Epoch 166/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 0.1670 - val_loss: 0.0927 - val_mae: 0.2184\n",
      "Epoch 167/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0541 - mae: 0.1786 - val_loss: 0.0914 - val_mae: 0.2161\n",
      "Epoch 168/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0415 - mae: 0.1572 - val_loss: 0.0926 - val_mae: 0.2186\n",
      "Epoch 169/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0613 - mae: 0.1770 - val_loss: 0.0922 - val_mae: 0.2171\n",
      "Epoch 170/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0463 - mae: 0.1626 - val_loss: 0.0908 - val_mae: 0.2162\n",
      "Epoch 171/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - mae: 0.1600 - val_loss: 0.0916 - val_mae: 0.2173\n",
      "Epoch 172/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.1631 - val_loss: 0.0908 - val_mae: 0.2173\n",
      "Epoch 173/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0455 - mae: 0.1653 - val_loss: 0.0907 - val_mae: 0.2159\n",
      "Epoch 174/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - mae: 0.1611 - val_loss: 0.0905 - val_mae: 0.2168\n",
      "Epoch 175/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0479 - mae: 0.1637 - val_loss: 0.0901 - val_mae: 0.2161\n",
      "Epoch 176/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0579 - mae: 0.1746 - val_loss: 0.0917 - val_mae: 0.2194\n",
      "Epoch 177/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0465 - mae: 0.1672 - val_loss: 0.0921 - val_mae: 0.2185\n",
      "Epoch 178/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0448 - mae: 0.1616 - val_loss: 0.0931 - val_mae: 0.2217\n",
      "Epoch 179/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0404 - mae: 0.1540 - val_loss: 0.0914 - val_mae: 0.2180\n",
      "Epoch 180/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0496 - mae: 0.1702 - val_loss: 0.0954 - val_mae: 0.2252\n",
      "Epoch 181/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0479 - mae: 0.1646 - val_loss: 0.0911 - val_mae: 0.2177\n",
      "Epoch 182/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0417 - mae: 0.1585 - val_loss: 0.0922 - val_mae: 0.2202\n",
      "Epoch 183/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.1742 - val_loss: 0.0915 - val_mae: 0.2190\n",
      "Epoch 184/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0494 - mae: 0.1645 - val_loss: 0.0913 - val_mae: 0.2185\n",
      "Epoch 185/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1512 - val_loss: 0.0923 - val_mae: 0.2199\n",
      "Epoch 186/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0564 - mae: 0.1696 - val_loss: 0.0923 - val_mae: 0.2191\n",
      "Epoch 187/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0418 - mae: 0.1586 - val_loss: 0.0919 - val_mae: 0.2182\n",
      "Epoch 188/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0657 - mae: 0.1721 - val_loss: 0.0900 - val_mae: 0.2167\n",
      "Epoch 189/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0523 - mae: 0.1707 - val_loss: 0.0903 - val_mae: 0.2177\n",
      "Epoch 190/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1593 - val_loss: 0.0901 - val_mae: 0.2165\n",
      "Epoch 191/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0459 - mae: 0.1710 - val_loss: 0.0909 - val_mae: 0.2183\n",
      "Epoch 192/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1555 - val_loss: 0.0911 - val_mae: 0.2171\n",
      "Epoch 193/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1562 - val_loss: 0.0902 - val_mae: 0.2172\n",
      "Epoch 194/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0518 - mae: 0.1700 - val_loss: 0.0920 - val_mae: 0.2203\n",
      "Epoch 195/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0576 - mae: 0.1750 - val_loss: 0.0905 - val_mae: 0.2173\n",
      "Epoch 196/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1623 - val_loss: 0.0902 - val_mae: 0.2168\n",
      "Epoch 197/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0542 - mae: 0.1713 - val_loss: 0.0914 - val_mae: 0.2185\n",
      "Epoch 198/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.1616 - val_loss: 0.0925 - val_mae: 0.2188\n",
      "Epoch 199/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.1572 - val_loss: 0.0914 - val_mae: 0.2183\n",
      "Epoch 200/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 0.1627 - val_loss: 0.0907 - val_mae: 0.2181\n",
      "Epoch 201/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1624 - val_loss: 0.0922 - val_mae: 0.2205\n",
      "Epoch 202/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1535 - val_loss: 0.0929 - val_mae: 0.2211\n",
      "Epoch 203/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0452 - mae: 0.1605 - val_loss: 0.0905 - val_mae: 0.2177\n",
      "Epoch 204/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1604 - val_loss: 0.0899 - val_mae: 0.2165\n",
      "Epoch 205/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0465 - mae: 0.1629 - val_loss: 0.0910 - val_mae: 0.2203\n",
      "Epoch 206/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0544 - mae: 0.1762 - val_loss: 0.0896 - val_mae: 0.2177\n",
      "Epoch 207/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1581 - val_loss: 0.0906 - val_mae: 0.2205\n",
      "Epoch 208/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0514 - mae: 0.1653 - val_loss: 0.0890 - val_mae: 0.2173\n",
      "Epoch 209/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - mae: 0.1689 - val_loss: 0.0895 - val_mae: 0.2178\n",
      "Epoch 210/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - mae: 0.1686 - val_loss: 0.0891 - val_mae: 0.2172\n",
      "Epoch 211/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1647 - val_loss: 0.0899 - val_mae: 0.2189\n",
      "Epoch 212/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1609 - val_loss: 0.0908 - val_mae: 0.2222\n",
      "Epoch 213/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.1712 - val_loss: 0.0893 - val_mae: 0.2168\n",
      "Epoch 214/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1678 - val_loss: 0.0894 - val_mae: 0.2168\n",
      "Epoch 215/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0503 - mae: 0.1651 - val_loss: 0.0881 - val_mae: 0.2159\n",
      "Epoch 216/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0450 - mae: 0.1644 - val_loss: 0.0897 - val_mae: 0.2186\n",
      "Epoch 217/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.1616 - val_loss: 0.0903 - val_mae: 0.2188\n",
      "Epoch 218/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.1622 - val_loss: 0.0902 - val_mae: 0.2186\n",
      "Epoch 219/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.1592 - val_loss: 0.0912 - val_mae: 0.2205\n",
      "Epoch 220/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.1534 - val_loss: 0.0907 - val_mae: 0.2200\n",
      "Epoch 221/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1598 - val_loss: 0.0895 - val_mae: 0.2170\n",
      "Epoch 222/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0509 - mae: 0.1770 - val_loss: 0.0902 - val_mae: 0.2175\n",
      "Epoch 223/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0488 - mae: 0.1661 - val_loss: 0.0891 - val_mae: 0.2161\n",
      "Epoch 224/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1607 - val_loss: 0.0897 - val_mae: 0.2169\n",
      "Epoch 225/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0476 - mae: 0.1722 - val_loss: 0.0892 - val_mae: 0.2171\n",
      "Epoch 226/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1562 - val_loss: 0.0886 - val_mae: 0.2159\n",
      "Epoch 227/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1575 - val_loss: 0.0893 - val_mae: 0.2173\n",
      "Epoch 228/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1558 - val_loss: 0.0885 - val_mae: 0.2163\n",
      "Epoch 229/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - mae: 0.1578 - val_loss: 0.0897 - val_mae: 0.2179\n",
      "Epoch 230/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0471 - mae: 0.1686 - val_loss: 0.0887 - val_mae: 0.2169\n",
      "Epoch 231/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.1574 - val_loss: 0.0899 - val_mae: 0.2186\n",
      "Epoch 232/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - mae: 0.1645 - val_loss: 0.0894 - val_mae: 0.2171\n",
      "Epoch 233/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0452 - mae: 0.1629 - val_loss: 0.0886 - val_mae: 0.2156\n",
      "Epoch 234/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0517 - mae: 0.1736 - val_loss: 0.0875 - val_mae: 0.2139\n",
      "Epoch 235/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - mae: 0.1684 - val_loss: 0.0888 - val_mae: 0.2161\n",
      "Epoch 236/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1536 - val_loss: 0.0889 - val_mae: 0.2153\n",
      "Epoch 237/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - mae: 0.1673 - val_loss: 0.0906 - val_mae: 0.2185\n",
      "Epoch 238/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.1638 - val_loss: 0.0927 - val_mae: 0.2235\n",
      "Epoch 239/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 0.1659 - val_loss: 0.0907 - val_mae: 0.2208\n",
      "Epoch 240/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0396 - mae: 0.1578 - val_loss: 0.0899 - val_mae: 0.2196\n",
      "Epoch 241/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0409 - mae: 0.1574 - val_loss: 0.0889 - val_mae: 0.2181\n",
      "Epoch 242/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0472 - mae: 0.1621 - val_loss: 0.0928 - val_mae: 0.2245\n",
      "Epoch 243/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1600 - val_loss: 0.0918 - val_mae: 0.2220\n",
      "Epoch 244/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1627 - val_loss: 0.0899 - val_mae: 0.2196\n",
      "Epoch 245/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0434 - mae: 0.1608 - val_loss: 0.0910 - val_mae: 0.2208\n",
      "Epoch 246/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1648 - val_loss: 0.0895 - val_mae: 0.2183\n",
      "Epoch 247/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1640 - val_loss: 0.0880 - val_mae: 0.2157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0447 - mae: 0.1615 - val_loss: 0.0885 - val_mae: 0.2173\n",
      "Epoch 249/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0407 - mae: 0.1584 - val_loss: 0.0881 - val_mae: 0.2170\n",
      "Epoch 250/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.1622 - val_loss: 0.0885 - val_mae: 0.2170\n",
      "Epoch 251/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1658 - val_loss: 0.0902 - val_mae: 0.2197\n",
      "Epoch 252/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - mae: 0.1724 - val_loss: 0.0873 - val_mae: 0.2149\n",
      "Epoch 253/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0401 - mae: 0.1570 - val_loss: 0.0888 - val_mae: 0.2171\n",
      "Epoch 254/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0491 - mae: 0.1630 - val_loss: 0.0915 - val_mae: 0.2234\n",
      "Epoch 255/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0418 - mae: 0.1604 - val_loss: 0.0893 - val_mae: 0.2176\n",
      "Epoch 256/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1596 - val_loss: 0.0895 - val_mae: 0.2218\n",
      "Epoch 257/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0559 - mae: 0.1731 - val_loss: 0.0878 - val_mae: 0.2158\n",
      "Epoch 258/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.1630 - val_loss: 0.0899 - val_mae: 0.2205\n",
      "Epoch 259/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0492 - mae: 0.1687 - val_loss: 0.0896 - val_mae: 0.2189\n",
      "Epoch 260/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.1561 - val_loss: 0.0897 - val_mae: 0.2209\n",
      "Epoch 261/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - mae: 0.1685 - val_loss: 0.0923 - val_mae: 0.2283\n",
      "Epoch 262/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1616 - val_loss: 0.0890 - val_mae: 0.2174\n",
      "Epoch 263/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - mae: 0.1543 - val_loss: 0.0884 - val_mae: 0.2163\n",
      "Epoch 264/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0489 - mae: 0.1666 - val_loss: 0.0898 - val_mae: 0.2188\n",
      "Epoch 265/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1536 - val_loss: 0.0907 - val_mae: 0.2198\n",
      "Epoch 266/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 0.1592 - val_loss: 0.0909 - val_mae: 0.2203\n",
      "Epoch 267/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1617 - val_loss: 0.0897 - val_mae: 0.2195\n",
      "Epoch 268/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 0.1603 - val_loss: 0.0900 - val_mae: 0.2200\n",
      "Epoch 269/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0385 - mae: 0.1577 - val_loss: 0.0897 - val_mae: 0.2187\n",
      "Epoch 270/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1649 - val_loss: 0.0895 - val_mae: 0.2182\n",
      "Epoch 271/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1514 - val_loss: 0.0898 - val_mae: 0.2193\n",
      "Epoch 272/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 0.1608 - val_loss: 0.0899 - val_mae: 0.2201\n",
      "Epoch 273/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1636 - val_loss: 0.0895 - val_mae: 0.2188\n",
      "Epoch 274/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1573 - val_loss: 0.0924 - val_mae: 0.2265\n",
      "Epoch 275/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 0.1632 - val_loss: 0.0884 - val_mae: 0.2185\n",
      "Epoch 276/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0415 - mae: 0.1593 - val_loss: 0.0890 - val_mae: 0.2188\n",
      "Epoch 277/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0476 - mae: 0.1696 - val_loss: 0.0881 - val_mae: 0.2164\n",
      "Epoch 278/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - mae: 0.1742 - val_loss: 0.0881 - val_mae: 0.2169\n",
      "Epoch 279/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.1655 - val_loss: 0.0883 - val_mae: 0.2172\n",
      "Epoch 280/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - mae: 0.1634 - val_loss: 0.0877 - val_mae: 0.2165\n",
      "Epoch 281/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0407 - mae: 0.1617 - val_loss: 0.0883 - val_mae: 0.2178\n",
      "Epoch 282/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - mae: 0.1724 - val_loss: 0.0871 - val_mae: 0.2143\n",
      "Epoch 283/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0487 - mae: 0.1674 - val_loss: 0.0875 - val_mae: 0.2157\n",
      "Epoch 284/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.1605 - val_loss: 0.0892 - val_mae: 0.2185\n",
      "Epoch 285/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0401 - mae: 0.1583 - val_loss: 0.0890 - val_mae: 0.2179\n",
      "Epoch 286/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0386 - mae: 0.1592 - val_loss: 0.0897 - val_mae: 0.2189\n",
      "Epoch 287/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - mae: 0.1656 - val_loss: 0.0887 - val_mae: 0.2166\n",
      "Epoch 288/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - mae: 0.1681 - val_loss: 0.0889 - val_mae: 0.2167\n",
      "Epoch 289/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - mae: 0.1801 - val_loss: 0.0888 - val_mae: 0.2178\n",
      "Epoch 290/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0440 - mae: 0.1630 - val_loss: 0.0906 - val_mae: 0.2208\n",
      "Epoch 291/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1580 - val_loss: 0.0895 - val_mae: 0.2185\n",
      "Epoch 292/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1455 - val_loss: 0.0907 - val_mae: 0.2204\n",
      "Epoch 293/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.1674 - val_loss: 0.0891 - val_mae: 0.2178\n",
      "Epoch 294/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0510 - mae: 0.1684 - val_loss: 0.0884 - val_mae: 0.2161\n",
      "Epoch 295/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0530 - mae: 0.1772 - val_loss: 0.0877 - val_mae: 0.2156\n",
      "Epoch 296/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 0.1551 - val_loss: 0.0867 - val_mae: 0.2151\n",
      "Epoch 297/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1588 - val_loss: 0.0885 - val_mae: 0.2184\n",
      "Epoch 298/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0389 - mae: 0.1565 - val_loss: 0.0891 - val_mae: 0.2192\n",
      "Epoch 299/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1596 - val_loss: 0.0916 - val_mae: 0.2255\n",
      "Epoch 300/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0417 - mae: 0.1613 - val_loss: 0.0875 - val_mae: 0.2156\n",
      "Epoch 301/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - mae: 0.1666 - val_loss: 0.0878 - val_mae: 0.2171\n",
      "Epoch 302/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0496 - mae: 0.1710 - val_loss: 0.0894 - val_mae: 0.2188\n",
      "Epoch 303/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1728 - val_loss: 0.0876 - val_mae: 0.2167\n",
      "Epoch 304/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.1566 - val_loss: 0.0891 - val_mae: 0.2192\n",
      "Epoch 305/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0383 - mae: 0.1559 - val_loss: 0.0881 - val_mae: 0.2179\n",
      "Epoch 306/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.1648 - val_loss: 0.0898 - val_mae: 0.2207\n",
      "Epoch 307/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0419 - mae: 0.1611 - val_loss: 0.0877 - val_mae: 0.2166\n",
      "Epoch 308/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1571 - val_loss: 0.0881 - val_mae: 0.2173\n",
      "Epoch 309/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.1656 - val_loss: 0.0882 - val_mae: 0.2175\n",
      "Epoch 310/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0417 - mae: 0.1564 - val_loss: 0.0879 - val_mae: 0.2167\n",
      "Epoch 311/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.1617 - val_loss: 0.0884 - val_mae: 0.2184\n",
      "Epoch 312/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.1615 - val_loss: 0.0872 - val_mae: 0.2163\n",
      "Epoch 313/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0476 - mae: 0.1654 - val_loss: 0.0898 - val_mae: 0.2214\n",
      "Epoch 314/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0587 - mae: 0.1784 - val_loss: 0.0885 - val_mae: 0.2171\n",
      "Epoch 315/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - mae: 0.1738 - val_loss: 0.0872 - val_mae: 0.2156\n",
      "Epoch 316/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0459 - mae: 0.1685 - val_loss: 0.0872 - val_mae: 0.2162\n",
      "Epoch 317/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1596 - val_loss: 0.0875 - val_mae: 0.2170\n",
      "Epoch 318/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1598 - val_loss: 0.0884 - val_mae: 0.2185\n",
      "Epoch 319/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0516 - mae: 0.1773 - val_loss: 0.0881 - val_mae: 0.2176\n",
      "Epoch 320/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0432 - mae: 0.1619 - val_loss: 0.0878 - val_mae: 0.2175\n",
      "Epoch 321/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1611 - val_loss: 0.0871 - val_mae: 0.2161\n",
      "Epoch 322/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1587 - val_loss: 0.0873 - val_mae: 0.2180\n",
      "Epoch 323/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0651 - mae: 0.1805 - val_loss: 0.0862 - val_mae: 0.2152\n",
      "Epoch 324/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0390 - mae: 0.1542 - val_loss: 0.0872 - val_mae: 0.2166\n",
      "Epoch 325/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0492 - mae: 0.1718 - val_loss: 0.0897 - val_mae: 0.2199\n",
      "Epoch 326/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0432 - mae: 0.1662 - val_loss: 0.0888 - val_mae: 0.2190\n",
      "Epoch 327/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.1603 - val_loss: 0.0873 - val_mae: 0.2160\n",
      "Epoch 328/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0440 - mae: 0.1654 - val_loss: 0.0887 - val_mae: 0.2191\n",
      "Epoch 329/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0615 - mae: 0.1806 - val_loss: 0.0888 - val_mae: 0.2183\n",
      "Epoch 330/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0374 - mae: 0.1531 - val_loss: 0.0899 - val_mae: 0.2243\n",
      "Epoch 331/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.1656 - val_loss: 0.0886 - val_mae: 0.2186\n",
      "Epoch 332/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - mae: 0.1575 - val_loss: 0.0899 - val_mae: 0.2243\n",
      "Epoch 333/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0403 - mae: 0.1600 - val_loss: 0.0892 - val_mae: 0.2196\n",
      "Epoch 334/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0407 - mae: 0.1596 - val_loss: 0.0898 - val_mae: 0.2212\n",
      "Epoch 335/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.1616 - val_loss: 0.0870 - val_mae: 0.2163\n",
      "Epoch 336/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0512 - mae: 0.1718 - val_loss: 0.0864 - val_mae: 0.2152\n",
      "Epoch 337/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0513 - mae: 0.1696 - val_loss: 0.0884 - val_mae: 0.2220\n",
      "Epoch 338/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.1629 - val_loss: 0.0863 - val_mae: 0.2153\n",
      "Epoch 339/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0486 - mae: 0.1711 - val_loss: 0.0865 - val_mae: 0.2155\n",
      "Epoch 340/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1578 - val_loss: 0.0910 - val_mae: 0.2250\n",
      "Epoch 341/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0517 - mae: 0.1737 - val_loss: 0.0900 - val_mae: 0.2212\n",
      "Epoch 342/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.1601 - val_loss: 0.0897 - val_mae: 0.2207\n",
      "Epoch 343/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1576 - val_loss: 0.0874 - val_mae: 0.2163\n",
      "Epoch 344/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0401 - mae: 0.1606 - val_loss: 0.0873 - val_mae: 0.2168\n",
      "Epoch 345/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0424 - mae: 0.1617 - val_loss: 0.0892 - val_mae: 0.2202\n",
      "Epoch 346/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0447 - mae: 0.1621 - val_loss: 0.0891 - val_mae: 0.2196\n",
      "Epoch 347/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0446 - mae: 0.1681 - val_loss: 0.0875 - val_mae: 0.2175\n",
      "Epoch 348/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0434 - mae: 0.1639 - val_loss: 0.0872 - val_mae: 0.2168\n",
      "Epoch 349/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0503 - mae: 0.1673 - val_loss: 0.0871 - val_mae: 0.2165\n",
      "Epoch 350/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1566 - val_loss: 0.0868 - val_mae: 0.2159\n",
      "Epoch 351/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0453 - mae: 0.1626 - val_loss: 0.0872 - val_mae: 0.2173\n",
      "Epoch 352/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0448 - mae: 0.1648 - val_loss: 0.0883 - val_mae: 0.2191\n",
      "Epoch 353/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1661 - val_loss: 0.0888 - val_mae: 0.2201\n",
      "Epoch 354/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0464 - mae: 0.1620 - val_loss: 0.0880 - val_mae: 0.2189\n",
      "Epoch 355/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1638 - val_loss: 0.0884 - val_mae: 0.2202\n",
      "Epoch 356/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.1598 - val_loss: 0.0901 - val_mae: 0.2227\n",
      "Epoch 357/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1664 - val_loss: 0.0886 - val_mae: 0.2189\n",
      "Epoch 358/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0478 - mae: 0.1689 - val_loss: 0.0880 - val_mae: 0.2194\n",
      "Epoch 359/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0375 - mae: 0.1527 - val_loss: 0.0884 - val_mae: 0.2197\n",
      "Epoch 360/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0529 - mae: 0.1708 - val_loss: 0.0872 - val_mae: 0.2175\n",
      "Epoch 361/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0400 - mae: 0.1555 - val_loss: 0.0898 - val_mae: 0.2251\n",
      "Epoch 362/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0415 - mae: 0.1608 - val_loss: 0.0869 - val_mae: 0.2163\n",
      "Epoch 363/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - mae: 0.1734 - val_loss: 0.0871 - val_mae: 0.2170\n",
      "Epoch 364/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1575 - val_loss: 0.0881 - val_mae: 0.2184\n",
      "Epoch 365/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1597 - val_loss: 0.0880 - val_mae: 0.2186\n",
      "Epoch 366/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1609 - val_loss: 0.0882 - val_mae: 0.2197\n",
      "Epoch 367/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - mae: 0.1488 - val_loss: 0.0901 - val_mae: 0.2227\n",
      "Epoch 368/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.1622 - val_loss: 0.0899 - val_mae: 0.2220\n",
      "Epoch 369/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0416 - mae: 0.1620 - val_loss: 0.0906 - val_mae: 0.2238\n",
      "Epoch 370/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1552 - val_loss: 0.0898 - val_mae: 0.2217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1748 - val_loss: 0.0881 - val_mae: 0.2186\n",
      "Epoch 372/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - mae: 0.1647 - val_loss: 0.0895 - val_mae: 0.2210\n",
      "Epoch 373/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - mae: 0.1725 - val_loss: 0.0877 - val_mae: 0.2183\n",
      "Epoch 374/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0453 - mae: 0.1660 - val_loss: 0.0883 - val_mae: 0.2192\n",
      "Epoch 375/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0388 - mae: 0.1557 - val_loss: 0.0912 - val_mae: 0.2230\n",
      "Epoch 376/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0433 - mae: 0.1619 - val_loss: 0.0888 - val_mae: 0.2202\n",
      "Epoch 377/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1592 - val_loss: 0.0879 - val_mae: 0.2189\n",
      "Epoch 378/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0609 - mae: 0.1768 - val_loss: 0.0869 - val_mae: 0.2170\n",
      "Epoch 379/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0453 - mae: 0.1660 - val_loss: 0.0898 - val_mae: 0.2225\n",
      "Epoch 380/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.1632 - val_loss: 0.0878 - val_mae: 0.2181\n",
      "Epoch 381/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.1637 - val_loss: 0.0890 - val_mae: 0.2193\n",
      "Epoch 382/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.1589 - val_loss: 0.0872 - val_mae: 0.2167\n",
      "Epoch 383/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0446 - mae: 0.1622 - val_loss: 0.0889 - val_mae: 0.2203\n",
      "Epoch 384/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0568 - mae: 0.1721 - val_loss: 0.0894 - val_mae: 0.2217\n",
      "Epoch 385/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - mae: 0.1657 - val_loss: 0.0901 - val_mae: 0.2239\n",
      "Epoch 386/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1559 - val_loss: 0.0902 - val_mae: 0.2226\n",
      "Epoch 387/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0444 - mae: 0.1638 - val_loss: 0.0903 - val_mae: 0.2226\n",
      "Epoch 388/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - mae: 0.1759 - val_loss: 0.0915 - val_mae: 0.2234\n",
      "Epoch 389/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.1578 - val_loss: 0.0918 - val_mae: 0.2251\n",
      "Epoch 390/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0524 - mae: 0.1706 - val_loss: 0.0891 - val_mae: 0.2206\n",
      "Epoch 391/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0395 - mae: 0.1567 - val_loss: 0.0900 - val_mae: 0.2221\n",
      "Epoch 392/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0498 - mae: 0.1706 - val_loss: 0.0908 - val_mae: 0.2244\n",
      "Epoch 393/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0578 - mae: 0.1782 - val_loss: 0.0885 - val_mae: 0.2204\n",
      "Epoch 394/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1636 - val_loss: 0.0877 - val_mae: 0.2191\n",
      "Epoch 395/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0419 - mae: 0.1623 - val_loss: 0.0878 - val_mae: 0.2188\n",
      "Epoch 396/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.1621 - val_loss: 0.0877 - val_mae: 0.2177\n",
      "Epoch 397/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.1638 - val_loss: 0.0875 - val_mae: 0.2180\n",
      "Epoch 398/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.1566 - val_loss: 0.0877 - val_mae: 0.2183\n",
      "Epoch 399/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - mae: 0.1624 - val_loss: 0.0914 - val_mae: 0.2232\n",
      "Epoch 400/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1618 - val_loss: 0.0911 - val_mae: 0.2239\n",
      "Epoch 401/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0436 - mae: 0.1619 - val_loss: 0.0882 - val_mae: 0.2189\n",
      "Epoch 402/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1577 - val_loss: 0.0902 - val_mae: 0.2230\n",
      "Epoch 403/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0450 - mae: 0.1672 - val_loss: 0.0874 - val_mae: 0.2185\n",
      "Epoch 404/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1606 - val_loss: 0.0880 - val_mae: 0.2190\n",
      "Epoch 405/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0401 - mae: 0.1583 - val_loss: 0.0887 - val_mae: 0.2190\n",
      "Epoch 406/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.1742 - val_loss: 0.0875 - val_mae: 0.2173\n",
      "Epoch 407/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0490 - mae: 0.1662 - val_loss: 0.0890 - val_mae: 0.2197\n",
      "Epoch 408/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0395 - mae: 0.1579 - val_loss: 0.0900 - val_mae: 0.2217\n",
      "Epoch 409/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0491 - mae: 0.1746 - val_loss: 0.0909 - val_mae: 0.2237\n",
      "Epoch 410/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - mae: 0.1823 - val_loss: 0.0897 - val_mae: 0.2222\n",
      "Epoch 411/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0558 - mae: 0.1694 - val_loss: 0.0892 - val_mae: 0.2216\n",
      "Epoch 412/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.1586 - val_loss: 0.0890 - val_mae: 0.2197\n",
      "Epoch 413/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0500 - mae: 0.1732 - val_loss: 0.0890 - val_mae: 0.2199\n",
      "Epoch 414/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0480 - mae: 0.1687 - val_loss: 0.0883 - val_mae: 0.2194\n",
      "Epoch 415/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0440 - mae: 0.1641 - val_loss: 0.0871 - val_mae: 0.2168\n",
      "Epoch 416/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1597 - val_loss: 0.0872 - val_mae: 0.2158\n",
      "Epoch 417/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - mae: 0.1638 - val_loss: 0.0885 - val_mae: 0.2196\n",
      "Epoch 418/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.1677 - val_loss: 0.0876 - val_mae: 0.2179\n",
      "Epoch 419/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0387 - mae: 0.1545 - val_loss: 0.0878 - val_mae: 0.2182\n",
      "Epoch 420/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0494 - mae: 0.1698 - val_loss: 0.0870 - val_mae: 0.2177\n",
      "Epoch 421/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0464 - mae: 0.1650 - val_loss: 0.0871 - val_mae: 0.2181\n",
      "Epoch 422/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1502 - val_loss: 0.0902 - val_mae: 0.2224\n",
      "Epoch 423/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0488 - mae: 0.1717 - val_loss: 0.0877 - val_mae: 0.2184\n",
      "Epoch 424/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1610 - val_loss: 0.0868 - val_mae: 0.2171\n",
      "Epoch 425/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0415 - mae: 0.1615 - val_loss: 0.0863 - val_mae: 0.2162\n",
      "Epoch 426/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.1649 - val_loss: 0.0864 - val_mae: 0.2160\n",
      "Epoch 427/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0480 - mae: 0.1720 - val_loss: 0.0875 - val_mae: 0.2175\n",
      "Epoch 428/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0499 - mae: 0.1710 - val_loss: 0.0874 - val_mae: 0.2171\n",
      "Epoch 429/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.1546 - val_loss: 0.0865 - val_mae: 0.2168\n",
      "Epoch 430/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0488 - mae: 0.1682 - val_loss: 0.0875 - val_mae: 0.2176\n",
      "Epoch 431/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1627 - val_loss: 0.0869 - val_mae: 0.2175\n",
      "Epoch 432/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0493 - mae: 0.1665 - val_loss: 0.0868 - val_mae: 0.2173\n",
      "Epoch 433/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 0.1642 - val_loss: 0.0880 - val_mae: 0.2189\n",
      "Epoch 434/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0470 - mae: 0.1705 - val_loss: 0.0888 - val_mae: 0.2205\n",
      "Epoch 435/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0486 - mae: 0.1694 - val_loss: 0.0893 - val_mae: 0.2206\n",
      "Epoch 436/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0395 - mae: 0.1592 - val_loss: 0.0874 - val_mae: 0.2184\n",
      "Epoch 437/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0422 - mae: 0.1612 - val_loss: 0.0879 - val_mae: 0.2187\n",
      "Epoch 438/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.1618 - val_loss: 0.0874 - val_mae: 0.2174\n",
      "Epoch 439/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0368 - mae: 0.1543 - val_loss: 0.0877 - val_mae: 0.2191\n",
      "Epoch 440/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1584 - val_loss: 0.0883 - val_mae: 0.2198\n",
      "Epoch 441/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0433 - mae: 0.1629 - val_loss: 0.0888 - val_mae: 0.2213\n",
      "Epoch 442/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.1601 - val_loss: 0.0889 - val_mae: 0.2212\n",
      "Epoch 443/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1550 - val_loss: 0.0887 - val_mae: 0.2207\n",
      "Epoch 444/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1616 - val_loss: 0.0872 - val_mae: 0.2169\n",
      "Epoch 445/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1609 - val_loss: 0.0873 - val_mae: 0.2180\n",
      "Epoch 446/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0418 - mae: 0.1612 - val_loss: 0.0872 - val_mae: 0.2187\n",
      "Epoch 447/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 0.1593 - val_loss: 0.0884 - val_mae: 0.2198\n",
      "Epoch 448/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.1619 - val_loss: 0.0886 - val_mae: 0.2204\n",
      "Epoch 449/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0442 - mae: 0.1647 - val_loss: 0.0873 - val_mae: 0.2194\n",
      "Epoch 450/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1619 - val_loss: 0.0866 - val_mae: 0.2178\n",
      "Epoch 451/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0370 - mae: 0.1530 - val_loss: 0.0870 - val_mae: 0.2180\n",
      "Epoch 452/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1671 - val_loss: 0.0870 - val_mae: 0.2191\n",
      "Epoch 453/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - mae: 0.1590 - val_loss: 0.0893 - val_mae: 0.2260\n",
      "Epoch 454/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1725 - val_loss: 0.0877 - val_mae: 0.2191\n",
      "Epoch 455/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0418 - mae: 0.1630 - val_loss: 0.0871 - val_mae: 0.2182\n",
      "Epoch 456/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.1744 - val_loss: 0.0867 - val_mae: 0.2185\n",
      "Epoch 457/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1672 - val_loss: 0.0890 - val_mae: 0.2211\n",
      "Epoch 458/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0374 - mae: 0.1539 - val_loss: 0.0875 - val_mae: 0.2184\n",
      "Epoch 459/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - mae: 0.1619 - val_loss: 0.0879 - val_mae: 0.2201\n",
      "Epoch 460/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0407 - mae: 0.1615 - val_loss: 0.0886 - val_mae: 0.2196\n",
      "Epoch 461/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0503 - mae: 0.1705 - val_loss: 0.0868 - val_mae: 0.2177\n",
      "Epoch 462/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - mae: 0.1565 - val_loss: 0.0858 - val_mae: 0.2158\n",
      "Epoch 463/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.1638 - val_loss: 0.0865 - val_mae: 0.2176\n",
      "Epoch 464/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0530 - mae: 0.1735 - val_loss: 0.0865 - val_mae: 0.2174\n",
      "Epoch 465/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0455 - mae: 0.1652 - val_loss: 0.0873 - val_mae: 0.2180\n",
      "Epoch 466/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0513 - mae: 0.1696 - val_loss: 0.0869 - val_mae: 0.2177\n",
      "Epoch 467/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.1643 - val_loss: 0.0868 - val_mae: 0.2178\n",
      "Epoch 468/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1573 - val_loss: 0.0878 - val_mae: 0.2196\n",
      "Epoch 469/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0582 - mae: 0.1765 - val_loss: 0.0877 - val_mae: 0.2185\n",
      "Epoch 470/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 0.1593 - val_loss: 0.0863 - val_mae: 0.2171\n",
      "Epoch 471/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.1630 - val_loss: 0.0883 - val_mae: 0.2208\n",
      "Epoch 472/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1650 - val_loss: 0.0877 - val_mae: 0.2183\n",
      "Epoch 473/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0516 - mae: 0.1722 - val_loss: 0.0869 - val_mae: 0.2177\n",
      "Epoch 474/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.1605 - val_loss: 0.0872 - val_mae: 0.2188\n",
      "Epoch 475/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0415 - mae: 0.1571 - val_loss: 0.0877 - val_mae: 0.2197\n",
      "Epoch 476/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.1617 - val_loss: 0.0866 - val_mae: 0.2167\n",
      "Epoch 477/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.1562 - val_loss: 0.0868 - val_mae: 0.2169\n",
      "Epoch 478/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0408 - mae: 0.1596 - val_loss: 0.0883 - val_mae: 0.2204\n",
      "Epoch 479/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1626 - val_loss: 0.0873 - val_mae: 0.2194\n",
      "Epoch 480/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0527 - mae: 0.1712 - val_loss: 0.0887 - val_mae: 0.2209\n",
      "Epoch 481/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0405 - mae: 0.1637 - val_loss: 0.0882 - val_mae: 0.2190\n",
      "Epoch 482/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - mae: 0.1647 - val_loss: 0.0898 - val_mae: 0.2213\n",
      "Epoch 483/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0496 - mae: 0.1736 - val_loss: 0.0872 - val_mae: 0.2173\n",
      "Epoch 484/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1533 - val_loss: 0.0885 - val_mae: 0.2194\n",
      "Epoch 485/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1673 - val_loss: 0.0876 - val_mae: 0.2190\n",
      "Epoch 486/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1643 - val_loss: 0.0879 - val_mae: 0.2199\n",
      "Epoch 487/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0407 - mae: 0.1614 - val_loss: 0.0880 - val_mae: 0.2201\n",
      "Epoch 488/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0462 - mae: 0.1621 - val_loss: 0.0923 - val_mae: 0.2298\n",
      "Epoch 489/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - mae: 0.1651 - val_loss: 0.0892 - val_mae: 0.2219\n",
      "Epoch 490/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - mae: 0.1644 - val_loss: 0.0906 - val_mae: 0.2237\n",
      "Epoch 491/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0480 - mae: 0.1671 - val_loss: 0.0876 - val_mae: 0.2197\n",
      "Epoch 492/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1585 - val_loss: 0.0887 - val_mae: 0.2212\n",
      "Epoch 493/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0455 - mae: 0.1622 - val_loss: 0.0885 - val_mae: 0.2211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0465 - mae: 0.1622 - val_loss: 0.0882 - val_mae: 0.2208\n",
      "Epoch 495/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0505 - mae: 0.1692 - val_loss: 0.0888 - val_mae: 0.2205\n",
      "Epoch 496/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1629 - val_loss: 0.0879 - val_mae: 0.2205\n",
      "Epoch 497/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.1553 - val_loss: 0.0896 - val_mae: 0.2213\n",
      "Epoch 498/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1591 - val_loss: 0.0891 - val_mae: 0.2214\n",
      "Epoch 499/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0417 - mae: 0.1625 - val_loss: 0.0888 - val_mae: 0.2216\n",
      "Epoch 500/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0404 - mae: 0.1567 - val_loss: 0.0882 - val_mae: 0.2209\n",
      "Epoch 501/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1738 - val_loss: 0.0873 - val_mae: 0.2185\n",
      "Epoch 502/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.1594 - val_loss: 0.0885 - val_mae: 0.2215\n",
      "Epoch 503/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0433 - mae: 0.1627 - val_loss: 0.0888 - val_mae: 0.2215\n",
      "Epoch 504/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - mae: 0.1697 - val_loss: 0.0891 - val_mae: 0.2221\n",
      "Epoch 505/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1547 - val_loss: 0.0877 - val_mae: 0.2202\n",
      "Epoch 506/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0521 - mae: 0.1670 - val_loss: 0.0887 - val_mae: 0.2213\n",
      "Epoch 507/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1567 - val_loss: 0.0878 - val_mae: 0.2195\n",
      "Epoch 508/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - mae: 0.1556 - val_loss: 0.0913 - val_mae: 0.2253\n",
      "Epoch 509/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1564 - val_loss: 0.0890 - val_mae: 0.2221\n",
      "Epoch 510/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0458 - mae: 0.1682 - val_loss: 0.0887 - val_mae: 0.2220\n",
      "Epoch 511/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1530 - val_loss: 0.0868 - val_mae: 0.2192\n",
      "Epoch 512/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1553 - val_loss: 0.0874 - val_mae: 0.2199\n",
      "Epoch 513/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - mae: 0.1657 - val_loss: 0.0883 - val_mae: 0.2198\n",
      "Epoch 514/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0457 - mae: 0.1617 - val_loss: 0.0880 - val_mae: 0.2204\n",
      "Epoch 515/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1538 - val_loss: 0.0889 - val_mae: 0.2207\n",
      "Epoch 516/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0498 - mae: 0.1751 - val_loss: 0.0879 - val_mae: 0.2205\n",
      "Epoch 517/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0471 - mae: 0.1658 - val_loss: 0.0884 - val_mae: 0.2211\n",
      "Epoch 518/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0404 - mae: 0.1554 - val_loss: 0.0889 - val_mae: 0.2224\n",
      "Epoch 519/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0382 - mae: 0.1602 - val_loss: 0.0876 - val_mae: 0.2197\n",
      "Epoch 520/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0533 - mae: 0.1692 - val_loss: 0.0868 - val_mae: 0.2178\n",
      "Epoch 521/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0408 - mae: 0.1633 - val_loss: 0.0864 - val_mae: 0.2170\n",
      "Epoch 522/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0502 - mae: 0.1693 - val_loss: 0.0873 - val_mae: 0.2198\n",
      "Epoch 523/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0471 - mae: 0.1672 - val_loss: 0.0869 - val_mae: 0.2180\n",
      "Epoch 524/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0552 - mae: 0.1784 - val_loss: 0.0879 - val_mae: 0.2200\n",
      "Epoch 525/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0470 - mae: 0.1667 - val_loss: 0.0869 - val_mae: 0.2185\n",
      "Epoch 526/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1650 - val_loss: 0.0869 - val_mae: 0.2186\n",
      "Epoch 527/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1555 - val_loss: 0.0889 - val_mae: 0.2200\n",
      "Epoch 528/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0389 - mae: 0.1569 - val_loss: 0.0877 - val_mae: 0.2191\n",
      "Epoch 529/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0403 - mae: 0.1624 - val_loss: 0.0874 - val_mae: 0.2193\n",
      "Epoch 530/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1587 - val_loss: 0.0873 - val_mae: 0.2180\n",
      "Epoch 531/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0395 - mae: 0.1587 - val_loss: 0.0876 - val_mae: 0.2199\n",
      "Epoch 532/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0461 - mae: 0.1631 - val_loss: 0.0901 - val_mae: 0.2282\n",
      "Epoch 533/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0464 - mae: 0.1642 - val_loss: 0.0883 - val_mae: 0.2205\n",
      "Epoch 534/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0448 - mae: 0.1628 - val_loss: 0.0876 - val_mae: 0.2195\n",
      "Epoch 535/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1538 - val_loss: 0.0867 - val_mae: 0.2178\n",
      "Epoch 536/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0505 - mae: 0.1678 - val_loss: 0.0881 - val_mae: 0.2202\n",
      "Epoch 537/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0409 - mae: 0.1613 - val_loss: 0.0865 - val_mae: 0.2179\n",
      "Epoch 538/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0382 - mae: 0.1559 - val_loss: 0.0866 - val_mae: 0.2176\n",
      "Epoch 539/600\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0388 - mae: 0.1592 - val_loss: 0.0877 - val_mae: 0.2189\n",
      "Epoch 540/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0442 - mae: 0.1672 - val_loss: 0.0883 - val_mae: 0.2214\n",
      "Epoch 541/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0456 - mae: 0.1671 - val_loss: 0.0863 - val_mae: 0.2174\n",
      "Epoch 542/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0445 - mae: 0.1614 - val_loss: 0.0883 - val_mae: 0.2197\n",
      "Epoch 543/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0523 - mae: 0.1753 - val_loss: 0.0887 - val_mae: 0.2200\n",
      "Epoch 544/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0494 - mae: 0.1697 - val_loss: 0.0926 - val_mae: 0.2301\n",
      "Epoch 545/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.1634 - val_loss: 0.0870 - val_mae: 0.2178\n",
      "Epoch 546/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0464 - mae: 0.1651 - val_loss: 0.0869 - val_mae: 0.2181\n",
      "Epoch 547/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - mae: 0.1481 - val_loss: 0.0890 - val_mae: 0.2247\n",
      "Epoch 548/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.1677 - val_loss: 0.0872 - val_mae: 0.2197\n",
      "Epoch 549/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - mae: 0.1535 - val_loss: 0.0872 - val_mae: 0.2185\n",
      "Epoch 550/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.1621 - val_loss: 0.0870 - val_mae: 0.2183\n",
      "Epoch 551/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1650 - val_loss: 0.0880 - val_mae: 0.2188\n",
      "Epoch 552/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1607 - val_loss: 0.0870 - val_mae: 0.2176\n",
      "Epoch 553/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.1625 - val_loss: 0.0867 - val_mae: 0.2183\n",
      "Epoch 554/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.1621 - val_loss: 0.0884 - val_mae: 0.2197\n",
      "Epoch 555/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - mae: 0.1713 - val_loss: 0.0874 - val_mae: 0.2187\n",
      "Epoch 556/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0475 - mae: 0.1682 - val_loss: 0.0872 - val_mae: 0.2183\n",
      "Epoch 557/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0488 - mae: 0.1732 - val_loss: 0.0875 - val_mae: 0.2185\n",
      "Epoch 558/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0369 - mae: 0.1546 - val_loss: 0.0874 - val_mae: 0.2182\n",
      "Epoch 559/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.1605 - val_loss: 0.0877 - val_mae: 0.2188\n",
      "Epoch 560/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0404 - mae: 0.1569 - val_loss: 0.0869 - val_mae: 0.2182\n",
      "Epoch 561/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1682 - val_loss: 0.0872 - val_mae: 0.2179\n",
      "Epoch 562/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0393 - mae: 0.1596 - val_loss: 0.0865 - val_mae: 0.2176\n",
      "Epoch 563/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1622 - val_loss: 0.0868 - val_mae: 0.2178\n",
      "Epoch 564/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0461 - mae: 0.1632 - val_loss: 0.0871 - val_mae: 0.2202\n",
      "Epoch 565/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1543 - val_loss: 0.0863 - val_mae: 0.2168\n",
      "Epoch 566/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0403 - mae: 0.1602 - val_loss: 0.0865 - val_mae: 0.2166\n",
      "Epoch 567/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0388 - mae: 0.1577 - val_loss: 0.0883 - val_mae: 0.2203\n",
      "Epoch 568/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0466 - mae: 0.1679 - val_loss: 0.0899 - val_mae: 0.2237\n",
      "Epoch 569/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0374 - mae: 0.1578 - val_loss: 0.0872 - val_mae: 0.2186\n",
      "Epoch 570/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - mae: 0.1700 - val_loss: 0.0861 - val_mae: 0.2172\n",
      "Epoch 571/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0448 - mae: 0.1665 - val_loss: 0.0858 - val_mae: 0.2163\n",
      "Epoch 572/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 0.1634 - val_loss: 0.0859 - val_mae: 0.2167\n",
      "Epoch 573/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - mae: 0.1687 - val_loss: 0.0857 - val_mae: 0.2165\n",
      "Epoch 574/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1661 - val_loss: 0.0860 - val_mae: 0.2163\n",
      "Epoch 575/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - mae: 0.1600 - val_loss: 0.0882 - val_mae: 0.2196\n",
      "Epoch 576/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1603 - val_loss: 0.0869 - val_mae: 0.2190\n",
      "Epoch 577/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.1601 - val_loss: 0.0883 - val_mae: 0.2205\n",
      "Epoch 578/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0479 - mae: 0.1674 - val_loss: 0.0884 - val_mae: 0.2205\n",
      "Epoch 579/600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0434 - mae: 0.1680 - val_loss: 0.0877 - val_mae: 0.2200\n",
      "Epoch 580/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 0.1613 - val_loss: 0.0861 - val_mae: 0.2175\n",
      "Epoch 581/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - mae: 0.1617 - val_loss: 0.0868 - val_mae: 0.2187\n",
      "Epoch 582/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0471 - mae: 0.1693 - val_loss: 0.0862 - val_mae: 0.2167\n",
      "Epoch 583/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0446 - mae: 0.1600 - val_loss: 0.0868 - val_mae: 0.2172\n",
      "Epoch 584/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - mae: 0.1574 - val_loss: 0.0867 - val_mae: 0.2178\n",
      "Epoch 585/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1540 - val_loss: 0.0878 - val_mae: 0.2193\n",
      "Epoch 586/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0453 - mae: 0.1624 - val_loss: 0.0870 - val_mae: 0.2186\n",
      "Epoch 587/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.1595 - val_loss: 0.0867 - val_mae: 0.2177\n",
      "Epoch 588/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1525 - val_loss: 0.0893 - val_mae: 0.2220\n",
      "Epoch 589/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1565 - val_loss: 0.0876 - val_mae: 0.2195\n",
      "Epoch 590/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0534 - mae: 0.1767 - val_loss: 0.0894 - val_mae: 0.2223\n",
      "Epoch 591/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0581 - mae: 0.1788 - val_loss: 0.0870 - val_mae: 0.2187\n",
      "Epoch 592/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.1589 - val_loss: 0.0878 - val_mae: 0.2198\n",
      "Epoch 593/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0397 - mae: 0.1614 - val_loss: 0.0906 - val_mae: 0.2243\n",
      "Epoch 594/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0455 - mae: 0.1676 - val_loss: 0.0883 - val_mae: 0.2207\n",
      "Epoch 595/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1585 - val_loss: 0.0865 - val_mae: 0.2179\n",
      "Epoch 596/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1578 - val_loss: 0.0873 - val_mae: 0.2201\n",
      "Epoch 597/600\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0394 - mae: 0.1547 - val_loss: 0.0891 - val_mae: 0.2217\n",
      "Epoch 598/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1589 - val_loss: 0.0875 - val_mae: 0.2186\n",
      "Epoch 599/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - mae: 0.1566 - val_loss: 0.0880 - val_mae: 0.2198\n",
      "Epoch 600/600\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1559 - val_loss: 0.0883 - val_mae: 0.2211\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=3, activation='tanh', kernel_initializer='he_normal', input_shape=(input_layer_size,)))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.005), loss = 'mse', metrics = ['mae'])\n",
    "history = model.fit(x_train, y_train, batch_size=4, epochs=600,\n",
    "                        validation_data=(x_validate, y_validate), verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f90c307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat_train = model.predict(x_train)\n",
    "y_hat_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20c73d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2_train0 = str(np.round(r2_score(np.exp(y_train[:,0]), np.exp(y_hat_train[:,0])),5))\n",
    "r2_train1 = str(np.round(r2_score(np.exp(y_train[:,1]), np.exp(y_hat_train[:,1])),5))\n",
    "\n",
    "plt.figure(figsize = [20, 6])\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(np.exp(y_train[:,0]), np.exp(y_hat_train[:,0]))\n",
    "plt.xlabel('Targets (y_train_train)',size=10)\n",
    "plt.ylabel('Predictions (y_hat)',size=10)\n",
    "plt.plot([0,15], [0, 15], color='green', marker='o', linestyle='dashed', linewidth=1, markersize=5)\n",
    "plt.annotate('r2_score =' + r2_train0, xy=(2,14), fontsize=15)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(np.exp(y_train[:,1]), np.exp(y_hat_train[:,1]))\n",
    "plt.xlabel('Targets (y_train)',size=10)\n",
    "plt.ylabel('Predictions (y_hat)',size=10)\n",
    "plt.plot([0,4], [0, 4], color='green', marker='o', linestyle='dashed', linewidth=1, markersize=5)\n",
    "plt.annotate('r2_score =' + r2_train1, xy=(0.5,3.5), fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "983e7c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2_test0 = str(np.round(r2_score(np.exp(y_test[:,0]), np.exp(y_hat_test[:,0])),5))\n",
    "r2_test1 = str(np.round(r2_score(np.exp(y_test[:,1]), np.exp(y_hat_test[:,1])),5))\n",
    "\n",
    "plt.figure(figsize = [20, 6])\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(np.exp(y_test[:,0]), np.exp(y_hat_test[:,0]))\n",
    "plt.xlabel('Targets (y_train_train)',size=10)\n",
    "plt.ylabel('Predictions (y_hat)',size=10)\n",
    "plt.plot([0,15], [0, 15], color='green', marker='o', linestyle='dashed', linewidth=1, markersize=5)\n",
    "plt.annotate('r2_score =' + r2_test0, xy=(2,14), fontsize=15)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(np.exp(y_test[:,1]), np.exp(y_hat_test[:,1]))\n",
    "plt.xlabel('Targets (y_train)',size=10)\n",
    "plt.ylabel('Predictions (y_hat)',size=10)\n",
    "plt.plot([0,4], [0, 4], color='green', marker='o', linestyle='dashed', linewidth=1, markersize=5)\n",
    "plt.annotate('r2_score =' + r2_test1, xy=(0.5,3.5), fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96e948fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"ANN_model.h5\")\n",
    "\n",
    "scaler = pickle.dump(sc_x, open('scaler.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Artificial Neural Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
